{"config":{"lang":["nl"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Algoritmekader","text":"<p>Wil de overheid\u202feffectief en verantwoord gebruik kunnen maken van algoritmes en (daarmee) van Artifici\u00eble Intelligentie (AI), dan stelt dat eisen aan de manier waarop we daarmee omgaan.\u202fTegelijkertijd zien we ook dat wat nodig is voor verantwoorde inzet enorm in ontwikkeling is, bijvoorbeeld door de snelle opkomst van (generatieve) AI. In relatief korte tijd komen er veel nieuwe mogelijkheden, maar ook nieuwe wetten, regels, normen en instrumenten. Veel overheden zien soms door de bomen het bos niet meer. Want hoe voldoe je aan de minimale normen? Wanneer is er sprake van verantwoorde inzet? En: welk instrument pas je wanneer toe?  </p> <p>Met het Algoritmekader werken we als overheid samen aan de\u202fantwoorden daarop. Dat doen we open; iedereen kan deze ontwikkeling volgen en eraan bijdragen.\u202fWe maken bij de ontwikkeling gebruik van wat er al is: wetten, normen, regels, instrumenten en expertise. Het kader brengt dit samen op een logische manier. Zodat overheden in alle fasen van de levenscyclus van algoritmische en AI-toepassingen praktische handvatten hebben. Best practices, use cases en input van eindgebruikers en de toezichthouder helpen te komen tot een goed en gedragen Algoritmekader voor alle overheden.\u202fHet kader wordt een praktisch hulpmiddel om algoritmes en AI verantwoord te kunnen inzetten en te voldoen aan de minimale eisen die wet- en regelgeving daaraan stellen. </p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"#eerdere-versies-van-het-algoritmekader","title":"Eerdere versies van het algoritmekader","text":"<p>Zie het Implementatiekader dat in juni 2023 naar de Tweede Kamer is verzonden. </p>"},{"location":"#bijdragen-aan-het-algoritmekader","title":"Bijdragen aan het algoritmekader?","text":"<p>We ontwikkelen het Algoritmekader op een open manier via GitHub. Bekijk de ontwikkelomgeving van het Algoritmekader.</p>"},{"location":"#heb-je-een-vraag-of-opmerking","title":"Heb je een vraag of opmerking?","text":"<p>Neem contact op via GitHub (zie punt 4 of 5) of stuur een email naar algoritmes@minbzk.nl.</p> <p>Stuur een mail </p>"},{"location":"bouwblokken/","title":"Bouwblokken","text":"<ul> <li> <p> Fundamentele rechten (in ontwikkeling)</p> <p>Het bouwblok fundamentele rechten is opgesplitst in verschillende delen</p> <p> Naar fundamentele rechten</p> <p> Naar bias en non-discriminatie</p> </li> <li> <p> Publieke inkoop (in ontwikkeling)</p> <p>Hier kunnen we een korte tekst kwijt over publieke inkoop</p> <p> Naar publieke inkoop</p> </li> <li> <p> Privacy en gegevensbescherming (in ontwikkeling)</p> <p>Hier kunnen we een korte tekst kwijt over privacy en gegevensbescherming</p> <p> Naar privacy en gegevensbescherming</p> </li> <li> <p> Transparantie (in ontwikkeling)</p> <p>Hier kunnen we een korte tekst kwijt over transparantie</p> <p> Naar transparantie</p> </li> <li> <p> Conformiteitsbeoordeling (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over conformiteitsbeoordeling</p> <p> Naar conformiteitsbeoordeling</p> </li> <li> <p> Data (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over data</p> <p> Naar data</p> </li> <li> <p> Duurzaamheid (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over duurzaamheid</p> <p> Naar duurzaamheid</p> </li> <li> <p> Governance (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over governance</p> <p> Naar governance</p> </li> <li> <p> Menselijke controle (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over menselijke controle</p> <p> Naar menselijke controle</p> </li> <li> <p> Technische robuustheid en veiligheid (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over technische robuustheid en veiligheid</p> <p> Naar technische robuustheid en veiligheid</p> </li> </ul> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"bouwblokken/conformiteitsbeoordeling/","title":"Conformiteitsbeoordeling","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/conformiteitsbeoordeling/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/conformiteitsbeoordeling/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/data/","title":"Data","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/data/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmen en aiVolgens de archiefwet moeten overheden informatie bewaren op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en ai, tot stand zijn gekomen informatie over en van algoritmen en ai moet daarom ook bewaard en vernietigd wordenVerbod op schenden auteursrechtenBepaalde vormen van algoritmen en ai worden ontwikkeld op basis van grote hoeveelheden data deze data wordt gebruikt voor het trainen en testen van algoritmen en ai het gebruiken van deze data mag geen inbreuk maken op auteursrechten van diegene die deze rechten heeft ook de gegenereerde output van algoritmen en ai mag geen inbreuk maken op deze rechtenBeschermen van persoonsgegevensVoor de ontwikkeling en gebruik van algoritmen en ai is dat nodig deze data kan persoonsgegevens bevatten deze persoonsgegevens moeten worden beschermd de organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of ai-systeem voldoende te beschermen hierbij kan worden gedacht aan dataminimalisatie, het pseudonomiseren of aggregeren van persoonsgegevens per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijnVerbod op schenden databankenrechtenHet databankenrecht beschermt tegen kopi\u00ebren of oneigenlijk gebruik van gegevens in een databank degene die een substanti\u00eble financi\u00eble investering heeft verricht om de databank tot stand te brengen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken voor het ontwikkelen van algoritme en ai is data nodig de data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databank"},{"location":"bouwblokken/data/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/duurzaamheid/","title":"Duurzaamheid","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/duurzaamheid/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/duurzaamheid/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/fundamentele-rechten/","title":"Fundamentele rechten","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/fundamentele-rechten/#vereisten","title":"Vereisten","text":"VereisteUitlegNoneNoneKlachten indienen bij markttoezichtautoriteitNaast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en aiRecht op uitleg ai-besluitenElke persoon die wordt be\u00efnvloed door een besluit dat is genomen op basis van de output van een ai-systeem met een hoog risico, heeft het recht om van de exploitant een duidelijke uitleg te krijgen over de rol van het systeem in de besluitvorming en de belangrijkste aspecten van het besluit dit geldt voor besluiten die aanzienlijke gevolgen hebben voor de persoon, zoals die hun gezondheid, veiligheid of grondrechten be\u00efnvloeden deze maatregel waarborgt transparantie en verantwoordelijkheid bij het gebruik van ai in besluitvormingsprocessen, en biedt individuen de mogelijkheid om de beslissingen die hen be\u00efnvloeden te begrijpen en te betwistenVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatKlachtrecht downstreamaanbiedersDownstreamaanbieders hebben het recht om een klacht in te dienen bij het ai-bureau in het geval van een inbreuk op deze verordening dit biedt hen een mechanisme om actie te ondernemen bij schendingen van de regels met betrekking tot ai-systemen het ai-bureau kan dan passende maatregelen nemen om de naleving van de verordening te handhaven en eventuele geschillen op te lossenToepassing richtlijn (eu) 2019/1937Richtlijn (eu) 2019/1937 is van toepassing op het melden van inbreuken op deze verordening en op de bescherming van personen die deze inbreuken melden het biedt een kader voor het veilig en vertrouwelijk melden van schendingen van de verordening, terwijl het de melders beschermt tegen represailles of vervolging deze richtlijn bevordert transparantie en verantwoording binnen organisaties en draagt bij aan een cultuur van naleving en integriteitRisicobeoordeling voor jongeren en kwetsbarenBij het beheer van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het ai-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen"},{"location":"bouwblokken/fundamentele-rechten/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/","title":"Non-discriminatie","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#waarom","title":"Waarom?","text":"<p>Schrijf hier een tekst over wat [title] is en waarom dit belangrijk is voor een verantwoord gebruik van algoritmes bij overheidsorganisaties. </p>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#levenscyclus","title":"Levenscyclus","text":"<p>Een overzicht van welke fasen van de levenscyclus relevant zijn voor dit bouwblok. </p> <ul> <li> Probleemanalyse</li> <li> Ontwerp</li> <li> Data verkenning en data preparatie</li> <li> Ontwikkelen</li> <li> Validatie  </li> <li> Implementatie</li> <li> Monitoren</li> <li> Archiveren</li> </ul>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#normen","title":"Normen","text":"<p>Onderstaand een overzicht van de minimale vereisten die volgen uit geldende wet- en regelgeving, toetingskaders en andere bronnen</p> Laag risicoHoog risico Norm Uitleg Bron Norm 2 Korte uitleg over norm 2 Norm Uitleg Bron Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Korte uitleg over norm 1 Norm 2 Korte uitleg over norm 2 Norm 3 Korte uitleg over norm 3 Norm 4 Korte uitleg over norm 4"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#rollen","title":"Rollen","text":"<p>Overzicht van welke rollen belangrijk zijn te betrekken bij dit bouwblok. </p> <ul> <li>technische expert bron: handreiking non-discriminatie by design</li> <li>projectleider bron: handreiking non-discriminatie by design</li> <li>jurist bron: handreiking non-discriminatie by design</li> <li>functionaris gegevensbescherming bron: handreiking non-discriminatie by design</li> <li>relevante stakeholders bron: handreiking non-discriminatie by design</li> <li>domein expert bron: handreiking non-discriminatie by design</li> <li>data steward bron: handreiking non-discriminatie by design</li> <li>data analist bron: handreiking non-discriminatie by design</li> <li>beleid bron: evaluatie handreiking non-discriminatie by design door ADR</li> </ul>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#aanbevelingen","title":"Aanbevelingen","text":"<p>Rathenau</p> <ul> <li>Geef als uitvoeringsorganisatie meer inzicht in hoe biastoetsing plaatsvindt </li> <li>Zet een nationaal kennisplatform voor biastoetsing op waar expertise kan worden ontwikkeld en gedeeld. Bepaal welke mate van standaardisatie gewenst is en of wettelijke eisen nodig zijn.</li> </ul> <p>ADR</p> <ul> <li>Plaats de handreiking in een kader in relatie tot andere instrumenten </li> <li>Overweeg een risicogerichte benadering voor de toepassing van de handreiking </li> <li>Werk aan het vergroten van bewustzijn voor algoritmen en (data-)ethiek in de organisatie </li> <li>Zorg voor duidelijkheid in taken en verantwoordelijkheden van verschillende betrokkenen </li> <li>Beleg verantwoordelijkheid voor de handreiking en borg de (blijvende) aandacht ervoor </li> <li>Verplichte toepassing van de handreiking kan bestaande initiatieven tenietdoen </li> </ul> <p>Toetsingskader ADR</p> <ul> <li>De definitie van de verschillende groepen en de gewenste prestatie van het model voor deze groepen zijn opgenomen in de functionele eisen.</li> <li>De mate van geaccepteerde bias in de uitkomst is opgenomen in de functionele eisen en uitgewerkt in meetbare prestatiecriteria.</li> <li>De methoden om bias te voorkomen, detecteren en corrigeren zijn vastgelegd.</li> <li>De mate van bias in de data, dataverzameling en het model zijn in kaart gebracht.</li> <li>Tijdens de ontwikkeling van het model is beoordeeld of er een verschil bestaat tussen de prestatie van het model tussen verschillende subgroepen. De prestatiemetrieken afleidbaar uit de confusionmatrix zijn vergeleken voor deze subgroepen.</li> <li>De uitkomstbias van productiedata is beoordeeld voor de verschillende subgroepen en voldoet aan de prestatiecriteria.</li> <li>Bij de geconstateerde bias is beoordeeld of deze op discriminatie duidt.</li> </ul> <p>College voor de Rechten van de Mens (Richtlijnen)</p> <ul> <li>Overheidsinstanties mogen bij opsporings- en handhavingsbevoegdheden, met het oog op effectiviteit, effici\u00ebntie en kostenbesparing, gebruik maken van risicoprofielen. Binnen deze risicoprofielen mogen ervaringsgegevens die tot een bepaalde vooronderstelling leiden een rol spelen, tenzij dit leidt tot discriminatie op grond van ras of nationaliteit</li> <li>Risicoprofielen die uitsluitend of in doorslaggevende mate gebaseerd zijn op ras (waaronder etniciteit en afkomst) zijn in strijd met het discriminatieverbod;</li> <li>Risicoprofielen die zich richten op \u00e9\u00e9n bepaalde afkomst of nationaliteit hebben een stigmatiserend effect en zijn daarom strijdig met het discriminatieverbod;</li> <li>Risicoprofielen die uitsluitend gebaseerd zijn op nationaliteit zijn zeer moeilijk te rechtvaardigen;</li> <li>Risicoprofielen waarin ras of nationaliteit mede een rol speelt, kunnen slechts gerechtvaardigd worden door zeer zwaarwegende redenen;</li> <li>Het gebruik van ras of nationaliteit als selectiecriterium binnen een risicoprofiel is nooit toegestaan als er geen objectieve relatie kan worden aangetoond tussen dit selectiecriterium en het legitieme doel van het profiel;</li> <li>In alle gevallen moeten de selectiecriteria  binnen een risicoprofiel samen voldoende relevant en objectief (geschikt) zijn om op een effectieve wijze bij te dragen aan de verwezenlijking van het nagestreefde legitieme doel;</li> <li>Het gebruik van ras of nationaliteit als selectiecriterium binnen een risicoprofiel moet daarnaast noodzakelijk zijn om het gewenste doel tebereiken.</li> <li>Selectiebeslissingen moeten te allen tijde uitlegbaar zijn.</li> </ul>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#mogelijke-hulpmiddelen-en-methoden","title":"Mogelijke hulpmiddelen en methoden","text":"<ul> <li>Fairness Handbook</li> </ul>"},{"location":"bouwblokken/governance/","title":"Governance","text":"<p>Hier komt een beschrijving van dit bouwblok.</p>"},{"location":"bouwblokken/governance/#vereisten","title":"Vereisten","text":""},{"location":"bouwblokken/governance/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/menselijke-controle/","title":"Menselijke controle","text":"<p>Hier komt een beschrijving van dit bouwblok.</p>"},{"location":"bouwblokken/menselijke-controle/#vereisten","title":"Vereisten","text":""},{"location":"bouwblokken/menselijke-controle/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/privacy-en-gegevensbescherming/","title":"Privacy en gegevensbescherming","text":"<p>Hier komt een beschrijving van dit bouwblok.</p>"},{"location":"bouwblokken/privacy-en-gegevensbescherming/#vereisten","title":"Vereisten","text":""},{"location":"bouwblokken/privacy-en-gegevensbescherming/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/publieke-inkoop/","title":"Publieke inkoop","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Door middel van publieke inkoop wordt door overheidsinstellingen software ingekocht. Deze software wordt ingekocht om ambtenaren te ondersteunen met hun werkzaamheden om zo maatschappelijk waarden te cre\u00ebren. Het kan bijvoorbeeld gaan om het inkopen van een systeem waarmee een aanvraag voor een subsidie of vergunning kan worden behandeld. Het virtueel vergaderen of het digitaal samenwerken aan documenten zijn hier ook voorbeelden van. </p> <p>Software met algoritmen  en AI wordt vaak ontwikkeld door gespecialiseerde aanbieders en bevat steeds meer algoritmen en AI. Het komt ook voor dat de overheid deze technologie zelf ontwikkelt. Deze algoritmen en AI kunnen eenvoudig van aard zijn, zoals het maken van een eenvoudige berekening. Zij kunnen complexer van aard zijn, zoals een voorspelling geven of het genereren van informatie. In het laatste geval kan worden gedacht aan ChatGPT, Google Bard of Co-Pilot. Er zijn verschillende type technologie\u00ebn die vallen onder het bereik van algoritmen en AI. In dit kader drukken we deze uit als \u2018rekenregel\u2019, \u2018machine learning\u2019 en \u2018generatieve AI\u2019. Elke technologie heeft eigen bijzondere aandachtspunten. Ook de bijbehorende risico\u2019s kunnen per type verschillen. Het identificeren van deze risico\u2019s en het treffen van beheersmaatregelen is daarbij van belang. Dat geldt in het bijzonder als algoritmen en AI bijdragen aan de totstandkoming van overheidsbesluitvorming en impactvolle beslissingen die burgers en ondernemingen raken. </p> <p>Door bij publieke inkoop van software met algoritmen en AI rekening te houden met vereisten die voorkomen uit wet- en regelgeving, toepassen van publieke waarden, het type algoritme of AI en de potenti\u00eble risico\u2019s die ontstaan bij het gebruiken ervan, kunnen negatieve gevolgen worden voorkomen. Publieke inkoop speelt daarom een belangrijke rol bij de totstandkoming van verantwoord ontwikkelde algoritmen en AI en het gebruik daarvan door ambtenaren.  In dit deel van het Algoritmekader wordt nader ingegaan op deze vereisten. Er worden suggesties gedaan hoe deze vereisten kunnen worden nageleefd en welke rollen daarbij betrokken kunnen zijn. Waar mogelijk worden concrete voorbeelden uit de praktijk gegeven en zal worden aangegeven bij welk type algoritmen of AI dit relevant is.</p> <p>Het publiek inkopen van algoritmen en AI wordt ook gekoppeld aan de algoritme levenscyclus. Dit geeft een beeld van wanneer bepaalde vereisten en maatregelen, bij het ontwikkelen van algoritmen en AI, moeten worden geadresseerd. Door deze vereisten ook te vertalen naar het inkoopproces, zullen de rollen binnen het inkoopproces beter in staat zijn om te duiden wanneer en hoe dit kan worden geadresseerd. Dit moet bijdragen aan een goed samenspel met aanbieders, zodat de kansen van algoritmen en AI worden benut en de negatieve gevolgen worden voorkomen.  </p>"},{"location":"bouwblokken/publieke-inkoop/#algoritme-levenscyclus","title":"Algoritme levenscyclus","text":"<p>Algoritmen en AI kunnen een grote impact hebben op onze maatschappij. Daarom is het van belang dat deze op een verantwoorde manier worden ontwikkeld en gebruikt. Het toepassen van de algoritme levenscyclus is hierover een bruikbare leidraad. De algoritme levenscyclus bestaat uit meerdere fasen. De werkzaamheden die noodzakelijk zijn om een verantwoord algoritme of AI te ontwikkelen, kunnen logisch worden gekoppeld aan deze fasen.  Deze levenscyclus kan worden gebruikt voor alle typen algoritmen en AI. Het verschilt uiteraard wel per type wat moet worden gedaan en dit is mede afhankelijk van de risico classificatie. Bij hoge risico toepassing zal meer moeten worden gedaan om risico\u2019s te mitigeren dan als er sprake is van lage risico toepassingen. De levenscyclus geeft een bruikbaar overzicht voor leveranciers en opdrachtgevers wanneer welke werkzaamheden moeten worden uitgevoerd. Het laat ook zien welke werkzaamheden moeten zijn afgerond als algoritmen en AI in de markt mogen worden gezet en klaar zijn voor gebruik. </p> <p>Bij het publiek inkopen van software met bijbehorende algoritmen en AI zijn de wensen van de behoeftesteller en de doelstellingen van de organisatie van groot belang. Dit kan tot verschillende situaties leiden:</p> <p>\u2022   Een al ontwikkelde kant-en-klare oplossing voldoet direct aan deze wensen en doelstellingen;</p> <p>\u2022   Een al ontwikkelde oplossing moet eerst worden aangepast voordat deze kan worden gebruikt;</p> <p>\u2022   Er moet een nieuwe oplossing worden ontwikkeld om te voldoen aan de wensen. </p> <p>Deze inschatting is dus bepalend wat wel en niet van een product mag worden verwacht. Dit is relevant voor zowel de leverancier als de opdrachtgever. Het is aannemelijk dat als het om risicovolle (nog te ontwikkelen) algoritmen of AI gaat, de opdrachtgever een intensieve bijdrage moet leveren aan de samenwerking om het product te kunnen gebruiken. De opdrachtgever zal bijvoorbeeld moeten aangeven wat de juridische en ethische grenzen zijn van de uiteindelijk werking van het algoritme of AI. Als een kant-en-klare oplossing wordt afgenomen, dan zal de leverancier moeten laten zien dat de ontwikkelde algoritmen en AI voldoen aan alle vereisten en moet dit kunnen aantonen. </p> <p>De inzichten uit de algoritme levenscyclus kunnen ondersteunen bij bijvoorbeeld de behoeftestelling, het maken van make-or-buy beslissingen, de te hanteren aanbestedingsvorm, de totstandkoming van de selectie- en gunningseisen, contractspecificaties en de uitvoering en management van het contract. De algoritme levenscyclus kan worden geraadpleegd via het tabblad boven aan deze pagina. Per fase en per type algoritme of AI kan worden bekeken aan welke vereisten moet worden voldaan en welke beheersmaatregelen kunnen worden getroffen. </p>"},{"location":"bouwblokken/publieke-inkoop/#vereisten","title":"Vereisten","text":""},{"location":"bouwblokken/publieke-inkoop/#vereisten_1","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/publieke-inkoop/#maatregelen","title":"Maatregelen","text":"Vereisten Uitleg verplicht voor hoog-risico AI systemen (AI Act) verplicht voor impactvolle algoritmes verplicht voor niet-impactvolle algoritmes Archiveren De grondslag van de Archiefwet is dat, als de overheid de informatie bewaart die voortkomt uit de verschillende werkprocessen, aan de hand van deze informatie de werkprocessen kunnen worden gereconstrueerd en kan worden nagegaan hoe besluiten tot stand zijn gekomen. De oordeelsvorming over hoe zaken zijn verlopen kan dan worden overgelaten aan anderen Non-discriminatie Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan. Verbod schenden Auteursrechten Bepaalde vormen van algoritmen en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainingen en testen van algoritmen en AI. Deze data mag geen inbreuk maken op Auteursrechten. Ook de gegenereerde output van algoritmen en AI mag geen inbreuk maken op deze rechten. Kwaliteitsmanagementsysteem De  ontwikkelaar van een AI-systeem of een 'general purpose AI model' die deze op de markt plaatst zal een kwaliteitsmanagementsysteem toepassen waarmee wordt voldaan aan de verplichtingen die voortkomen uit de AI-verordening."},{"location":"bouwblokken/publieke-inkoop/#nuttige-informatie","title":"Nuttige informatie","text":"<p>Europese modelcontractbepalingen AI-systemen (hoog risico)</p> <p>Europese modelcontractbepalingen AI-systemen (niet hoog risico)</p> <p>Contractvoorwaarden voor algoritmen gemeente Amsterdam</p>"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/","title":"Technische robuustheid en veiligheid","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmen en aiVolgens de archiefwet moeten overheden informatie bewaren op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en ai, tot stand zijn gekomen informatie over en van algoritmen en ai moet daarom ook bewaard en vernietigd wordenInformatie en informatiesystemen van de overheid moet worden beveiligdInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen in nederland is besloten dat overheidsinstellingen de baseline informatiebeveiliging overheid dienen toe te passen over hun informatie en informatiesystemen de bio beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn algoritmen en ai-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de bio op van toepassing is het is van belang om algoritmische toepassingen en ai-systemen op de juiste manier te beveiligenOntwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAi-systemen met een hoog risico worden zorgvuldig ontworpen en ontwikkeld om een hoog niveau van nauwkeurigheid, robuustheid en cyberbeveiliging te bieden dit garandeert consistente prestaties gedurende hun levensduur en minimaliseert risico's met betrekking tot deze aspecten, waardoor de betrouwbaarheid en veiligheid van het systeem worden gewaarborgd"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/transparantie/","title":"Transparantie","text":"<p>Hier komt een beschrijving van dit bouwblok.</p>"},{"location":"bouwblokken/transparantie/#vereisten","title":"Vereisten","text":"VereisteUitlegImpactvolle algoritmen en ai worden gepubliceerd in het algoritmeregisterHet publiceren van impactvolle algoritmen en ai draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmen en ai worden gebruikt door de overheid het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmen en hoge risico ai publiceren in het algoritmeregisterEenieder heeft recht op toegang tot publieke informatieBij het ontwikkelen en gebruiken van algoritmen en ai kunnen documenten en kan publieke informatie ontstaan die (op verzoek) in aanmerkingen komen voor openbaarmaking het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat er kunnen uitsluitingsgronden bestaan voor het openbaarmaking van documentenTransparantie in ontwerp voor hoog-risico aiAi-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat exploitanten de output van het systeem kunnen begrijpen en adequaat kunnen gebruiken dit zorgt ervoor dat de aanbieders en exploitanten kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd"},{"location":"bouwblokken/transparantie/#maatregelen","title":"Maatregelen","text":""},{"location":"instrumenten/","title":"Instrumenten","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Het Algoritmekader is tot stand gekomen op basis van de volgende instrumenten:</p> Naam instrument Categorie Jaartal uitgebracht Verantwoordelijke organisatie Ontwikkeld door null null Ontwikkeld voor null null Voor overheidsorganisatie specfiek Volwassenheidsniveau Locatie Doel null null null Mogelijke wettelijke verplichting Toelichting doel Toepassing overheid wetenschap overig overheid wetenschap overig Informerend Sturend Normerend Faciliterend technologie algemeen Impact Assessment Mensenrechten en Algoritmes Impact Assessment 2021 Universiteit Utrecht ja ja ja ja In gebruik Internationaal \u00b1 - - + ja Dit impact assessment werkt in eerste instantie faciliterend voor het gesprek. Maar biedt ook veel informatie. \u00b1 Handreiking Non-discriminatie by Design Handleiking/leidraad 2021 Binnenlandse Zaken ja ja nee ja ja ja In gebruik Nationaal + + - \u00b1 nee Deze handreiking is bedoeld voor projectleiders die sturing geven aan systeembouwers, data-analisten en AI-experts op het gebied van het discriminatieverbod. - De Ethische Data Assistent (DEDA) Handleiking/leidraad 2022 Utrecht Data School nee ja nee ja ja ja In gebruik Nationaal + - - + nee DEDA helpt data-analisten, projectmanagers en beleidsmakers om samen ethische problemen in dataprojecten, datamanagement en databeleid te herkennen. - Toetsingskader Algoritmes Algemene Rekenkamer Toetsingskader 2020 Algemene Rekenkamer ja nee nee ja ja ja In gebruik Nationaal + + - - nee Dit toetsingskader is een instrument dat aandacht besteedt aan de relevante perspectieven op algoritmes. Met een vertaling van normenkaders en richtlijnen naar verschillende aspecten waarop algoritmes kunnen worden getoetst. Een instrument dat bovendien rekening houdt met de risico\u2019s en de onderzoeksvragen die in een toetsingskader aan bod moeten komen. - Baseline Informatiebeveiliging Overheid Wet- en regelgeving 2018 Binnenlandse Zaken ja nee nee ja nee nee In gebruik Nationaal - - + - ja De Baseline Informatiebeveiliging Overheid (BIO) is het basisnormenkader voor informatiebeveiliging binnen alle overheidslagen (Rijk, gemeenten, provincies en waterschappen). + Framework for Meaningful Engagement Handleiking/leidraad 2023 Action Coalition on Civic Engagement for AI (Denemarken) ja nee ja ja ja ja In gebruik Internationaal + \u00b1 - + nee Dit kader is gecre\u00eberd om iedereen die producten of diensten ontwerpt met behulp van AI, machine learning of op algoritme-gebaseerde gegegevensanalyse in staat te stellen belanghebbenden bij dat proces te betrekken. \u00b1 Waarborgen Selectie-Instrumenten voor de Belastingdienst Handleiking/leidraad 2023 Belastingdienst ja nee nee ja nee nee Financi\u00ebn (Fin) In gebruik Nationaal + + \u00b1 - nee Een waarborgenkader voor selectie-instrumenten waarmee de rechtmatigheid en transparantie van de instrumenten (beter) gegarandeerd kunnen worden. + Modelbepalingen en toelichting voor verantwoord gebruik van algoritme door de overheid (contractvoorwaarden) Handleiking/leidraad 2022 Gemeente Amsterdam ja nee nee ja nee nee Gemeenten In gebruik Nationaal + + \u00b1 - nee + AI Impact Assessment Handleiking/leidraad 2022 Infrastructuur en Waterstaat ja nee nee ja ja ja In gebruik Nationaal \u00b1 - - + nee Het AI Impact Assessment (AIIA) is een hulpmiddel voor het maken van afwegingen bij het inzetten van kunstmatige intelligentie (artificial intelligence, AI) in een project. Het AIIA dient als instrument voor het gesprek en het vastleggen van het denkproces zodat onder andere de verantwoording, kwaliteit en reproduceerbaarheid worden vergroot. - Artificial Intelligence Impact Assessment Handleiking/leidraad 2018 ECP nee nee ja ja ja ja In gebruik Nationaal \u00b1 - - + nee De Artificial Intelligence Impact Assessment (AIIA) helpt bedrijven artificial intelligence verantwoord in te zetten, nu slimme algoritmes steeds vaker taken van mensen overnemen. Aan de hand van een stappenplan, bestaande uit acht stappen, maken bedrijven inzichtelijk welke juridische en ethische normen een rol spelen bij de ontwikkeling en inzet van AI-toepassingen, en welke afwegingen ten grondslag liggen aan keuzes en besluiten. - Data Protection Impact Assessment Impact Assessment 2018 Autoriteit Persoonsgegevens ja nee nee ja ja ja In gebruik Nationaal - - + - ja Is een organisatie van plan persoonsgegevens te verwerken, maar levert dat waarschijnlijk een hoog privacyrisico op? Dan is de organisatie verplicht eerst een 'data protection impact assessment' (DPIA) uit te voeren. Een DPIA is een instrument om vooraf de privacyrisico\u2019s van een gegevensverwerking in kaart te brengen. + The Fairness Handbook Handleiking/leidraad 2022 Gemeente Amsterdam ja nee nee ja ja ja In gebruik Nationaal + \u00b1 - \u00b1 nee The Fairness Handbook is uitgebracht door de gemeente Amsterdam om bias in algoritmische systemen te minimaliseren en fairness te maximaliseren. Het handboek legt uit hoe vooroordelen en andere problemen rondom fairness tijdens de ontwikkeling van algoritmes kunnen voorkomen en wat hieraan gedaan kan worden. - Ethics Guideline for Trustworthy AI Handleiking/leidraad 2019 EU High-Level Expert Group on AI ja nee nee ja ja ja In gebruik Internationaal \u00b1 + - - nee Deze richtlijnen, opgesteld door leden van de 'high level expert group on AI', hebben als doel gebruikers te begeleiden in het ontwikkelen van betrouwbare AI. Hiervoor worden drie domeinen belicht; juridisch, ethisch en robuustheid. - Norea Guiding Principles Trustworthy AI Investigations Handleiking/leidraad 2021 Norea Beroepsorganisatie van IT-auditors nee nee ja ja ja ja In gebruik Internationaal \u00b1 + - - nee -"},{"location":"levenscyclus/","title":"Levenscyclus","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Algoritmen en kunstmatige intelligentie zijn \u2018producten\u2019 die door overheidsinstellingen kunnen worden gebruikt om de uitvoering van wettelijke taken te ondersteunen. Deze producten doorlopen een zogenaamde levenscyclus. Een algoritme wordt ontwikkeld en na enige tijd van gebruik kan worden besloten het gebruik ervan te be\u00ebindigen. Een krachtig aspect van de \u2018algoritme levenscyclus\u2019 is dat de levenscyclus voor alle gevallen nagenoeg hetzelfde is. Daarmee is het bruikbaar als leidraad om relevante informatie te structureren en  te communiceren. Het is tegelijkertijd een brug tussen de technische kant van het product en de wereld van gebruikers. Om tot een wettige, ethisch verantwoorde en robuuste oplossing te komen zullen in elke fase van de algoritme levenscyclus specifieke handelingen of maatregelen moeten worden getroffen.  </p> <p></p>"},{"location":"levenscyclus/archiveren/","title":"Archiveren","text":"<p>Wanneer het AI-model niet langer nodig is of wordt vervangen door een verbeterde versie, wordt het gearchiveerd. Dit omvat het behouden van documentatie en eventuele relevante artefacten.</p>"},{"location":"levenscyclus/archiveren/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmen en aiVolgens de archiefwet moeten overheden informatie bewaren op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en ai, tot stand zijn gekomen informatie over en van algoritmen en ai moet daarom ook bewaard en vernietigd wordenProportionaliteit en subsidiariteitProportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterktBewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het ai-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periodeBewaartermijn voor gegenereerde logsAanbieders van ai-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplichtVerplicht risicobeheersysteem voor hoog-risico aiVoor ai-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de ai-systemen te waarborgen en mogelijke schade te voorkomen of te beperkenVerstrekking van informatie op verzoekAanbieders van ai-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de eu, zoals gekozen door de betrokken lidstaatRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming"},{"location":"levenscyclus/archiveren/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/","title":"Dataverkenning en datapreparatie","text":"<p>In deze fase worden relevante datasets geidentificeerd en genaliseerd om inziichten te krijgen. Daarna worden de gegevens verzameld, gereinigd en voorbereid voor gebruik.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#vereisten","title":"Vereisten","text":"VereisteUitlegVerbod op schenden auteursrechtenBepaalde vormen van algoritmen en ai worden ontwikkeld op basis van grote hoeveelheden data deze data wordt gebruikt voor het trainen en testen van algoritmen en ai het gebruiken van deze data mag geen inbreuk maken op auteursrechten van diegene die deze rechten heeft ook de gegenereerde output van algoritmen en ai mag geen inbreuk maken op deze rechtenAutomatische logregistratie voor hoog-risico aiAi-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren, wat vaak wordt aangeduid als \"logs\" deze logs bieden een traceerbaarheidsmechanisme waarmee exploitanten en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken het doel van deze registratie is om de transparantie en verantwoordingsplicht van ai-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetertProportionaliteit en subsidiariteitProportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterktBeperkte bewaartermijn van persoonsgegevensGegevens mogen niet langer worden bewaard dan nodig is voor het beoogde doel, zoals vereist door het principe van opslagbeperking deze maatregel waarborgt dat persoonsgegevens niet langer worden bewaard dan strikt noodzakelijk is, waardoor risico's met betrekking tot gegevensbescherming worden verminderd en de privacy van individuen wordt beschermd het naleven van de opslagbeperking draagt bij aan een effici\u00ebnte gegevensverwerking en bevordert het vertrouwen van individuen in hoe hun gegevens worden beheerdBeschermen van persoonsgegevensVoor de ontwikkeling en gebruik van algoritmen en ai is dat nodig deze data kan persoonsgegevens bevatten deze persoonsgegevens moeten worden beschermd de organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of ai-systeem voldoende te beschermen hierbij kan worden gedacht aan dataminimalisatie, het pseudonomiseren of aggregeren van persoonsgegevens per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijnBescherming van kwetsbare groepenBescherm de privacy van kinderen en kwetsbare groepen door ervoor te zorgen dat de verwerking van hun persoonsgegevens voldoet aan de algemene verordening gegevensbescherming (avg) dit omvat het nemen van passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens veilig en rechtmatig is, en dat de rechten van deze groepen worden gerespecteerd het waarborgen van privacy voor deze groepen draagt bij aan een veilige en vertrouwde online omgeving waarin hun gegevens worden beschermdBeschrijven en toewijzen van verantwoordelijkhedenBij het verwerken van persoonsgegevens voor algoritmen en ai-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn de verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergrotenVerbod op schenden databankenrechtenHet databankenrecht beschermt tegen kopi\u00ebren of oneigenlijk gebruik van gegevens in een databank degene die een substanti\u00eble financi\u00eble investering heeft verricht om de databank tot stand te brengen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken voor het ontwikkelen van algoritme en ai is data nodig de data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databankDocumentatie beoordeling niet-hoog-risico aiEen aanbieder die oordeelt dat een ai-systeem geen hoog risico vormt, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem en voldoet aan de registratievereisten op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordelingNoneNoneGeb/dpia verplicht bij hoog risicoEen gegevensbeschermingseffectbeoordeling (geb) of data protection impact assessment (dpia) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgdGerichte doelverzamelingPersoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerkingPrivacyrechtenMensen hebben het recht om hun privacyrechten uit te oefenen door een beroep te doen op verschillende wettelijke bepalingen, zoals het recht op inzage, correctie, verwijdering en bezwaar tegen de verwerking van hun persoonsgegevens dit betekent dat individuen controle hebben over hoe hun gegevens worden gebruikt en kunnen verzoeken om toegang tot hun gegevens of om wijzigingen aan te brengen indien nodig het kunnen uitoefenen van privacyrechten is essentieel voor het beschermen van de privacy van individuen en het waarborgen van transparantie en controle over hun persoonsgegevensJuistheid en actualiteit van gegevensDe te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevensRecht op uitleg ai-besluitenElke persoon die wordt be\u00efnvloed door een besluit dat is genomen op basis van de output van een ai-systeem met een hoog risico, heeft het recht om van de exploitant een duidelijke uitleg te krijgen over de rol van het systeem in de besluitvorming en de belangrijkste aspecten van het besluit dit geldt voor besluiten die aanzienlijke gevolgen hebben voor de persoon, zoals die hun gezondheid, veiligheid of grondrechten be\u00efnvloeden deze maatregel waarborgt transparantie en verantwoordelijkheid bij het gebruik van ai in besluitvormingsprocessen, en biedt individuen de mogelijkheid om de beslissingen die hen be\u00efnvloeden te begrijpen en te betwistenKwaliteitscriteria voor data van hoog-risico aiAi-systemen met een hoog risico die data gebruiken voor het trainen van ai-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het ai-systeem waarborgtBeoordeling van grondrechten door exploitantenVoordat een ai-systeem met een hoog risico in gebruik wordt genomen, moeten publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde ai-systemen, een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben deze evaluatie is bedoeld om potenti\u00eble risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van ai-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiekVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatOntwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAi-systemen met een hoog risico worden zorgvuldig ontworpen en ontwikkeld om een hoog niveau van nauwkeurigheid, robuustheid en cyberbeveiliging te bieden dit garandeert consistente prestaties gedurende hun levensduur en minimaliseert risico's met betrekking tot deze aspecten, waardoor de betrouwbaarheid en veiligheid van het systeem worden gewaarborgdPersoonsgegevens verzamelen voor specifieke doeleindenPersoonsgegevens mogen alleen verzameld worden voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden en mogen daarna niet op een manier worden verwerkt die niet verenigbaar is met deze doeleindenPersoonsgegeven worden rechtmatig, behoorlijk en transparant verwerktDe verwerking van persoonsgegevens moet eerlijk en rechtmatig plaatsvinden, wat betekent dat het voldoet aan de principes van rechtmatigheid, behoorlijkheid en transparantie dit houdt in dat de verwerking gebaseerd moet zijn op een van de wettelijke grondslagen die zijn vastgesteld in de algemene verordening gegevensbescherming (avg)Privacy bij ontwerpGegevensbescherming door ontwerp en standaardinstellingen houdt in dat privacy- en gegevensbescherming vanaf het begin worden ge\u00efntegreerd in de ontwikkeling van systemen en processen door al bij het ontwerp rekening te houden met privacyaspecten en door standaardinstellingen die de privacy bevorderen, wordt de bescherming van persoonsgegevens versterkt deze aanpak zorgt ervoor dat privacy overwegingen een integraal onderdeel zijn van alle aspecten van gegevensverwerking en draagt bij aan het vertrouwen van individuen in de veilige omgang met hun gegevensEenieder heeft recht op toegang tot publieke informatieBij het ontwikkelen en gebruiken van algoritmen en ai kunnen documenten en kan publieke informatie ontstaan die (op verzoek) in aanmerkingen komen voor openbaarmaking het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat er kunnen uitsluitingsgronden bestaan voor het openbaarmaking van documentenTechnische documentatie voor hoog-risico aiDe technische documentatie van een ai-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen de documentatie bevat ten minste de elementen zoals uiteengezet in bijlage ivToezichtmogelijkheden voor gebruikersAi-systemen met een hoog risico moeten zodanig worden ontworpen en ontwikkeld dat natuurlijke personen effectief toezicht kunnen houden op hun werking tijdens gebruik dit omvat het implementeren van passende mens-machine-interface-instrumenten die gebruikers in staat stellen om het systeem te begrijpen en te controleren het doel is om gebruikers in staat te stellen een actieve rol te spelen bij het monitoren en beheren van de werking van deze systemen, waardoor het vertrouwen en de veiligheid worden vergrootNoneNoneVerplicht risicobeheersysteem voor hoog-risico aiVoor ai-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de ai-systemen te waarborgen en mogelijke schade te voorkomen of te beperkenVerstrekking van informatie op verzoekAanbieders van ai-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de eu, zoals gekozen door de betrokken lidstaatWettelijke verwerking van gevoelige gegevensHet algoritme mag alleen persoonsgegevens verwerken die onder wettelijke uitzonderingen verwerkt mogen worden deze beperkingen zijn bedoeld om de privacy van individuen te beschermen en ervoor te zorgen dat gevoelige informatie niet onrechtmatig wordt verwerkt door algoritmenRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/implementatie/","title":"Implementatie","text":"<p>In deze fase wordt het AI-model in de praktijk gebracht en ge\u00efntegreerd in het bedrijfsproces. Het wordt operationeel en begint te werken met echte gegevens.</p>"},{"location":"levenscyclus/implementatie/#vereisten","title":"Vereisten","text":"VereisteUitlegImpactvolle algoritmen en ai worden gepubliceerd in het algoritmeregisterHet publiceren van impactvolle algoritmen en ai draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmen en ai worden gebruikt door de overheid het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmen en hoge risico ai publiceren in het algoritmeregisterDe archiefwet is ook van toepassing op algoritmen en aiVolgens de archiefwet moeten overheden informatie bewaren op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en ai, tot stand zijn gekomen informatie over en van algoritmen en ai moet daarom ook bewaard en vernietigd wordenProportionaliteit en subsidiariteitProportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterktInformatie en informatiesystemen van de overheid moet worden beveiligdInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen in nederland is besloten dat overheidsinstellingen de baseline informatiebeveiliging overheid dienen toe te passen over hun informatie en informatiesystemen de bio beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn algoritmen en ai-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de bio op van toepassing is het is van belang om algoritmische toepassingen en ai-systemen op de juiste manier te beveiligenKlachten indienen bij markttoezichtautoriteitNaast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en aiMaatregelen van exploitanten voor gebruikExploitanten van ai-systemen met een hoog risico moeten geschikte maatregelen nemen om ervoor te zorgen dat ze deze systemen gebruiken volgens de bijgevoegde instructies dit is in lijn met de voorschriften van de verordeningMelden van ernstige incidentenAanbieders van ai-systemen met een hoog risico die binnen de eu worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze ai-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek het doel is om de veiligheid en betrouwbaarheid van ai-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliserenVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatEenieder heeft recht op toegang tot publieke informatieBij het ontwikkelen en gebruiken van algoritmen en ai kunnen documenten en kan publieke informatie ontstaan die (op verzoek) in aanmerkingen komen voor openbaarmaking het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat er kunnen uitsluitingsgronden bestaan voor het openbaarmaking van documentenTechnische documentatie voor hoog-risico aiDe technische documentatie van een ai-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen de documentatie bevat ten minste de elementen zoals uiteengezet in bijlage ivToezichtmogelijkheden voor gebruikersAi-systemen met een hoog risico moeten zodanig worden ontworpen en ontwikkeld dat natuurlijke personen effectief toezicht kunnen houden op hun werking tijdens gebruik dit omvat het implementeren van passende mens-machine-interface-instrumenten die gebruikers in staat stellen om het systeem te begrijpen en te controleren het doel is om gebruikers in staat te stellen een actieve rol te spelen bij het monitoren en beheren van de werking van deze systemen, waardoor het vertrouwen en de veiligheid worden vergrootTransparantie in ontwerp voor hoog-risico aiAi-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat exploitanten de output van het systeem kunnen begrijpen en adequaat kunnen gebruiken dit zorgt ervoor dat de aanbieders en exploitanten kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerdNoneNoneVerplicht risicobeheersysteem voor hoog-risico aiVoor ai-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de ai-systemen te waarborgen en mogelijke schade te voorkomen of te beperkenVerstrekking van informatie op verzoekAanbieders van ai-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de eu, zoals gekozen door de betrokken lidstaatRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming"},{"location":"levenscyclus/implementatie/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/monitoren/","title":"Monitoren","text":"<p>Het AI-model wordt voortdurend gemonitord om ervoor te zorgen dat het blijft presteren zoals verwacht. Eventuele afwijkingen of degradatie van prestaties worden ge\u00efdentificeerd en aangepakt.</p>"},{"location":"levenscyclus/monitoren/#vereisten","title":"Vereisten","text":"VereisteUitlegImpactvolle algoritmen en ai worden gepubliceerd in het algoritmeregisterHet publiceren van impactvolle algoritmen en ai draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmen en ai worden gebruikt door de overheid het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmen en hoge risico ai publiceren in het algoritmeregisterProportionaliteit en subsidiariteitProportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterktInformatie en informatiesystemen van de overheid moet worden beveiligdInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen in nederland is besloten dat overheidsinstellingen de baseline informatiebeveiliging overheid dienen toe te passen over hun informatie en informatiesystemen de bio beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn algoritmen en ai-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de bio op van toepassing is het is van belang om algoritmische toepassingen en ai-systemen op de juiste manier te beveiligenBewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het ai-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periodeBewaartermijn voor gegenereerde logsAanbieders van ai-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplichtCorrigerende maatregelen voor non-conforme aiAanbieders van ai-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem ze moeten ook alle relevante partijen, zoals distributeurs, exploitanten en importeurs, op de hoogte stellen van deze maatregelenKlachten indienen bij markttoezichtautoriteitNaast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en aiMelden van ernstige incidentenAanbieders van ai-systemen met een hoog risico die binnen de eu worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze ai-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek het doel is om de veiligheid en betrouwbaarheid van ai-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliserenMonitoring na het in de handel brengenAanbieders moeten een monitoringssysteem na het in de handel brengen opzetten en documenteren, passend bij de aard van de ai-technologie\u00ebn en de risico's van het betreffende ai-systeem met een hoog risico dit monitoringssysteem moet proportioneel zijn aan de complexiteit en potenti\u00eble impact van het ai-systeemVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatKlachtrecht downstreamaanbiedersDownstreamaanbieders hebben het recht om een klacht in te dienen bij het ai-bureau in het geval van een inbreuk op deze verordening dit biedt hen een mechanisme om actie te ondernemen bij schendingen van de regels met betrekking tot ai-systemen het ai-bureau kan dan passende maatregelen nemen om de naleving van de verordening te handhaven en eventuele geschillen op te lossenRecht op niet geautomatiseerd besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffenEenieder heeft recht op toegang tot publieke informatieBij het ontwikkelen en gebruiken van algoritmen en ai kunnen documenten en kan publieke informatie ontstaan die (op verzoek) in aanmerkingen komen voor openbaarmaking het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat er kunnen uitsluitingsgronden bestaan voor het openbaarmaking van documentenToepassing richtlijn (eu) 2019/1937Richtlijn (eu) 2019/1937 is van toepassing op het melden van inbreuken op deze verordening en op de bescherming van personen die deze inbreuken melden het biedt een kader voor het veilig en vertrouwelijk melden van schendingen van de verordening, terwijl het de melders beschermt tegen represailles of vervolging deze richtlijn bevordert transparantie en verantwoording binnen organisaties en draagt bij aan een cultuur van naleving en integriteitTechnische documentatie voor hoog-risico aiDe technische documentatie van een ai-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen de documentatie bevat ten minste de elementen zoals uiteengezet in bijlage ivToezichtmogelijkheden voor gebruikersAi-systemen met een hoog risico moeten zodanig worden ontworpen en ontwikkeld dat natuurlijke personen effectief toezicht kunnen houden op hun werking tijdens gebruik dit omvat het implementeren van passende mens-machine-interface-instrumenten die gebruikers in staat stellen om het systeem te begrijpen en te controleren het doel is om gebruikers in staat te stellen een actieve rol te spelen bij het monitoren en beheren van de werking van deze systemen, waardoor het vertrouwen en de veiligheid worden vergrootTransparantie in ontwerp voor hoog-risico aiAi-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat exploitanten de output van het systeem kunnen begrijpen en adequaat kunnen gebruiken dit zorgt ervoor dat de aanbieders en exploitanten kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerdNoneNoneVerplicht risicobeheersysteem voor hoog-risico aiVoor ai-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de ai-systemen te waarborgen en mogelijke schade te voorkomen of te beperkenVerstrekking van informatie op verzoekAanbieders van ai-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de eu, zoals gekozen door de betrokken lidstaatRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming"},{"location":"levenscyclus/monitoren/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/ontwerp/","title":"Ontwerp","text":"<p>Hier wordt het conceptuele ontwerp van het AI-systeem gemaakt. Dit omvat het bepalen van de architectuur, algoritmen en benodigde middelen voor de implementatie.</p>"},{"location":"levenscyclus/ontwerp/#vereisten","title":"Vereisten","text":"VereisteUitlegVerbod op schenden auteursrechtenBepaalde vormen van algoritmen en ai worden ontwikkeld op basis van grote hoeveelheden data deze data wordt gebruikt voor het trainen en testen van algoritmen en ai het gebruiken van deze data mag geen inbreuk maken op auteursrechten van diegene die deze rechten heeft ook de gegenereerde output van algoritmen en ai mag geen inbreuk maken op deze rechtenProportionaliteit en subsidiariteitProportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterktBeperkte bewaartermijn van persoonsgegevensGegevens mogen niet langer worden bewaard dan nodig is voor het beoogde doel, zoals vereist door het principe van opslagbeperking deze maatregel waarborgt dat persoonsgegevens niet langer worden bewaard dan strikt noodzakelijk is, waardoor risico's met betrekking tot gegevensbescherming worden verminderd en de privacy van individuen wordt beschermd het naleven van de opslagbeperking draagt bij aan een effici\u00ebnte gegevensverwerking en bevordert het vertrouwen van individuen in hoe hun gegevens worden beheerdBescherming van kwetsbare groepenBescherm de privacy van kinderen en kwetsbare groepen door ervoor te zorgen dat de verwerking van hun persoonsgegevens voldoet aan de algemene verordening gegevensbescherming (avg) dit omvat het nemen van passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens veilig en rechtmatig is, en dat de rechten van deze groepen worden gerespecteerd het waarborgen van privacy voor deze groepen draagt bij aan een veilige en vertrouwde online omgeving waarin hun gegevens worden beschermdBeschrijven en toewijzen van verantwoordelijkhedenBij het verwerken van persoonsgegevens voor algoritmen en ai-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn de verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergrotenInformatie en informatiesystemen van de overheid moet worden beveiligdInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen in nederland is besloten dat overheidsinstellingen de baseline informatiebeveiliging overheid dienen toe te passen over hun informatie en informatiesystemen de bio beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn algoritmen en ai-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de bio op van toepassing is het is van belang om algoritmische toepassingen en ai-systemen op de juiste manier te beveiligenBevorder ai-geletterdheid personeelAanbieders en exploitanten van ai-systemen nemen maatregelen om ervoor te zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van ai dit omvat het overwegen van technische kennis, ervaring, onderwijs en opleiding van individuen, evenals de context waarin de ai-systemen worden gebruikt en de gebruikers van deze systemen het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van ai en het minimaliseren van risico'sBewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het ai-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periodeBewaartermijn voor gegenereerde logsAanbieders van ai-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplichtCorrigerende maatregelen voor non-conforme aiAanbieders van ai-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem ze moeten ook alle relevante partijen, zoals distributeurs, exploitanten en importeurs, op de hoogte stellen van deze maatregelenVerbod op schenden databankenrechtenHet databankenrecht beschermt tegen kopi\u00ebren of oneigenlijk gebruik van gegevens in een databank degene die een substanti\u00eble financi\u00eble investering heeft verricht om de databank tot stand te brengen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken voor het ontwikkelen van algoritme en ai is data nodig de data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databankDocumentatie beoordeling niet-hoog-risico aiEen aanbieder die oordeelt dat een ai-systeem geen hoog risico vormt, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem en voldoet aan de registratievereisten op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordelingNoneNoneGeb/dpia verplicht bij hoog risicoEen gegevensbeschermingseffectbeoordeling (geb) of data protection impact assessment (dpia) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgdGerichte doelverzamelingPersoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerkingPrivacyrechtenMensen hebben het recht om hun privacyrechten uit te oefenen door een beroep te doen op verschillende wettelijke bepalingen, zoals het recht op inzage, correctie, verwijdering en bezwaar tegen de verwerking van hun persoonsgegevens dit betekent dat individuen controle hebben over hoe hun gegevens worden gebruikt en kunnen verzoeken om toegang tot hun gegevens of om wijzigingen aan te brengen indien nodig het kunnen uitoefenen van privacyrechten is essentieel voor het beschermen van de privacy van individuen en het waarborgen van transparantie en controle over hun persoonsgegevensJuistheid en actualiteit van gegevensDe te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevensRecht op uitleg ai-besluitenElke persoon die wordt be\u00efnvloed door een besluit dat is genomen op basis van de output van een ai-systeem met een hoog risico, heeft het recht om van de exploitant een duidelijke uitleg te krijgen over de rol van het systeem in de besluitvorming en de belangrijkste aspecten van het besluit dit geldt voor besluiten die aanzienlijke gevolgen hebben voor de persoon, zoals die hun gezondheid, veiligheid of grondrechten be\u00efnvloeden deze maatregel waarborgt transparantie en verantwoordelijkheid bij het gebruik van ai in besluitvormingsprocessen, en biedt individuen de mogelijkheid om de beslissingen die hen be\u00efnvloeden te begrijpen en te betwistenKwaliteitsbeheersysteem voor hoog-risico aiAanbieders van ai-systemen met een hoog risico moeten een kwaliteitsbeheersysteem implementeren om te garanderen dat ze voldoen aan de verordening dit systeem omvat gedocumenteerde beleidslijnen, procedures en instructies, en behandelt belangrijke aspecten zoals aangegeven in artikel 17Kwaliteitscriteria voor data van hoog-risico aiAi-systemen met een hoog risico die data gebruiken voor het trainen van ai-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het ai-systeem waarborgtBeoordeling van grondrechten door exploitantenVoordat een ai-systeem met een hoog risico in gebruik wordt genomen, moeten publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde ai-systemen, een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben deze evaluatie is bedoeld om potenti\u00eble risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van ai-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiekVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatOntwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAi-systemen met een hoog risico worden zorgvuldig ontworpen en ontwikkeld om een hoog niveau van nauwkeurigheid, robuustheid en cyberbeveiliging te bieden dit garandeert consistente prestaties gedurende hun levensduur en minimaliseert risico's met betrekking tot deze aspecten, waardoor de betrouwbaarheid en veiligheid van het systeem worden gewaarborgdPersoonsgegevens verzamelen voor specifieke doeleindenPersoonsgegevens mogen alleen verzameld worden voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden en mogen daarna niet op een manier worden verwerkt die niet verenigbaar is met deze doeleindenPersoonsgegeven worden rechtmatig, behoorlijk en transparant verwerktDe verwerking van persoonsgegevens moet eerlijk en rechtmatig plaatsvinden, wat betekent dat het voldoet aan de principes van rechtmatigheid, behoorlijkheid en transparantie dit houdt in dat de verwerking gebaseerd moet zijn op een van de wettelijke grondslagen die zijn vastgesteld in de algemene verordening gegevensbescherming (avg)Privacy bij ontwerpGegevensbescherming door ontwerp en standaardinstellingen houdt in dat privacy- en gegevensbescherming vanaf het begin worden ge\u00efntegreerd in de ontwikkeling van systemen en processen door al bij het ontwerp rekening te houden met privacyaspecten en door standaardinstellingen die de privacy bevorderen, wordt de bescherming van persoonsgegevens versterkt deze aanpak zorgt ervoor dat privacy overwegingen een integraal onderdeel zijn van alle aspecten van gegevensverwerking en draagt bij aan het vertrouwen van individuen in de veilige omgang met hun gegevensRecht op niet geautomatiseerd besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffenEenieder heeft recht op toegang tot publieke informatieBij het ontwikkelen en gebruiken van algoritmen en ai kunnen documenten en kan publieke informatie ontstaan die (op verzoek) in aanmerkingen komen voor openbaarmaking het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat er kunnen uitsluitingsgronden bestaan voor het openbaarmaking van documentenToepassing richtlijn (eu) 2019/1937Richtlijn (eu) 2019/1937 is van toepassing op het melden van inbreuken op deze verordening en op de bescherming van personen die deze inbreuken melden het biedt een kader voor het veilig en vertrouwelijk melden van schendingen van de verordening, terwijl het de melders beschermt tegen represailles of vervolging deze richtlijn bevordert transparantie en verantwoording binnen organisaties en draagt bij aan een cultuur van naleving en integriteitRisicobeoordeling voor jongeren en kwetsbarenBij het beheer van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het ai-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepenTechnische documentatie voor hoog-risico aiDe technische documentatie van een ai-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen de documentatie bevat ten minste de elementen zoals uiteengezet in bijlage ivToezichtmogelijkheden voor gebruikersAi-systemen met een hoog risico moeten zodanig worden ontworpen en ontwikkeld dat natuurlijke personen effectief toezicht kunnen houden op hun werking tijdens gebruik dit omvat het implementeren van passende mens-machine-interface-instrumenten die gebruikers in staat stellen om het systeem te begrijpen en te controleren het doel is om gebruikers in staat te stellen een actieve rol te spelen bij het monitoren en beheren van de werking van deze systemen, waardoor het vertrouwen en de veiligheid worden vergrootTransparantie in ontwerp voor hoog-risico aiAi-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat exploitanten de output van het systeem kunnen begrijpen en adequaat kunnen gebruiken dit zorgt ervoor dat de aanbieders en exploitanten kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerdNoneNoneNoneVoor zover strikt noodzakelijk voor het detecteren en corrigeren van vooringenomenheid met betrekking tot ai-systemen met een hoog risico, mogen aanbieders van dergelijke systemen uitzonderlijk speciale categorie\u00ebn persoonsgegevens verwerken deze verwerking moet gepaard gaan met passende waarborgen voor de fundamentele rechten en vrijheden van natuurlijke personenVerplicht risicobeheersysteem voor hoog-risico aiVoor ai-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de ai-systemen te waarborgen en mogelijke schade te voorkomen of te beperkenVerstrekking van informatie op verzoekAanbieders van ai-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de eu, zoals gekozen door de betrokken lidstaatWettelijke verwerking van gevoelige gegevensHet algoritme mag alleen persoonsgegevens verwerken die onder wettelijke uitzonderingen verwerkt mogen worden deze beperkingen zijn bedoeld om de privacy van individuen te beschermen en ervoor te zorgen dat gevoelige informatie niet onrechtmatig wordt verwerkt door algoritmenRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming"},{"location":"levenscyclus/ontwerp/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/ontwikkelen/","title":"Ontwikkelen","text":"<p>Dit is de fase waarin het AI-model of algoritme wordt gebouwd. Als het gaat om AI-modellen, omvat het trainen van modellen met behulp van de voorbereide gegevens.</p>"},{"location":"levenscyclus/ontwikkelen/#vereisten","title":"Vereisten","text":"VereisteUitlegImpactvolle algoritmen en ai worden gepubliceerd in het algoritmeregisterHet publiceren van impactvolle algoritmen en ai draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmen en ai worden gebruikt door de overheid het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmen en hoge risico ai publiceren in het algoritmeregisterAutomatische logregistratie voor hoog-risico aiAi-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren, wat vaak wordt aangeduid als \"logs\" deze logs bieden een traceerbaarheidsmechanisme waarmee exploitanten en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken het doel van deze registratie is om de transparantie en verantwoordingsplicht van ai-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetertProportionaliteit en subsidiariteitProportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterktBeperkte bewaartermijn van persoonsgegevensGegevens mogen niet langer worden bewaard dan nodig is voor het beoogde doel, zoals vereist door het principe van opslagbeperking deze maatregel waarborgt dat persoonsgegevens niet langer worden bewaard dan strikt noodzakelijk is, waardoor risico's met betrekking tot gegevensbescherming worden verminderd en de privacy van individuen wordt beschermd het naleven van de opslagbeperking draagt bij aan een effici\u00ebnte gegevensverwerking en bevordert het vertrouwen van individuen in hoe hun gegevens worden beheerdBeschermen van persoonsgegevensVoor de ontwikkeling en gebruik van algoritmen en ai is dat nodig deze data kan persoonsgegevens bevatten deze persoonsgegevens moeten worden beschermd de organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of ai-systeem voldoende te beschermen hierbij kan worden gedacht aan dataminimalisatie, het pseudonomiseren of aggregeren van persoonsgegevens per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijnBescherming van kwetsbare groepenBescherm de privacy van kinderen en kwetsbare groepen door ervoor te zorgen dat de verwerking van hun persoonsgegevens voldoet aan de algemene verordening gegevensbescherming (avg) dit omvat het nemen van passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens veilig en rechtmatig is, en dat de rechten van deze groepen worden gerespecteerd het waarborgen van privacy voor deze groepen draagt bij aan een veilige en vertrouwde online omgeving waarin hun gegevens worden beschermdBeschrijven en toewijzen van verantwoordelijkhedenBij het verwerken van persoonsgegevens voor algoritmen en ai-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn de verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergrotenBewaartermijn voor gegenereerde logsAanbieders van ai-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplichtCorrigerende maatregelen voor non-conforme aiAanbieders van ai-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem ze moeten ook alle relevante partijen, zoals distributeurs, exploitanten en importeurs, op de hoogte stellen van deze maatregelenDocumentatie beoordeling niet-hoog-risico aiEen aanbieder die oordeelt dat een ai-systeem geen hoog risico vormt, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem en voldoet aan de registratievereisten op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordelingGeb/dpia verplicht bij hoog risicoEen gegevensbeschermingseffectbeoordeling (geb) of data protection impact assessment (dpia) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgdGerichte doelverzamelingPersoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerkingPrivacyrechtenMensen hebben het recht om hun privacyrechten uit te oefenen door een beroep te doen op verschillende wettelijke bepalingen, zoals het recht op inzage, correctie, verwijdering en bezwaar tegen de verwerking van hun persoonsgegevens dit betekent dat individuen controle hebben over hoe hun gegevens worden gebruikt en kunnen verzoeken om toegang tot hun gegevens of om wijzigingen aan te brengen indien nodig het kunnen uitoefenen van privacyrechten is essentieel voor het beschermen van de privacy van individuen en het waarborgen van transparantie en controle over hun persoonsgegevensJuistheid en actualiteit van gegevensDe te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevensRecht op uitleg ai-besluitenElke persoon die wordt be\u00efnvloed door een besluit dat is genomen op basis van de output van een ai-systeem met een hoog risico, heeft het recht om van de exploitant een duidelijke uitleg te krijgen over de rol van het systeem in de besluitvorming en de belangrijkste aspecten van het besluit dit geldt voor besluiten die aanzienlijke gevolgen hebben voor de persoon, zoals die hun gezondheid, veiligheid of grondrechten be\u00efnvloeden deze maatregel waarborgt transparantie en verantwoordelijkheid bij het gebruik van ai in besluitvormingsprocessen, en biedt individuen de mogelijkheid om de beslissingen die hen be\u00efnvloeden te begrijpen en te betwistenBeoordeling van grondrechten door exploitantenVoordat een ai-systeem met een hoog risico in gebruik wordt genomen, moeten publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde ai-systemen, een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben deze evaluatie is bedoeld om potenti\u00eble risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van ai-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiekOntwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAi-systemen met een hoog risico worden zorgvuldig ontworpen en ontwikkeld om een hoog niveau van nauwkeurigheid, robuustheid en cyberbeveiliging te bieden dit garandeert consistente prestaties gedurende hun levensduur en minimaliseert risico's met betrekking tot deze aspecten, waardoor de betrouwbaarheid en veiligheid van het systeem worden gewaarborgdPersoonsgegevens verzamelen voor specifieke doeleindenPersoonsgegevens mogen alleen verzameld worden voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden en mogen daarna niet op een manier worden verwerkt die niet verenigbaar is met deze doeleindenPrivacy bij ontwerpGegevensbescherming door ontwerp en standaardinstellingen houdt in dat privacy- en gegevensbescherming vanaf het begin worden ge\u00efntegreerd in de ontwikkeling van systemen en processen door al bij het ontwerp rekening te houden met privacyaspecten en door standaardinstellingen die de privacy bevorderen, wordt de bescherming van persoonsgegevens versterkt deze aanpak zorgt ervoor dat privacy overwegingen een integraal onderdeel zijn van alle aspecten van gegevensverwerking en draagt bij aan het vertrouwen van individuen in de veilige omgang met hun gegevensRecht op niet geautomatiseerd besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffenEenieder heeft recht op toegang tot publieke informatieBij het ontwikkelen en gebruiken van algoritmen en ai kunnen documenten en kan publieke informatie ontstaan die (op verzoek) in aanmerkingen komen voor openbaarmaking het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat er kunnen uitsluitingsgronden bestaan voor het openbaarmaking van documentenToepassing richtlijn (eu) 2019/1937Richtlijn (eu) 2019/1937 is van toepassing op het melden van inbreuken op deze verordening en op de bescherming van personen die deze inbreuken melden het biedt een kader voor het veilig en vertrouwelijk melden van schendingen van de verordening, terwijl het de melders beschermt tegen represailles of vervolging deze richtlijn bevordert transparantie en verantwoording binnen organisaties en draagt bij aan een cultuur van naleving en integriteitRisicobeoordeling voor jongeren en kwetsbarenBij het beheer van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het ai-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepenTechnische documentatie voor hoog-risico aiDe technische documentatie van een ai-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen de documentatie bevat ten minste de elementen zoals uiteengezet in bijlage ivToezichtmogelijkheden voor gebruikersAi-systemen met een hoog risico moeten zodanig worden ontworpen en ontwikkeld dat natuurlijke personen effectief toezicht kunnen houden op hun werking tijdens gebruik dit omvat het implementeren van passende mens-machine-interface-instrumenten die gebruikers in staat stellen om het systeem te begrijpen en te controleren het doel is om gebruikers in staat te stellen een actieve rol te spelen bij het monitoren en beheren van de werking van deze systemen, waardoor het vertrouwen en de veiligheid worden vergrootTransparantie in ontwerp voor hoog-risico aiAi-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat exploitanten de output van het systeem kunnen begrijpen en adequaat kunnen gebruiken dit zorgt ervoor dat de aanbieders en exploitanten kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerdNoneNoneVerplicht risicobeheersysteem voor hoog-risico aiVoor ai-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de ai-systemen te waarborgen en mogelijke schade te voorkomen of te beperkenVerstrekking van informatie op verzoekAanbieders van ai-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de eu, zoals gekozen door de betrokken lidstaatRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming"},{"location":"levenscyclus/ontwikkelen/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/probleemanalyse/","title":"Probleemanalyse","text":"<p>In deze fase wordt het probleem gedefinieerd dat moet worden opgelost. Het omvat het begrijpen van de vereisten, doelstellingen en beperkingen van het probleem.</p>"},{"location":"levenscyclus/probleemanalyse/#vereisten","title":"Vereisten","text":"VereisteUitlegProportionaliteit en subsidiariteitProportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterktBevorder ai-geletterdheid personeelAanbieders en exploitanten van ai-systemen nemen maatregelen om ervoor te zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van ai dit omvat het overwegen van technische kennis, ervaring, onderwijs en opleiding van individuen, evenals de context waarin de ai-systemen worden gebruikt en de gebruikers van deze systemen het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van ai en het minimaliseren van risico'sNoneNoneGerichte doelverzamelingPersoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerkingJuistheid en actualiteit van gegevensDe te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevensKwaliteitsbeheersysteem voor hoog-risico aiAanbieders van ai-systemen met een hoog risico moeten een kwaliteitsbeheersysteem implementeren om te garanderen dat ze voldoen aan de verordening dit systeem omvat gedocumenteerde beleidslijnen, procedures en instructies, en behandelt belangrijke aspecten zoals aangegeven in artikel 17Verbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatPersoonsgegeven worden rechtmatig, behoorlijk en transparant verwerktDe verwerking van persoonsgegevens moet eerlijk en rechtmatig plaatsvinden, wat betekent dat het voldoet aan de principes van rechtmatigheid, behoorlijkheid en transparantie dit houdt in dat de verwerking gebaseerd moet zijn op een van de wettelijke grondslagen die zijn vastgesteld in de algemene verordening gegevensbescherming (avg)Risicobeoordeling voor jongeren en kwetsbarenBij het beheer van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het ai-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepenNoneVoor zover strikt noodzakelijk voor het detecteren en corrigeren van vooringenomenheid met betrekking tot ai-systemen met een hoog risico, mogen aanbieders van dergelijke systemen uitzonderlijk speciale categorie\u00ebn persoonsgegevens verwerken deze verwerking moet gepaard gaan met passende waarborgen voor de fundamentele rechten en vrijheden van natuurlijke personenVerplicht risicobeheersysteem voor hoog-risico aiVoor ai-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de ai-systemen te waarborgen en mogelijke schade te voorkomen of te beperkenVerstrekking van informatie op verzoekAanbieders van ai-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de eu, zoals gekozen door de betrokken lidstaatRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming"},{"location":"levenscyclus/probleemanalyse/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/validatie/","title":"Validatie","text":"<p>Nadat het model is ontwikkeld, wordt het gevalideerd om ervoor te zorgen dat het goed presteert op nieuwe, niet eerder geziene gegevens. Dit omvat het evalueren van de nauwkeurigheid en prestaties van het model. Validatie is een interatief proces dat plaatsvindt op verschillende momenten van de levenscyclus.</p>"},{"location":"levenscyclus/validatie/#vereisten","title":"Vereisten","text":"VereisteUitlegImpactvolle algoritmen en ai worden gepubliceerd in het algoritmeregisterHet publiceren van impactvolle algoritmen en ai draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmen en ai worden gebruikt door de overheid het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmen en hoge risico ai publiceren in het algoritmeregisterProportionaliteit en subsidiariteitProportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterktBeschrijven en toewijzen van verantwoordelijkhedenBij het verwerken van persoonsgegevens voor algoritmen en ai-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn de verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergrotenGeb/dpia verplicht bij hoog risicoEen gegevensbeschermingseffectbeoordeling (geb) of data protection impact assessment (dpia) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgdKlachten indienen bij markttoezichtautoriteitNaast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en aiBeoordeling van grondrechten door exploitantenVoordat een ai-systeem met een hoog risico in gebruik wordt genomen, moeten publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde ai-systemen, een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben deze evaluatie is bedoeld om potenti\u00eble risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van ai-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiekMelden van ernstige incidentenAanbieders van ai-systemen met een hoog risico die binnen de eu worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze ai-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek het doel is om de veiligheid en betrouwbaarheid van ai-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliserenVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatEenieder heeft recht op toegang tot publieke informatieBij het ontwikkelen en gebruiken van algoritmen en ai kunnen documenten en kan publieke informatie ontstaan die (op verzoek) in aanmerkingen komen voor openbaarmaking het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat er kunnen uitsluitingsgronden bestaan voor het openbaarmaking van documentenTechnische documentatie voor hoog-risico aiDe technische documentatie van een ai-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen de documentatie bevat ten minste de elementen zoals uiteengezet in bijlage ivToezichtmogelijkheden voor gebruikersAi-systemen met een hoog risico moeten zodanig worden ontworpen en ontwikkeld dat natuurlijke personen effectief toezicht kunnen houden op hun werking tijdens gebruik dit omvat het implementeren van passende mens-machine-interface-instrumenten die gebruikers in staat stellen om het systeem te begrijpen en te controleren het doel is om gebruikers in staat te stellen een actieve rol te spelen bij het monitoren en beheren van de werking van deze systemen, waardoor het vertrouwen en de veiligheid worden vergrootTransparantie in ontwerp voor hoog-risico aiAi-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat exploitanten de output van het systeem kunnen begrijpen en adequaat kunnen gebruiken dit zorgt ervoor dat de aanbieders en exploitanten kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerdNoneNoneVerplicht risicobeheersysteem voor hoog-risico aiVoor ai-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de ai-systemen te waarborgen en mogelijke schade te voorkomen of te beperkenVerstrekking van informatie op verzoekAanbieders van ai-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de eu, zoals gekozen door de betrokken lidstaatRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming"},{"location":"levenscyclus/validatie/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"maatregelen/","title":"Maatregelen","text":"<p>Hier komt een overzicht van alle maatregelen.</p>"},{"location":"overhetalgoritmekader/","title":"Over het algoritmekader","text":"<p>Overheidsorganisaties moeten weten wat de eisen zijn voor verantwoorde inzet van algoritmes. Er zijn al verschillende instrumenten ontwikkeld die helpen wet- en regelgeving beter toe te passen.\u00a0Het algoritmekader gaat prioriteiten aanbrengen in deze instrumenten en stroomlijnt ze, zodat overheden in alle fasen van de levenscyclus van algoritmische toepassingen praktische handvatten hebben. Best practices, use cases en input van eindgebruikers en de toezichthouder helpen tot een goed en gedragen algoritmekader voor alle overheden te komen.</p> <p>7 juli 2023 is het concept Implementatiekader naar de kamer verstuurd, vergezeld door de Kamerbrief 'Verzamelbrief Algoritmes Reguleren'.</p>"},{"location":"overhetalgoritmekader/#uitgangspunt-publieke-waarden-mensenrechten-en-ethische-principes","title":"Uitgangspunt: Publieke waarden, mensenrechten en ethische principes","text":"<p>Het verantwoord inzetten van algoritmen betekent dat de inzet wettig, ethisch en robuust is. Dit betekent dat ten minste voldaan moet worden aan wet- en regelgeving en dat de inzet in lijn is met publieke waarden en ethische principes. Het algoritmekader neemt dit dan ook als uitgangspunt.</p> <p>Voor de structuur is aangesloten op de ethische richtsnoeren die ook een basis vormen voor de Europese AI Verordening. Deze richtsnoeren omvatten belangrijke publieke waarden zoals menselijke controle, rechtvaardigheid, privacy en non-discriminatie. In deze thema\u2019s zijn de belangrijkste bestaande verplichtingen en richtlijnen in kaart gebracht, en worden maatregelen en waarborgen aangereikt. </p>"},{"location":"overhetalgoritmekader/#doorontwikkeling","title":"Doorontwikkeling","text":"<p>Hoe deze governance (waaronder een heldere verdeling van bevoegdheden en verantwoordelijkheden) binnen de overheid invulling krijgt, is nog onderwerp van gesprek. Dit wordt  meegenomen in de verdere doorontwikkeling van het algoritmekader.</p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"overhetalgoritmekader/definities/","title":"Definities","text":"<p>Welke definities gebruikt het Algoritmekader? Je vindt een overzicht op deze pagina. Deze definities komen overeen met de definities van het het Algoritmeregister, zie daarvoor de Handreiking Algoritmeregister</p>"},{"location":"overhetalgoritmekader/definities/#definitie-van-een-algoritme","title":"Definitie van een algoritme","text":"<p>Er zijn veel definities van een algoritme. Voor het algoritmekader hanteren we de definitie van de Algemene Rekenkamer:</p> <p>'Een set van regels en instructies die een computer geautomatiseerd volgt bij het maken van berekeningen om een probleem op te lossen of een vraag te beantwoorden.\u2019</p> <p>Dit is een brede definitie die de maximale reikwijdte weergeeft van algoritmes waarvoor het Algoritmekader relevant is. Waar de definitie van de Algemene Rekenkamer schrijft \u201com een probleem op te lossen of een vraag te beantwoorden\u201d, verstaan we daar ook onder \u201com een taak of proces uit te voeren of tot een besluit te komen\u201d. In het uitvoeren van een taak of het komen tot een besluit kunnen \u00e9\u00e9n of meer algoritmes voorkomen. Daarnaast hebben we het bij het Algoritmekader over zowel Artifici\u00eble Intelligentie (AI) als algoritmes. De essentie is dat AI is opgebouwd uit algoritmes. Maar niet alle algoritmes zijn AI. </p> <p></p> <p>Gebruikte terminologie</p> <p>De termen hoog-risico, impactvol, AI en Algoritmes worden veel door elkaar gebruikt. Wij hanteren uitsluitend de volgende twee termen:</p> <ol> <li> <p>Hoog-risico AI (-systeem)  Hiermee bedoelen we altijd de definitie zoals deze in de AI-verordening wordt gehanteerd.</p> </li> <li> <p>Impactvolle algoritmes Dit betreft de minimale reikwijdte van het Algoritmekader. Het omvat de hoog-risico AI-systemen zoals gedefinieerd in de AI-verordening \u00e9n de algoritmes die we daarnaast als impactvol beschouwen. </p> </li> </ol>"},{"location":"overhetalgoritmekader/definities/#relatie-scope-algoritmekader-en-de-ai-verordening","title":"Relatie scope Algoritmekader en de AI-Verordening","text":"<p>Op dit moment wordt op EU-niveau de AI-verordening ontwikkeld, die naar verwachting van toepassing wordt op een deel van de algoritmes in gebruik bij de overheid. In de AI-verordening zijn AI-systemen onderverdeeld in verschillende categorie\u00ebn: verboden praktijken, hoog-risico AI-systemen, AI-systemen met manipulatierisico\u2019s en AI-systemen met geen/minimale risico\u2019s. Afhankelijk van de categorie waarin een AI-systeem valt, gelden zwaardere of minder zware eisen waar die systemen aan moeten voldoen.</p> <p>Het Algoritmekader is hoe dan ook relevant voor hoog-risico AI-systemen volgens de definitie van de AI-verordening. Een AI-systeem is hoog-risico als het voldoet aan de volgende eisen: 1. Het AI-systeem valt onder de definitie van AI-systemen in artikel 3 lid 1 van de verordening en moet o.a. autonome elementen bevatten, en</p> <ol> <li>Het AI-systeem wordt in een van de toepassingsgebieden van ANNEX III ingezet zoals biometrie, kritieke infrastructuur en rechtshandhaving. Bovenstaande betreft een versimpelde beschrijving van de AI-verordening. In bijlage 2 van de Handreiking Algoritmeregister is meer informatie te vinden over de AI-verordening. Aangezien de AI-verordening nog in onderhandeling is, bestaat de kans dat de classificatie van hoog-risico AI-systemen nog wordt aangepast. </li> </ol>"},{"location":"overhetalgoritmekader/definities/#definitie-van-impactvolle-algoritmes","title":"Definitie van impactvolle algoritmes","text":"<p>Om te bepalen of een algoritme in aanmerking komt voor publicatie in het Algoritmeregister, is een hulpmiddel 'Selectie' gemaakt. Het zijn dezelfde algoritmes die relevant zijn voor het Algoritmekader. Dit hulpmiddel wordt hieronder weergegeven in de figuur, en is ook leidend voor het Algoritmekader.</p> <p></p> <p>Voor meer toelichting over dit hulpmiddel verwijzen we naar de Handreiking Algoritmeregister. </p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/","title":"Rollen","text":"<p>Hier komt een overzicht van alle rollen.</p>"},{"location":"rollen/data-scientist/","title":"Data scientist","text":""},{"location":"rollen/data-scientist/#title-data-scientist","title":"title: Data scientist","text":""},{"location":"vereisten/","title":"Vereisten","text":"<p>Hier komt een lijst van de vereisten.</p>"},{"location":"vereisten/algoritmeregister/","title":"Impactvolle algoritmen en ai worden gepubliceerd in het algoritmeregister","text":"<p>OntwikkelenValidatieImplementatieMonitorenTransparantie</p>"},{"location":"vereisten/algoritmeregister/#vereiste","title":"Vereiste","text":"<p>Bestuurorganen publiceren impactvolle algoritmen en hoge risico AI in het Algoritmeregister.</p>"},{"location":"vereisten/algoritmeregister/#toelichting","title":"Toelichting","text":"<p>Het publiceren van impactvolle algoritmen en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmen en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmen en hoge risico AI publiceren in het algoritmeregister.</p>"},{"location":"vereisten/algoritmeregister/#bronnen","title":"Bronnen","text":"Bron Handreiking Algoritmeregister Werkagenda Kamerbrieven"},{"location":"vereisten/algoritmeregister/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/algoritmeregister/#risico","title":"Risico","text":""},{"location":"vereisten/algoritmeregister/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/algoritmeregister/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/archiefwet/","title":"De archiefwet is ook van toepassing op algoritmen en ai","text":"<p>ArchiverenImplementatieTechnische robuustheid en veiligheidGovernanceDataPrivacy en gegevensbescherming</p>"},{"location":"vereisten/archiefwet/#vereiste","title":"Vereiste","text":"<p>Overheidsorganen zijn verplicht de onder hen berustende archiefbescheiden in goede, geordende en toegankelijke staat te brengen en te bewaren, alsmede zorg te dragen voor de vernietiging van de daarvoor in aanmerking komende archiefbescheiden.</p>"},{"location":"vereisten/archiefwet/#toelichting","title":"Toelichting","text":"<p>Volgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en AI, tot stand zijn gekomen. Informatie over en van algoritmen en AI moet daarom ook bewaard en vernietigd worden.</p>"},{"location":"vereisten/archiefwet/#bronnen","title":"Bronnen","text":"Bron Artikel 3 Archiefwet Artikel 15 lid 2 Archiefwet Archiefbesluit 1995 Archiefregeling"},{"location":"vereisten/archiefwet/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/archiefwet/#risico","title":"Risico","text":"<p>Zonder goede toepassing van de Archiefwet is het voor betrokkene(n) of derden niet mogelijk om achteraf te reconstrueren en te controleren hoe besluiten, waar algoritmen en AI aan hebben bijgedragen, tot stand zijn gekomen. Het nalaten om archiefbescheiden na verloop van tijd te verwijderen brengt risico's met zich mee op het gebied van privacy en informatiebeveiliging </p>"},{"location":"vereisten/archiefwet/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/archiefwet/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/auteursrechten/","title":"Verbod op schenden auteursrechten","text":"<p>Dataverkenning en datapreparatieOntwerpDataGovernance</p>"},{"location":"vereisten/auteursrechten/#vereiste","title":"Vereiste","text":"<p>Auteursrechten mogen niet geschonden worden bij het ontwikkelen en gebruiken van algoritmen en AI.</p>"},{"location":"vereisten/auteursrechten/#toelichting","title":"Toelichting","text":"<p>Bepaalde vormen van algoritmen en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmen en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmen en AI mag geen inbreuk maken op deze rechten.</p>"},{"location":"vereisten/auteursrechten/#bronnen","title":"Bronnen","text":"Bron Artikel 1 Auteurswet Artikel 4-9 Auteurswet Artikel 10 Auteurswet Artikel 13 Auteurswet Artikel 15n jo. 15o Auteurswet Artikel 3 en 4 van de DSM-richtlijn (EU 2019/790)"},{"location":"vereisten/auteursrechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/auteursrechten/#risico","title":"Risico","text":"<p>Het is onduidelijk of de ontwikkelaar van het algoritme of AI voldoende rekening heeft gehouden met de rechten van auteurs wiens werken al dan niet zijn gebruikt als trainingsdata voor het ontwikkelde algoritme of AI. Daardoor ontstaat het risico, bv. bij scraping van data van het internet, dat auteursrechten worden geschonden.</p>"},{"location":"vereisten/auteursrechten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/auteursrechten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/automatische_logregistratie/","title":"Automatische logregistratie voor hoog-risico ai","text":"<p>Dataverkenning en datapreparatieOntwikkelenGovernance</p>"},{"location":"vereisten/automatische_logregistratie/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).</p>"},{"location":"vereisten/automatische_logregistratie/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren, wat vaak wordt aangeduid als \"logs\". Deze logs bieden een traceerbaarheidsmechanisme waarmee exploitanten en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken. Het doel van deze registratie is om de transparantie en verantwoordingsplicht van AI-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetert.</p>"},{"location":"vereisten/automatische_logregistratie/#bronnen","title":"Bronnen","text":"Bron Artikel 12(1) Registratie- AI verordening"},{"location":"vereisten/automatische_logregistratie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/automatische_logregistratie/#risico","title":"Risico","text":"<p>Ontbreken van automatische logregistratie kan leiden tot een gebrek aan transparantie en traceerbaarheid van het AI-systeem, wat het vermogen om verantwoordelijkheid te nemen en eventuele problemen aan te pakken belemmert.</p>"},{"location":"vereisten/automatische_logregistratie/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/automatische_logregistratie/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/beginsel_van_eerlijke_verwerking/","title":"Beginsel van eerlijke verwerking","text":"<p>title: Persoonsgegevens moeten worden eerlijk verwerkt toelichting:  het beginsel van behoorlijke (eerlijke) verwerking bepaalt voornamelijk de relatie tussen de verwerkingsverantwoordelijke en de betrokkene verwerkingsverantwoordelijken moeten  betrokkenen en het grote publiek in kennisstellen dat ze gegevens op een wettelijke en transparante manier zullen verwerken ze moeten ook in staat zijn om aan te tonen dat de verwerking mag in het kader van de avg verwerkingen mogen dus niet in het geheim worden uitgevoerd en betrokkenen moeten zich bewust zijn van de risico\u2019s daarnaast moeten verwerkingsverantwoordelijken, voor zover mogelijk, dat ze tegemoet moeten komen aan de wensen van de betrokkene, vooral toestemming de rechtsgrondslag voor de gegevensverwerking vormt status_vereiste:   - Geldend  -  levenscyclus:  - ontwerp - dataverkenning-en-datapreparatie - ontwikkelen - validatie - implementatie - monitoren bouwblok:  - transparantie rekenregels:  - niet-impactvol:  - impactvol:  machine-learning:  - niet-impactvol:  - impactvol:  - hoog-risico:  generatieve-ai:  - niet-impactvol:  - impactvol:  - hoog-risico: </p>"},{"location":"vereisten/beginsel_van_eerlijke_verwerking/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens moeten worden verwerkt op een wijze die rechtmatig, behoorlijk (eerlijk) en transparant is.</p>"},{"location":"vereisten/beginsel_van_eerlijke_verwerking/#toelichting","title":"Toelichting","text":"<p>Het beginsel van behoorlijke (eerlijke) verwerking bepaalt voornamelijk de relatie tussen de verwerkingsverantwoordelijke en de betrokkene. Verwerkingsverantwoordelijken moeten  betrokkenen en het grote publiek in kennisstellen dat ze gegevens op een wettelijke en transparante manier zullen verwerken. Ze moeten ook in staat zijn om aan te tonen dat de verwerking mag in het kader van de AVG. Verwerkingen mogen dus niet in het geheim worden uitgevoerd en betrokkenen moeten zich bewust zijn van de risico\u2019s. Daarnaast moeten verwerkingsverantwoordelijken, voor zover mogelijk, dat ze tegemoet moeten komen aan de wensen van de betrokkene, vooral toestemming de rechtsgrondslag voor de gegevensverwerking vormt.</p>"},{"location":"vereisten/beginsel_van_eerlijke_verwerking/#bronnen","title":"Bronnen","text":"Bron Artikel 5, lid 1, sub a, AVG Artikel 3 Wjsg Artikel 3 Wpg"},{"location":"vereisten/beginsel_van_eerlijke_verwerking/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beginsel_van_eerlijke_verwerking/#risico","title":"Risico","text":""},{"location":"vereisten/beginsel_van_eerlijke_verwerking/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beginsel_van_eerlijke_verwerking/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/","title":"Proportionaliteit en subsidiariteit","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenValidatieImplementatieMonitorenArchiverenGovernance</p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#vereiste","title":"Vereiste","text":"<p>Gegevensverwerking in verhouding moet staan tot het beoogde doel en persoonsgegevens alleen worden verwerkt als er geen minder ingrijpende manier is om het doel te bereiken.</p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#toelichting","title":"Toelichting","text":"<p>Proportionaliteit vereist dat de omvang van gegevensverwerking in balans is met het beoogde doel, terwijl subsidiariteit en noodzakelijk benadrukt dat persoonsgegevens alleen moeten worden verwerkt als dit de enige geschikte manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden, waardoor de bescherming van persoonsgegevens wordt versterkt.</p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#bronnen","title":"Bronnen","text":"Bron Artikel 5,6, Grond 170 AVG Artikel 5(4)Verdrag betreffende de Europese Unie (VEU) Artikel 52 Handvest van de Grondrechten van de Europese Unie Protocol (Nr. 2) Betreffende de Toepassing van de Beginselen van Subsidiariteit en Evenredigheid bij het Verdrag van Maastricht artikel 1.10, 1.13 en 1.16 van de Aanbestedingswet"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#risico","title":"Risico","text":""},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/","title":"Beperkte bewaartermijn van persoonsgegevens","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Gegevens worden niet langer bewaard dan nodig (opslagbeperking)</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Gegevens mogen niet langer worden bewaard dan nodig is voor het beoogde doel, zoals vereist door het principe van opslagbeperking. Deze maatregel waarborgt dat persoonsgegevens niet langer worden bewaard dan strikt noodzakelijk is, waardoor risico's met betrekking tot gegevensbescherming worden verminderd en de privacy van individuen wordt beschermd. Het naleven van de opslagbeperking draagt bij aan een effici\u00ebnte gegevensverwerking en bevordert het vertrouwen van individuen in hoe hun gegevens worden beheerd.</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 onder e AVG"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#risico","title":"Risico","text":""},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bescherming_persoonsgegevens/","title":"Beschermen van persoonsgegevens","text":"<p>Dataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbeschermingData</p>"},{"location":"vereisten/bescherming_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Rekening houdend met de stand van de techniek, de uitvoeringskosten, alsook met de aard, de omvang, de context en de verwerkingsdoeleinden en de qua waarschijnlijkheid en ernst uiteenlopende risico's voor de rechten en vrijheden  van personen, treffen de verwerkingsverantwoordelijke en de verwerker passende technische en organisatorische maatregelen om een op het risico afgestemd beveiligingsniveau te waarborgen.</p>"},{"location":"vereisten/bescherming_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Voor de ontwikkeling en gebruik van algoritmen en AI is dat nodig. Deze data kan persoonsgegevens bevatten. Deze persoonsgegevens moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonomiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.</p>"},{"location":"vereisten/bescherming_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 32 AVG"},{"location":"vereisten/bescherming_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bescherming_persoonsgegevens/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals ongeautoriseerde toegang, vernietiging, onrechtmatige verwerking, verlies, wijziging of niet-toegestane verwerking van persoonsgegevens.</p>"},{"location":"vereisten/bescherming_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bescherming_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/","title":"Bescherming van kwetsbare groepen","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#vereiste","title":"Vereiste","text":"<p>Bescherm de privacy van kinderen en kwetsbare groepen en neem passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens in overeenstemming is met de AVG</p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#toelichting","title":"Toelichting","text":"<p>Bescherm de privacy van kinderen en kwetsbare groepen door ervoor te zorgen dat de verwerking van hun persoonsgegevens voldoet aan de Algemene Verordening Gegevensbescherming (AVG). Dit omvat het nemen van passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens veilig en rechtmatig is, en dat de rechten van deze groepen worden gerespecteerd. Het waarborgen van privacy voor deze groepen draagt bij aan een veilige en vertrouwde online omgeving waarin hun gegevens worden beschermd.</p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#bronnen","title":"Bronnen","text":"Bron Artikel 8 AVG Overweging 38 en 75 AVG"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#risico","title":"Risico","text":""},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/","title":"Beschrijven en toewijzen van verantwoordelijkheden","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatieGovernance</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De verantwoordelijkheden bij de verwerking van persoonsgegevens voor algoritmen en AI-systemen moeten zijn beschreven en toegekend.</p> <p>De verwerkingsverantwoordelijke is verantwoordelijk voor de naleving van lid 1 en kan deze aantonen (\"verantwoordingsplicht\").</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Bij het verwerken van persoonsgegevens voor algoritmen en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 24, 26, 27, 28 en 29, 5(2) AVG"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#risico","title":"Risico","text":"<p>Door rollen en verantwoordelijkheden rondom de verwerking van persoonsgegevens niet te duiden en te beleggen, ontstaat het risico dat persoonsgegevens onrechtmatig on onveilig wordt verwerkt.</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/","title":"Informatie en informatiesystemen van de overheid moet worden beveiligd","text":"<p>OntwerpImplementatieMonitorenTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#vereiste","title":"Vereiste","text":"<p>Informatie en informatiesystemen moeten op de juiste manier worden beveiligd.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#toelichting","title":"Toelichting","text":"<p>Informatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn. Algoritmen en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#bronnen","title":"Bronnen","text":"Bron Baseline Informatiebeveiliging Overheid Besluit voorschrift informatiebeveiliging rijksdienst 2007"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals ongeautoriseerde toegang, vernietiging, verlies, wijziging of niet-toegestane verwerking van gegevens als de informatie en informatiesystemen onvoldoende zijn beveiligd.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/","title":"Bevorder ai-geletterdheid personeel","text":"<p>ProbleemanalyseOntwerpMenselijke controle</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#vereiste","title":"Vereiste","text":"<p>Aanbieders en exploitanten van AI-systemen nemen maatregelen om, zoveel als mogelijk, te zorgen voor een toereikend niveau van AI-geletterdheid bij hun personeel en andere personen die namens hen AI-systemen exploiteren en gebruiken, en houden daarbij rekening met hun technische kennis, ervaring, onderwijs en opleiding en de context waarin de AI-systemen zullen worden gebruikt, evenals met de personen of groepen personen ten aanzien van wie de AI-systemen zullen worden gebruikt.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#toelichting","title":"Toelichting","text":"<p>Aanbieders en exploitanten van AI-systemen nemen maatregelen om ervoor te zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het overwegen van technische kennis, ervaring, onderwijs en opleiding van individuen, evenals de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#bronnen","title":"Bronnen","text":"Bron Artikel 4 AI-geletterdheid - AI verordening"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#risico","title":"Risico","text":"<p>Onvoldoende AI-geletterdheid kan leiden tot misbruik of verkeerd gebruik van AI-systemen.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/","title":"Bewaartermijn voor documentatie","text":"<p>OntwerpMonitorenArchiverenGovernance</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#vereiste","title":"Vereiste","text":"<p>De aanbieder houdt gedurende een periode van tien jaar nadat het AI-systeem met een hoog risico in de handel is gebracht of in gebruik is gesteld de elementen van art. 18 ter beschikking van de nationale bevoegde autoriteiten.</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#toelichting","title":"Toelichting","text":"<p>De aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#bronnen","title":"Bronnen","text":"Bron Artikel 18(1) Bewaring van documentatie- AI verordening"},{"location":"vereisten/bewaartermijn_voor_documentatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bewaartermijn_voor_documentatie/#risico","title":"Risico","text":"<p>Niet voldoen aan de bewaartermijn kan leiden tot juridische consequenties en kan het vermogen van de autoriteiten om toezicht te houden op de naleving van de regelgeving belemmeren.</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/","title":"Bewaartermijn voor gegenereerde logs","text":"<p>OntwerpOntwikkelenMonitorenArchiverenGovernance</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen. Deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door Unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplicht.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#bronnen","title":"Bronnen","text":"Bron Artikel 19(1) Automatisch gegenereerde logs- AI verordening"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#risico","title":"Risico","text":"<p>Onvoldoende bewaring van logs kan het vermogen belemmeren om incidenten te analyseren, naleving te controleren en verantwoordelijkheid vast te stellen bij mogelijke problemen met het AI-systeem.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/","title":"Corrigerende maatregelen voor non-conforme ai","text":"<p>MonitorenOntwerpOntwikkelenGovernance</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met deze verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de exploitanten, de gemachtigden en importeurs dienovereenkomstig in kennis.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem. Ze moeten ook alle relevante partijen, zoals distributeurs, exploitanten en importeurs, op de hoogte stellen van deze maatregelen.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 20(1) Corrigerende maatregelen en mededelingsverplichting- AI verordening"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#risico","title":"Risico","text":"<p>Niet reageren op non-conformiteit kan leiden tot juridische en reputatieschade, evenals risico's voor gebruikers en derden.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/databankenwet/","title":"Verbod op schenden databankenrechten","text":"<p>OntwerpDataverkenning en datapreparatieData</p>"},{"location":"vereisten/databankenwet/#vereiste","title":"Vereiste","text":"<p>Het is verboden onbevoegd data op te vragen of te hergebruiken uit een databank, wanneer deze systematisch zijn geordend en door een substanti\u00eble investering tot stand is gekomen.</p>"},{"location":"vereisten/databankenwet/#toelichting","title":"Toelichting","text":"<p>Het databankenrecht beschermt tegen kopi\u00ebren of oneigenlijk gebruik van gegevens in een databank. Degene die een substanti\u00eble financi\u00eble investering heeft verricht om de databank tot stand te brengen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken. Voor het ontwikkelen van algoritme en AI is data nodig. De data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databank.</p>"},{"location":"vereisten/databankenwet/#bronnen","title":"Bronnen","text":"Bron Artikel 5a en 5b Databankenwet"},{"location":"vereisten/databankenwet/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/databankenwet/#risico","title":"Risico","text":"<p>Als een ontwikkelaar onbevoegd gebruik heeft gemaakt van data uit een databank bij de ontwikkeling van algoritmen en AI, wordt het databankenrecht geschonden van de eigenaar.  De eigenaar van de databank kan bijvoorbeeld ontrekking van de data uit het handelsverkeer, vernietiging en onbruikbaarmaking  eisen, wat vergaande gevolgen kan hebben voor het gebruik kunnen maken van het algoritmen of AI-systeem.</p>"},{"location":"vereisten/databankenwet/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/databankenwet/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/","title":"Documentatie beoordeling niet-hoog-risico ai","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenGovernance</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>Een aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>Een aanbieder die oordeelt dat een AI-systeem geen hoog risico vormt, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem en voldoet aan de registratievereisten. Op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 6(4) Classificatieregels voor AI-systemen met een hoog risico - AI verordening"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#risico","title":"Risico","text":"<p>Gebrek aan transparantie en verantwoording bij risicobeoordeling kan leiden tot onrechtmatig in de markt brengen van risicovolle AI-systemen.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/fundamentele_rechten/","title":"None","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieFundamentele rechten</p>"},{"location":"vereisten/fundamentele_rechten/#vereiste","title":"Vereiste","text":"<p>Fundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.</p>"},{"location":"vereisten/fundamentele_rechten/#toelichting","title":"Toelichting","text":""},{"location":"vereisten/fundamentele_rechten/#bronnen","title":"Bronnen","text":"Bron Grondwet en internationale verdragen Art 29a AI-verordening"},{"location":"vereisten/fundamentele_rechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/fundamentele_rechten/#risico","title":"Risico","text":"<p>Grondrechten kunnen worden aangetast door de inzet van algoritmes</p>"},{"location":"vereisten/fundamentele_rechten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/fundamentele_rechten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/","title":"Geb/dpia verplicht bij hoog risico","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatiePrivacy en gegevensbescherming</p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Een gegevensbeschermingseffectbeoordeling / Data Protection Impact Assessment (GEB / DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen.</p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#toelichting","title":"Toelichting","text":"<p>Een Gegevensbeschermingseffectbeoordeling (GEB) of Data Protection Impact Assessment (DPIA) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgd.</p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 35 AVG"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#risico","title":"Risico","text":"<p>Bij de verwerking van persoonsgegevens zijn de risico's voor de rechten en vrijheden van betrokkenen zijn niet bekend en niet gemitigeerd.</p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/","title":"Gerichte doelverzameling","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens mogen alleen voor welbepaalde, uitdrukkelijk omschreven en gerechtvaardigde doeleinden worden verzameld en mogen vervolgens niet verder op een met die doeleinden onverenigbare wijze worden verwerkt (doelbinding).</p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden. Het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden. Deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden. Dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerking.</p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid, onder b AVG Overweging 50 AVG Artikel 54 AI-Verordening"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#risico","title":"Risico","text":"<p>De verwerking van persoonsgegevens in het algoritme valt niet onder het doel waarvoor zij verzameld zijn of een hiermee verenigbaar doel.</p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/","title":"Privacyrechten","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Betrokkenen kunnen een beroep doen op hun privacyrechten.</p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Mensen hebben het recht om hun privacyrechten uit te oefenen door een beroep te doen op verschillende wettelijke bepalingen, zoals het recht op inzage, correctie, verwijdering en bezwaar tegen de verwerking van hun persoonsgegevens. Dit betekent dat individuen controle hebben over hoe hun gegevens worden gebruikt en kunnen verzoeken om toegang tot hun gegevens of om wijzigingen aan te brengen indien nodig. Het kunnen uitoefenen van privacyrechten is essentieel voor het beschermen van de privacy van individuen en het waarborgen van transparantie en controle over hun persoonsgegevens.</p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 15 - 21 AVG"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#risico","title":"Risico","text":"<p>Betrokkenen hebben geen controle over hun persoonsgegevens doordat ze geen beroep kunnen doen op hun privacyrechten.</p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/","title":"Juistheid en actualiteit van gegevens","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De te verwerken gegevens zijn juist, nauwkeurig en zo nodig geactualiseerd</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>De te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt. Dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen. Het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevens.</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 sub d AVG Artikel 3 Wjsg Artikel 4 Wpg"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#risico","title":"Risico","text":"<p>De kwaliteit en integriteit van data is niet voldoende geborgd.</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/klachten/","title":"Klachten indienen bij markttoezichtautoriteit","text":"<p>ValidatieImplementatieMonitorenGovernanceFundamentele rechten</p>"},{"location":"vereisten/klachten/#vereiste","title":"Vereiste","text":"<p>Onverminderd andere administratieve of gerechtelijke rechtsmiddelen, kan elke natuurlijke of rechtspersoon die redenen heeft om van mening te zijn dat er inbreuk is gepleegd op de bepalingen van deze verordening, met redenen omklede klachten indienen bij de relevante markttoezichtautoriteit.</p>"},{"location":"vereisten/klachten/#toelichting","title":"Toelichting","text":"<p>Naast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit. Deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties. Deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en AI.</p>"},{"location":"vereisten/klachten/#bronnen","title":"Bronnen","text":"Bron Artikel 85(1) Recht om een klacht in te dienen bij een markttoezichtautoriteit- AI verordening"},{"location":"vereisten/klachten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/klachten/#risico","title":"Risico","text":"<p>Het indienen van klachten is een belangrijk middel om naleving van de verordening te waarborgen en eventuele inbreuken aan te pakken.</p>"},{"location":"vereisten/klachten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/klachten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/klachten_indienen_bij_markttoezichtautoriteit_/","title":"Recht op uitleg ai-besluiten","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenGovernanceFundamentele rechten</p>"},{"location":"vereisten/klachten_indienen_bij_markttoezichtautoriteit_/#vereiste","title":"Vereiste","text":"<p>Elke getroffen persoon op wie een besluit van toepassing is dat door de exploitant wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de exploitant duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.</p>"},{"location":"vereisten/klachten_indienen_bij_markttoezichtautoriteit_/#toelichting","title":"Toelichting","text":"<p>Elke persoon die wordt be\u00efnvloed door een besluit dat is genomen op basis van de output van een AI-systeem met een hoog risico, heeft het recht om van de exploitant een duidelijke uitleg te krijgen over de rol van het systeem in de besluitvorming en de belangrijkste aspecten van het besluit. Dit geldt voor besluiten die aanzienlijke gevolgen hebben voor de persoon, zoals die hun gezondheid, veiligheid of grondrechten be\u00efnvloeden. Deze maatregel waarborgt transparantie en verantwoordelijkheid bij het gebruik van AI in besluitvormingsprocessen, en biedt individuen de mogelijkheid om de beslissingen die hen be\u00efnvloeden te begrijpen en te betwisten.</p>"},{"location":"vereisten/klachten_indienen_bij_markttoezichtautoriteit_/#bronnen","title":"Bronnen","text":"Bron Artikel 86(1) Recht op toelichting bij individuele besluitvorming- AI verordening"},{"location":"vereisten/klachten_indienen_bij_markttoezichtautoriteit_/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/klachten_indienen_bij_markttoezichtautoriteit_/#risico","title":"Risico","text":"<p>Het recht op uitleg zorgt voor transparantie en verantwoording bij het gebruik van AI-systemen met een hoog risico en beschermt individuen tegen mogelijke nadelige gevolgen voor hun gezondheid, veiligheid en grondrechten.</p>"},{"location":"vereisten/klachten_indienen_bij_markttoezichtautoriteit_/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/klachten_indienen_bij_markttoezichtautoriteit_/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/","title":"Kwaliteitsbeheersysteem voor hoog-risico ai","text":"<p>ProbleemanalyseOntwerpGovernance</p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in art. 17.</p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten een kwaliteitsbeheersysteem implementeren om te garanderen dat ze voldoen aan de verordening. Dit systeem omvat gedocumenteerde beleidslijnen, procedures en instructies, en behandelt belangrijke aspecten zoals aangegeven in artikel 17.</p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 17(1) Systeem voor kwaliteitsbeheer- AI verordening"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#risico","title":"Risico","text":"<p>Onvoldoende kwaliteitsbeheer kan leiden tot non-conformiteit met de regelgeving, wat risico's met zich meebrengt voor de veiligheid, betrouwbaarheid en naleving van het AI-systeem.</p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/","title":"Kwaliteitscriteria voor data van hoog-risico ai","text":"<p>OntwerpDataverkenning en datapreparatieGovernance</p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico die technieken gebruiken die het trainen van AI-modellen met data omvatten, worden ontwikkeld op basis van datareeksen voor training, validatie en tests die voldoen aan de kwaliteitscriteria als bedoeld in de leden 2 tot en met 5 telkens wanneer dergelijke datareeksen worden gebruikt.</p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt.</p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#bronnen","title":"Bronnen","text":"Bron Artikel 10(1) Data and datagovernance - AI verordening"},{"location":"vereisten/kwaliteitscriteria_voor_data/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/kwaliteitscriteria_voor_data/#risico","title":"Risico","text":"<p>Gebruik van laagkwalitatieve of bevooroordeelde datasets kan leiden tot onbetrouwbare en oneerlijke AI-besluitvorming.</p> <p>Onvoldoende kwaliteitsborging van testdata kan leiden tot vertekende resultaten en gebrekkige prestaties van het AI-systeem bij gebruik in de praktijk.</p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/maatregelen_van_exploitanten_voor_gebruik/","title":"Maatregelen van exploitanten voor gebruik","text":"<p>ImplementatieGovernance</p>"},{"location":"vereisten/maatregelen_van_exploitanten_voor_gebruik/#vereiste","title":"Vereiste","text":"<p>Exploitanten van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6.</p>"},{"location":"vereisten/maatregelen_van_exploitanten_voor_gebruik/#toelichting","title":"Toelichting","text":"<p>Exploitanten van AI-systemen met een hoog risico moeten geschikte maatregelen nemen om ervoor te zorgen dat ze deze systemen gebruiken volgens de bijgevoegde instructies. Dit is in lijn met de voorschriften van de verordening.</p>"},{"location":"vereisten/maatregelen_van_exploitanten_voor_gebruik/#bronnen","title":"Bronnen","text":"Bron Artikel 26(1) Verplichtingen van exploitanten van AI-systemen met een hoog risico- AI verordening"},{"location":"vereisten/maatregelen_van_exploitanten_voor_gebruik/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/maatregelen_van_exploitanten_voor_gebruik/#risico","title":"Risico","text":"<p>Het niet naleven van deze maatregelen kan leiden tot onjuist gebruik van de AI-systemen, wat de effectiviteit en veiligheid ervan kan verminderen, en kan resulteren in risico's voor gebruikers en derden.</p>"},{"location":"vereisten/maatregelen_van_exploitanten_voor_gebruik/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/maatregelen_van_exploitanten_voor_gebruik/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/melden_van_ernstige_incidenten/","title":"Beoordeling van grondrechten door exploitanten","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatieGovernance</p>"},{"location":"vereisten/melden_van_ernstige_incidenten/#vereiste","title":"Vereiste","text":"<p>Voordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.</p>"},{"location":"vereisten/melden_van_ernstige_incidenten/#toelichting","title":"Toelichting","text":"<p>Voordat een AI-systeem met een hoog risico in gebruik wordt genomen, moeten publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde AI-systemen, een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben. Deze evaluatie is bedoeld om potenti\u00eble risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen. Het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van AI-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiek.</p>"},{"location":"vereisten/melden_van_ernstige_incidenten/#bronnen","title":"Bronnen","text":"Bron Artikel 27(1) Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico- AI verordening Artikel 6 lid 2 AI-verordening Punt 2 en punt 5 bij Bijlage III AI-verordening"},{"location":"vereisten/melden_van_ernstige_incidenten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/melden_van_ernstige_incidenten/#risico","title":"Risico","text":"<p>Het niet uitvoeren van deze beoordeling kan leiden tot schendingen van de grondrechten, juridische complicaties en verlies van vertrouwen van het publiek in het gebruik van AI-systemen door overheids- en openbare dienstverlenende entiteiten.</p>"},{"location":"vereisten/melden_van_ernstige_incidenten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/melden_van_ernstige_incidenten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/melding_ernstige_incidenten/","title":"Melden van ernstige incidenten","text":"<p>ValidatieImplementatieMonitorenGovernance</p>"},{"location":"vereisten/melding_ernstige_incidenten/#vereiste","title":"Vereiste","text":"<p>Aanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die binnen de EU worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden. Dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze AI-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek. Het doel is om de veiligheid en betrouwbaarheid van AI-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliseren.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#bronnen","title":"Bronnen","text":"Bron Artikel 73(1) Melding van ernstige incidenten AI verordening"},{"location":"vereisten/melding_ernstige_incidenten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/melding_ernstige_incidenten/#risico","title":"Risico","text":"<p>Het niet melden van ernstige incidenten kan leiden tot vertraagde reactie op potenti\u00eble gevaren voor gebruikers en kan het vertrouwen in AI-systemen ondermijnen.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/melding_ernstige_incidenten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/","title":"Monitoring na het in de handel brengen","text":"<p>MonitorenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#vereiste","title":"Vereiste","text":"<p>Aanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.</p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#toelichting","title":"Toelichting","text":"<p>Aanbieders moeten een monitoringssysteem na het in de handel brengen opzetten en documenteren, passend bij de aard van de AI-technologie\u00ebn en de risico's van het betreffende AI-systeem met een hoog risico. Dit monitoringssysteem moet proportioneel zijn aan de complexiteit en potenti\u00eble impact van het AI-systeem.</p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#bronnen","title":"Bronnen","text":"Bron Artikel 72(1) Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico- AI verordening"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#risico","title":"Risico","text":"<p>Privacy risico's: Het monitoringssysteem na het in de handel brengen kan actief en systematisch relevante data verzamelen die door exploitanten zijn verstrekt of via andere bronnen zijn verzameld. Dit kan leiden tot het verzamelen van persoonlijke gegevens van gebruikers of betrokkenen. Het systeem kan deze verzamelde gegevens analyseren om de prestaties van AI-systemen met een hoog risico te beoordelen. Dit impliceert mogelijk het analyseren van gevoelige informatie over individuen. De monitoring kan ook de interactie met andere AI-systemen analyseren, wat kan leiden tot het delen van gegevens tussen verschillende systemen, waardoor het risico op gegevensinbreuken toeneemt.</p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/non_discriminatie/","title":"Verbod op discriminatie","text":"<p>ProbleemanalyseDataverkenning en datapreparatieOntwerpValidatieImplementatieMonitorenFundamentele rechten</p>"},{"location":"vereisten/non_discriminatie/#vereiste","title":"Vereiste","text":"<p>Allen die zich in Nederland bevinden, worden in gelijke gevallen gelijk behandeld. Directe en indirecte discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, handicap, seksuele gerichtheid of op welke grond dan ook, is niet toegestaan.</p>"},{"location":"vereisten/non_discriminatie/#toelichting","title":"Toelichting","text":"<p>Overheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.</p>"},{"location":"vereisten/non_discriminatie/#bronnen","title":"Bronnen","text":"Bron Grondwet Artikel 1 EVRM Artikel 1 en 14, jo. 21 HvEU Algemene wet gelijke behandeling, Protocol 12 2.2, Artikel 1 lid 1 sub c Aritkel 9 AVG Artikel 2:4 Awb"},{"location":"vereisten/non_discriminatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/non_discriminatie/#risico","title":"Risico","text":"<p>Het model cre\u00ebert onwenselijke systematische afwijking voor specifieke personen, groepen of andere eenheden (bias). Deze onwenselijke systematische afwijking kan duiden op directe of indirecte discriminerende effecten van de inzet van het algoritme.</p>"},{"location":"vereisten/non_discriminatie/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/non_discriminatie/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/","title":"Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.</p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden zorgvuldig ontworpen en ontwikkeld om een hoog niveau van nauwkeurigheid, robuustheid en cyberbeveiliging te bieden. Dit garandeert consistente prestaties gedurende hun levensduur en minimaliseert risico's met betrekking tot deze aspecten, waardoor de betrouwbaarheid en veiligheid van het systeem worden gewaarborgd.</p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#bronnen","title":"Bronnen","text":"Bron Artikel 15(1) Nauwkeurigheid, robuustheid en cyberbeveiliging- AI verordening"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#risico","title":"Risico","text":"<p>Gebrek aan nauwkeurigheid, robuustheid of cyberbeveiliging kan leiden tot onbetrouwbare prestaties, kwetsbaarheid voor storingen en blootstelling aan beveiligingsrisico's, wat de effectiviteit en veiligheid van het AI-systeem in gevaar kan brengen.</p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/persoonsgegevens_verzamelen_voor_specifieke_doeleinden/","title":"Persoonsgegevens verzamelen voor specifieke doeleinden","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/persoonsgegevens_verzamelen_voor_specifieke_doeleinden/#vereiste","title":"Vereiste","text":"<p>Voor welbepaalde, uitdrukkelijk omschreven en gerechtvaardigde doeleinden worden verzameld en mogen vervolgens niet verder op een met die doeleinden onverenigbare wijze worden verwerkt; de verdere verwerking met het oog op archivering in het algemeen belang, wetenschappelijk of historisch onderzoek of statistische doeleinden wordt overeenkomstig artikel 89, lid 1, niet als onverenigbaar met de oorspronkelijke doeleinden beschouwd (\"doelbinding\")</p>"},{"location":"vereisten/persoonsgegevens_verzamelen_voor_specifieke_doeleinden/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens mogen alleen verzameld worden voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden en mogen daarna niet op een manier worden verwerkt die niet verenigbaar is met deze doeleinden.</p>"},{"location":"vereisten/persoonsgegevens_verzamelen_voor_specifieke_doeleinden/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 onder c AVG"},{"location":"vereisten/persoonsgegevens_verzamelen_voor_specifieke_doeleinden/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/persoonsgegevens_verzamelen_voor_specifieke_doeleinden/#risico","title":"Risico","text":"<p>De verwerkte persoonsgegevens zijn niet proportioneel en relevant in relatie tot het doel</p>"},{"location":"vereisten/persoonsgegevens_verzamelen_voor_specifieke_doeleinden/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/persoonsgegevens_verzamelen_voor_specifieke_doeleinden/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/","title":"Persoonsgegeven worden rechtmatig, behoorlijk en transparant verwerkt","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatiePrivacy en gegevensbescherming</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens is rechtmatig, behoorlijk en transparant. De verwerking (inclusief het verzamelen) is gebaseerd op \u00e9\u00e9n van de wettelijke grondslagen die zijn genoemd in de AVG. De verwerking van persoonsgegevens op een eerlijke en rechtmatige manier moet gebeuren.</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#toelichting","title":"Toelichting","text":"<p>De verwerking van persoonsgegevens moet eerlijk en rechtmatig plaatsvinden, wat betekent dat het voldoet aan de principes van rechtmatigheid, behoorlijkheid en transparantie. Dit houdt in dat de verwerking gebaseerd moet zijn op een van de wettelijke grondslagen die zijn vastgesteld in de Algemene Verordening Gegevensbescherming (AVG).</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 onder a AVG Artikel 6 en 12 AVG Artikel 5 en 6 AVG Overweging 39 en 60 AVG"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#risico","title":"Risico","text":""},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/","title":"Privacy bij ontwerp","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Gegevensbescherming door ontwerp en door standaardinstellingen</p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Gegevensbescherming door ontwerp en standaardinstellingen houdt in dat privacy- en gegevensbescherming vanaf het begin worden ge\u00efntegreerd in de ontwikkeling van systemen en processen. Door al bij het ontwerp rekening te houden met privacyaspecten en door standaardinstellingen die de privacy bevorderen, wordt de bescherming van persoonsgegevens versterkt. Deze aanpak zorgt ervoor dat privacy overwegingen een integraal onderdeel zijn van alle aspecten van gegevensverwerking en draagt bij aan het vertrouwen van individuen in de veilige omgang met hun gegevens.</p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 25 AVG Artikel 4b Wpg"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#risico","title":"Risico","text":"<p>Ontwerp en opzet van het algoritme zijn onvoldoende gericht op de bescherming van privacy.</p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/","title":"Klachtrecht downstreamaanbieders","text":"<p>MonitorenGovernanceFundamentele rechten</p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#vereiste","title":"Vereiste","text":"<p>Downstreamaanbieders hebben het recht een klacht in te dienen wegens inbreuk op deze verordening bij de AI-bureau.</p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#toelichting","title":"Toelichting","text":"<p>Downstreamaanbieders hebben het recht om een klacht in te dienen bij het AI-bureau in het geval van een inbreuk op deze verordening. Dit biedt hen een mechanisme om actie te ondernemen bij schendingen van de regels met betrekking tot AI-systemen. Het AI-bureau kan dan passende maatregelen nemen om de naleving van de verordening te handhaven en eventuele geschillen op te lossen.</p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#bronnen","title":"Bronnen","text":"Bron Artikel 89(1) Monitoringmaatregelen- AI verordening"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#risico","title":"Risico","text":"<p>Dit recht stelt downstreamaanbieders in staat om actie te ondernemen tegen mogelijke schendingen van de AI-verordening en draagt bij aan de handhaving van naleving in de AI-sector.</p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/","title":"Recht op niet geautomatiseerd besluitvorming","text":"<p>OntwerpOntwikkelenMonitorenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#vereiste","title":"Vereiste","text":"<p>Betrokkenen hebben het recht om niet onderworpen te worden aan een enkel op geautomatiseerde verwerking, waaronder proflering, gebaseerd besluit, wanneer dit rechtsgevolgen heeft voor hen of het hen anderszins in aanzienlijke mate tref.</p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#toelichting","title":"Toelichting","text":"<p>Mensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen.</p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#bronnen","title":"Bronnen","text":"Bron Artikel 22 AVG"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#risico","title":"Risico","text":"<p>Een betrokkene ondervindt aanmerkelijke gevolgen door een geautomatiseerd besluit, zonder dat deze een beroep op menselijke tussenkomst kan doen.</p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/","title":"Eenieder heeft recht op toegang tot publieke informatie","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatieImplementatieMonitorenTransparantie</p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#vereiste","title":"Vereiste","text":"<p>Een bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.</p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#toelichting","title":"Toelichting","text":"<p>Bij het ontwikkelen en gebruiken van algoritmen en AI kunnen documenten en kan publieke informatie ontstaan die (op verzoek) in aanmerkingen komen voor openbaarmaking. Het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat. Er kunnen uitsluitingsgronden bestaan voor het openbaarmaking van documenten.</p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#bronnen","title":"Bronnen","text":"Bron Artikel 1.1 en 2.5 Woo"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#risico","title":"Risico","text":""},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/","title":"Toepassing richtlijn (eu) 2019/1937","text":"<p>OntwerpOntwikkelenMonitorenGovernanceFundamentele rechten</p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#vereiste","title":"Vereiste","text":"<p>Richtlijn (EU) 2019/1937 is van toepassing op het melden van inbreuken op deze verordening en op de bescherming van personen die dergelijke inbreuken melden.</p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#toelichting","title":"Toelichting","text":"<p>Richtlijn (EU) 2019/1937 is van toepassing op het melden van inbreuken op deze verordening en op de bescherming van personen die deze inbreuken melden. Het biedt een kader voor het veilig en vertrouwelijk melden van schendingen van de verordening, terwijl het de melders beschermt tegen represailles of vervolging. Deze richtlijn bevordert transparantie en verantwoording binnen organisaties en draagt bij aan een cultuur van naleving en integriteit.</p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#bronnen","title":"Bronnen","text":"Bron Artikel 87 Melding van inbreuken en bescherming van melders- AI verordening"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#risico","title":"Risico","text":"<p>De richtlijn waarborgt een veilige omgeving voor klokkenluiders die inbreuken op de AI-verordening melden en stimuleert een effectief rapportagesysteem om de naleving van de verordening te waarborgen.</p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/","title":"Risicobeoordeling voor jongeren en kwetsbaren","text":"<p>ProbleemanalyseOntwerpOntwikkelenFundamentele rechten</p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#vereiste","title":"Vereiste","text":"<p>Bij de uitvoering van het in de leden 1 tot en met 7 bedoelde systeem voor risicobeheer houden aanbieders rekening met de vraag of het beoogde doel van het AI-systeem met een hoog risico waarschijnlijk negatieve gevolgen zal hebben voor personen jonger dan 18 jaar en, in voorkomend geval, voor andere groepen kwetsbare personen.</p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#toelichting","title":"Toelichting","text":"<p>Bij het beheer van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.</p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#bronnen","title":"Bronnen","text":"Bron Artikel 9(9) Systeem voor risicobeheer -  AI verordening"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#risico","title":"Risico","text":"<p>Niet adequaat adresseren van risico's voor jongeren en kwetsbare groepen kan leiden tot ernstige ethische en maatschappelijke schade.</p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/","title":"Technische documentatie voor hoog-risico ai","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatieImplementatieMonitorenGovernance</p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>De technische documentatie van een AI-systeem met een hoog risico wordt opgesteld voordat dit systeem in de handel wordt gebracht of in gebruikt wordt gesteld, en wordt geactualiseerd. De technische documentatie wordt op zodanige wijze opgesteld dat wordt aangetoond dat het AI-systeem met een hoog risico in overeenstemming is met de eisen van deze afdeling en dat nationale bevoegde autoriteiten en aangemelde instanties over de noodzakelijke, op heldere en begrijpelijke wijze gestelde informatie beschikken om de overeenstemming van het AI-systeem met deze voorschriften te kunnen beoordelen. De documentatie omvat ten minste de in bijlage IV uiteengezette elementen.</p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>De technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV.</p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 11(1) Technische documentatie- AI verordening Bijlage IV bij AI-Verordening"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#risico","title":"Risico","text":"<p>Het ontbreken van de benodigde informatie over de algoritmische toepassing of AI-systeem kan ertoe leiden dat onduidelijk is hoe het technisch functioneert. Dat kan tot problemen leiden bij de verantwoording, controle en het beheer ervan. Onvolledige of ontoereikende technische documentatie kan leiden tot onduidelijkheid over de conformiteit van het AI-systeem met de regelgeving, wat de veiligheid en naleving in gevaar kan brengen.</p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/","title":"Toezichtmogelijkheden voor gebruikers","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatieImplementatieMonitorenMenselijke controle</p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.</p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico moeten zodanig worden ontworpen en ontwikkeld dat natuurlijke personen effectief toezicht kunnen houden op hun werking tijdens gebruik. Dit omvat het implementeren van passende mens-machine-interface-instrumenten die gebruikers in staat stellen om het systeem te begrijpen en te controleren. Het doel is om gebruikers in staat te stellen een actieve rol te spelen bij het monitoren en beheren van de werking van deze systemen, waardoor het vertrouwen en de veiligheid worden vergroot.</p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#bronnen","title":"Bronnen","text":"Bron Artikel 14(1) Menselijk toezicht- AI verordening"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#risico","title":"Risico","text":"<p>Ontbreken van adequate toezichtmogelijkheden kan leiden tot gebrek aan controle en begrip over het functioneren van het AI-systeem, wat kan resulteren in ongewenste of onvoorspelbare uitkomsten.</p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/transparantie/","title":"Transparantie in ontwerp voor hoog-risico ai","text":"<p>OntwerpOntwikkelenValidatieImplementatieMonitorenTransparantie</p>"},{"location":"vereisten/transparantie/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat de werking ervan voldoende transparant is om exploitanten in staat te stellen de output van een systeem te interpreteren en op passende wijze te gebruiken. Een passende soort en mate van transparantie wordt gewaarborgd met het oog op de naleving van de relevante verplichtingen van de aanbieder en de exploitant zoals uiteengezet in afdeling 3.</p>"},{"location":"vereisten/transparantie/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat exploitanten de output van het systeem kunnen begrijpen en adequaat kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en exploitanten kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd.</p>"},{"location":"vereisten/transparantie/#bronnen","title":"Bronnen","text":"Bron Artikel 13(1) Transparantie en informatieverstrekking aan exploitanten- AI verordening"},{"location":"vereisten/transparantie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/transparantie/#risico","title":"Risico","text":"<p>Onvoldoende transparantie kan leiden tot een gebrek aan begrip over hoe het AI-systeem functioneert, wat de effectiviteit van de exploitatie ervan kan belemmeren en de naleving van wettelijke verplichtingen in gevaar kan brengen.</p>"},{"location":"vereisten/transparantie/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/transparantie/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/","title":"None","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatieImplementatieMonitorenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Open en duidelijk zijn over hoe persoonsgegevens worden verzameld, gebruikt, gedeeld en verwerkt. Dit moet worden toegepast op zowel de gegevensverzameling bij de betrokkene als op het verkrijgen van gegevens uit andere bronnen</p>"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#toelichting","title":"Toelichting","text":""},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 AVG Artikel 13 en 14 AVG Overweging 58 AVG"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#risico","title":"Risico","text":""},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/","title":"None","text":"<p>ProbleemanalyseOntwerpPrivacy en gegevensbescherming</p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#vereiste","title":"Vereiste","text":"<p>Voor zover dit strikt noodzakelijk is om de opsporing en correctie van vertekeningen te waarborgen in verband met de AI-systemen met een hoog risico overeenkomstig lid 2, punten f) en g), van dit artikel, mogen de aanbieders van dergelijke systemen uitzonderlijk bijzondere categorie\u00ebn persoonsgegevens verwerken, mits passende waarborgen worden geboden voor de grondrechten en fundamentele vrijheden van natuurlijke personen.</p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#toelichting","title":"Toelichting","text":"<p>Voor zover strikt noodzakelijk voor het detecteren en corrigeren van vooringenomenheid met betrekking tot AI-systemen met een hoog risico, mogen aanbieders van dergelijke systemen uitzonderlijk speciale categorie\u00ebn persoonsgegevens verwerken. Deze verwerking moet gepaard gaan met passende waarborgen voor de fundamentele rechten en vrijheden van natuurlijke personen.</p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#bronnen","title":"Bronnen","text":"Bron Artikel 10(5)  Data and datagovernance- AI verordening"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#risico","title":"Risico","text":""},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/","title":"Verplicht risicobeheersysteem voor hoog-risico ai","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenValidatieImplementatieMonitorenArchiverenGovernance</p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>In verband met AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.</p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>Voor AI-systemen met een hoog risico wordt een systeem voor risicobeheer opgezet, uitgevoerd, gedocumenteerd en onderhouden. Dit omvat het identificeren, beoordelen en beheersen van risico's die verband houden met deze systemen, en het nemen van passende maatregelen om deze risico's te minimaliseren. Het doel van het risicobeheersysteem is om de veiligheid en betrouwbaarheid van de AI-systemen te waarborgen en mogelijke schade te voorkomen of te beperken.</p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 9(1) Systeem voor risicobeheer - AI verordening"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#risico","title":"Risico","text":"<p>Falen in het risicobeheer kan leiden tot schade aan gebruikers of derden en wettelijke aansprakelijkheid voor de aanbieder.</p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/","title":"Verstrekking van informatie op verzoek","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenValidatieImplementatieMonitorenArchiverenGovernance</p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#vereiste","title":"Vereiste","text":"<p>Op een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie.</p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de verordening aan te tonen. Deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de EU, zoals gekozen door de betrokken lidstaat.</p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#bronnen","title":"Bronnen","text":"Bron Artikel 21(1) Samenwerking met bevoegde autoriteiten- AI verordening"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#risico","title":"Risico","text":"<p>Weigering om informatie te verstrekken kan leiden tot juridische sancties en kan het vermogen van de autoriteiten om toezicht te houden op de naleving van de regelgeving belemmeren.</p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/","title":"Wettelijke verwerking van gevoelige gegevens","text":"<p>OntwerpDataverkenning en datapreparatiePrivacy en gegevensbescherming</p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#vereiste","title":"Vereiste","text":"<p>Het algoritme verwerkt persoonsgegevens die alleen op basis van een wettelijke uitzondering verwerkt mogen worden, zoals bijzondere persoonsgegevens (o.a. gegevens m.b.t. ras of afkomst, religie, gezondheid of seksuele geaardheid), strafrechtelijke gegevens of nationale identificatienummers (o.a. BSN).</p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#toelichting","title":"Toelichting","text":"<p>Het algoritme mag alleen persoonsgegevens verwerken die onder wettelijke uitzonderingen verwerkt mogen worden. Deze beperkingen zijn bedoeld om de privacy van individuen te beschermen en ervoor te zorgen dat gevoelige informatie niet onrechtmatig wordt verwerkt door algoritmen.</p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 9, 10 en 87 AVG Hoofdstuk 3 UAVG Wabb Artikel 5 Wpg"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#risico","title":"Risico","text":"<p>Verwerking van bijzondere persoonsgegevens (o.a. gegevens m.b.t. ras of afkomst, religie, gezondheid of seksuele geaardheid), strafrechtelijke gegevens of nationale identificatienummers (o.a. BSN) is alleen toegestaan als hierop een wettelijke uitzondering toepassing is.</p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/","title":"Relevante feiten en belangen zijn bekend","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenValidatieImplementatieMonitorenArchiverenGovernance</p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#vereiste","title":"Vereiste","text":"<p>De ontwikkeling en het gebruik van algoritmes en AI-systeem komt zorgvuldig tot stand.</p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#toelichting","title":"Toelichting","text":"<p>Dit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming.</p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#bronnen","title":"Bronnen","text":"Bron Artikel 3.2 Awb Artikel 3.4 Awb"},{"location":"vereisten/zorgvuldigheidsbeginsel/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/zorgvuldigheidsbeginsel/#risico","title":"Risico","text":"<p>De werking van het algoritmen of AI sluit niet of onvoldoende aan bij de juridische en ethische grenzen van de te ondersteunen wettelijke taak. Hierdoor kunnen ongewenste gevolgen zoals discriminatie of onjuiste behandeling ontstaan bij belanghebbenden en betrokkenen.</p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"}]}