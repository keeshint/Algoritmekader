{"config":{"lang":["nl"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Algoritmekader","text":"<p>Wil de overheid\u202feffectief en verantwoord gebruik kunnen maken van algoritmes en (daarmee) van Artifici\u00eble Intelligentie (AI), dan stelt dat eisen aan de manier waarop we daarmee omgaan.\u202fTegelijkertijd zien we ook dat wat nodig is voor verantwoorde inzet enorm in ontwikkeling is, bijvoorbeeld door de snelle opkomst van (generatieve) AI. In relatief korte tijd komen er veel nieuwe mogelijkheden, maar ook nieuwe wetten, regels, normen en instrumenten. Veel overheden zien soms door de bomen het bos niet meer. Want hoe voldoe je aan de minimale normen? Wanneer is er sprake van verantwoorde inzet? En: welk instrument pas je wanneer toe?  </p> <p>Met het Algoritmekader werken we als overheid samen aan de\u202fantwoorden daarop. Dat doen we open; iedereen kan deze ontwikkeling volgen en eraan bijdragen.\u202fWe maken bij de ontwikkeling gebruik van wat er al is: wetten, normen, regels, instrumenten en expertise. Het kader brengt dit samen op een logische manier. Zodat overheden in alle fasen van de levenscyclus van algoritmische en AI-toepassingen praktische handvatten hebben. Best practices, use cases en input van eindgebruikers en de toezichthouder helpen te komen tot een goed en gedragen Algoritmekader voor alle overheden.\u202fHet kader wordt een praktisch hulpmiddel om algoritmes en AI verantwoord te kunnen inzetten en te voldoen aan de minimale eisen die wet- en regelgeving daaraan stellen. </p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"#eerdere-versies-van-het-algoritmekader","title":"Eerdere versies van het algoritmekader","text":"<p>Zie het Implementatiekader dat in juni 2023 naar de Tweede Kamer is verzonden. </p>"},{"location":"#bijdragen-aan-het-algoritmekader","title":"Bijdragen aan het algoritmekader?","text":"<p>We ontwikkelen het Algoritmekader op een open manier via GitHub. Bekijk de ontwikkelomgeving van het Algoritmekader.</p>"},{"location":"#heb-je-een-vraag-of-opmerking","title":"Heb je een vraag of opmerking?","text":"<p>Neem contact op via GitHub (zie punt 4 of 5) of stuur een email naar algoritmes@minbzk.nl.</p> <p>Stuur een mail </p>"},{"location":"bouwblokken/","title":"Bouwblokken","text":"<ul> <li> <p> Fundamentele rechten (in ontwikkeling)</p> <p>Het bouwblok fundamentele rechten is opgesplitst in verschillende delen</p> <p> Naar fundamentele rechten</p> <p> Naar bias en non-discriminatie</p> </li> <li> <p> Publieke inkoop (in ontwikkeling)</p> <p>Hier kunnen we een korte tekst kwijt over publieke inkoop</p> <p> Naar publieke inkoop</p> </li> <li> <p> Privacy en gegevensbescherming (in ontwikkeling)</p> <p>Hier kunnen we een korte tekst kwijt over privacy en gegevensbescherming</p> <p> Naar privacy en gegevensbescherming</p> </li> <li> <p> Transparantie (in ontwikkeling)</p> <p>Hier kunnen we een korte tekst kwijt over transparantie</p> <p> Naar transparantie</p> </li> <li> <p> Conformiteitsbeoordeling (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over conformiteitsbeoordeling</p> <p> Naar conformiteitsbeoordeling</p> </li> <li> <p> Data (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over data</p> <p> Naar data</p> </li> <li> <p> Duurzaamheid (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over duurzaamheid</p> <p> Naar duurzaamheid</p> </li> <li> <p> Governance (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over governance</p> <p> Naar governance</p> </li> <li> <p> Menselijke controle (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over menselijke controle</p> <p> Naar menselijke controle</p> </li> <li> <p> Technische robuustheid en veiligheid (nog te doen)</p> <p>Hier kunnen we een korte tekst kwijt over technische robuustheid en veiligheid</p> <p> Naar technische robuustheid en veiligheid</p> </li> </ul> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"bouwblokken/conformiteitsbeoordeling/","title":"Conformiteitsbeoordeling","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/conformiteitsbeoordeling/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/conformiteitsbeoordeling/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/data/","title":"Data","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/data/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmen en aiVolgens de archiefwet moeten overheden informatie bewaren op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en ai, tot stand zijn gekomen informatie over en van algoritmen en ai moet daarom ook bewaard en vernietigd wordenVerbod op schenden auteursrechtenBepaalde vormen van algoritmen en ai worden ontwikkeld op basis van grote hoeveelheden data deze data wordt gebruikt voor het trainen en testen van algoritmen en ai het gebruiken van deze data mag geen inbreuk maken op auteursrechten van diegene die deze rechten heeft ook de gegenereerde output van algoritmen en ai mag geen inbreuk maken op deze rechtenBeschermen van persoonsgegevensVoor de ontwikkeling en gebruik van algoritmen en ai is dat nodig deze data kan persoonsgegevens bevatten deze persoonsgegevens moeten worden beschermd de organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of ai-systeem voldoende te beschermen hierbij kan worden gedacht aan dataminimalisatie, het pseudonomiseren of aggregeren van persoonsgegevens per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijnVerbod op schenden databankenrechtenHet databankenrecht beschermt tegen kopi\u00ebren of oneigenlijk gebruik van gegevens in een databank degene die een substanti\u00eble financi\u00eble investering heeft verricht om de databank tot stand te brengen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken voor het ontwikkelen van algoritme en ai is data nodig de data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databank"},{"location":"bouwblokken/data/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/duurzaamheid/","title":"Duurzaamheid","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/duurzaamheid/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/duurzaamheid/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/fundamentele-rechten/","title":"Fundamentele rechten","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/fundamentele-rechten/#vereisten","title":"Vereisten","text":"VereisteUitlegNoneNoneKlachten indienen bij markttoezichtautoriteitNaast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en aiVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat"},{"location":"bouwblokken/fundamentele-rechten/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/","title":"Non-discriminatie","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#waarom","title":"Waarom?","text":"<p>Schrijf hier een tekst over wat [title] is en waarom dit belangrijk is voor een verantwoord gebruik van algoritmes bij overheidsorganisaties. </p>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#levenscyclus","title":"Levenscyclus","text":"<p>Een overzicht van welke fasen van de levenscyclus relevant zijn voor dit bouwblok. </p> <ul> <li> Probleemanalyse</li> <li> Ontwerp</li> <li> Data verkenning en data preparatie</li> <li> Ontwikkelen</li> <li> Validatie  </li> <li> Implementatie</li> <li> Monitoren</li> <li> Archiveren</li> </ul>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#normen","title":"Normen","text":"<p>Onderstaand een overzicht van de minimale vereisten die volgen uit geldende wet- en regelgeving, toetingskaders en andere bronnen</p> Laag risicoHoog risico Norm Uitleg Bron Norm 2 Korte uitleg over norm 2 Norm Uitleg Bron Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan Korte uitleg over norm 1 Norm 2 Korte uitleg over norm 2 Norm 3 Korte uitleg over norm 3 Norm 4 Korte uitleg over norm 4"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#rollen","title":"Rollen","text":"<p>Overzicht van welke rollen belangrijk zijn te betrekken bij dit bouwblok. </p> <ul> <li>technische expert bron: handreiking non-discriminatie by design</li> <li>projectleider bron: handreiking non-discriminatie by design</li> <li>jurist bron: handreiking non-discriminatie by design</li> <li>functionaris gegevensbescherming bron: handreiking non-discriminatie by design</li> <li>relevante stakeholders bron: handreiking non-discriminatie by design</li> <li>domein expert bron: handreiking non-discriminatie by design</li> <li>data steward bron: handreiking non-discriminatie by design</li> <li>data analist bron: handreiking non-discriminatie by design</li> <li>beleid bron: evaluatie handreiking non-discriminatie by design door ADR</li> </ul>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#aanbevelingen","title":"Aanbevelingen","text":"<p>Rathenau</p> <ul> <li>Geef als uitvoeringsorganisatie meer inzicht in hoe biastoetsing plaatsvindt </li> <li>Zet een nationaal kennisplatform voor biastoetsing op waar expertise kan worden ontwikkeld en gedeeld. Bepaal welke mate van standaardisatie gewenst is en of wettelijke eisen nodig zijn.</li> </ul> <p>ADR</p> <ul> <li>Plaats de handreiking in een kader in relatie tot andere instrumenten </li> <li>Overweeg een risicogerichte benadering voor de toepassing van de handreiking </li> <li>Werk aan het vergroten van bewustzijn voor algoritmen en (data-)ethiek in de organisatie </li> <li>Zorg voor duidelijkheid in taken en verantwoordelijkheden van verschillende betrokkenen </li> <li>Beleg verantwoordelijkheid voor de handreiking en borg de (blijvende) aandacht ervoor </li> <li>Verplichte toepassing van de handreiking kan bestaande initiatieven tenietdoen </li> </ul> <p>Toetsingskader ADR</p> <ul> <li>De definitie van de verschillende groepen en de gewenste prestatie van het model voor deze groepen zijn opgenomen in de functionele eisen.</li> <li>De mate van geaccepteerde bias in de uitkomst is opgenomen in de functionele eisen en uitgewerkt in meetbare prestatiecriteria.</li> <li>De methoden om bias te voorkomen, detecteren en corrigeren zijn vastgelegd.</li> <li>De mate van bias in de data, dataverzameling en het model zijn in kaart gebracht.</li> <li>Tijdens de ontwikkeling van het model is beoordeeld of er een verschil bestaat tussen de prestatie van het model tussen verschillende subgroepen. De prestatiemetrieken afleidbaar uit de confusionmatrix zijn vergeleken voor deze subgroepen.</li> <li>De uitkomstbias van productiedata is beoordeeld voor de verschillende subgroepen en voldoet aan de prestatiecriteria.</li> <li>Bij de geconstateerde bias is beoordeeld of deze op discriminatie duidt.</li> </ul> <p>College voor de Rechten van de Mens (Richtlijnen)</p> <ul> <li>Overheidsinstanties mogen bij opsporings- en handhavingsbevoegdheden, met het oog op effectiviteit, effici\u00ebntie en kostenbesparing, gebruik maken van risicoprofielen. Binnen deze risicoprofielen mogen ervaringsgegevens die tot een bepaalde vooronderstelling leiden een rol spelen, tenzij dit leidt tot discriminatie op grond van ras of nationaliteit</li> <li>Risicoprofielen die uitsluitend of in doorslaggevende mate gebaseerd zijn op ras (waaronder etniciteit en afkomst) zijn in strijd met het discriminatieverbod;</li> <li>Risicoprofielen die zich richten op \u00e9\u00e9n bepaalde afkomst of nationaliteit hebben een stigmatiserend effect en zijn daarom strijdig met het discriminatieverbod;</li> <li>Risicoprofielen die uitsluitend gebaseerd zijn op nationaliteit zijn zeer moeilijk te rechtvaardigen;</li> <li>Risicoprofielen waarin ras of nationaliteit mede een rol speelt, kunnen slechts gerechtvaardigd worden door zeer zwaarwegende redenen;</li> <li>Het gebruik van ras of nationaliteit als selectiecriterium binnen een risicoprofiel is nooit toegestaan als er geen objectieve relatie kan worden aangetoond tussen dit selectiecriterium en het legitieme doel van het profiel;</li> <li>In alle gevallen moeten de selectiecriteria  binnen een risicoprofiel samen voldoende relevant en objectief (geschikt) zijn om op een effectieve wijze bij te dragen aan de verwezenlijking van het nagestreefde legitieme doel;</li> <li>Het gebruik van ras of nationaliteit als selectiecriterium binnen een risicoprofiel moet daarnaast noodzakelijk zijn om het gewenste doel tebereiken.</li> <li>Selectiebeslissingen moeten te allen tijde uitlegbaar zijn.</li> </ul>"},{"location":"bouwblokken/fundamentele-rechten/non-discriminatie/#mogelijke-hulpmiddelen-en-methoden","title":"Mogelijke hulpmiddelen en methoden","text":"<ul> <li>Fairness Handbook</li> </ul>"},{"location":"bouwblokken/governance/","title":"Governance","text":"<p>Hier komt een beschrijving van dit bouwblok.</p>"},{"location":"bouwblokken/governance/#vereisten","title":"Vereisten","text":""},{"location":"bouwblokken/governance/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/menselijke-controle/","title":"Menselijke controle","text":"<p>Hier komt een beschrijving van dit bouwblok.</p>"},{"location":"bouwblokken/menselijke-controle/#vereisten","title":"Vereisten","text":""},{"location":"bouwblokken/menselijke-controle/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/privacy-en-gegevensbescherming/","title":"Privacy en gegevensbescherming","text":"<p>Hier komt een beschrijving van dit bouwblok.</p>"},{"location":"bouwblokken/privacy-en-gegevensbescherming/#vereisten","title":"Vereisten","text":""},{"location":"bouwblokken/privacy-en-gegevensbescherming/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/publieke-inkoop/","title":"Publieke inkoop","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Door middel van publieke inkoop wordt door overheidsinstellingen software ingekocht. Deze software wordt ingekocht om ambtenaren te ondersteunen met hun werkzaamheden om zo maatschappelijk waarden te cre\u00ebren. Het kan bijvoorbeeld gaan om het inkopen van een systeem waarmee een aanvraag voor een subsidie of vergunning kan worden behandeld. Het virtueel vergaderen of het digitaal samenwerken aan documenten zijn hier ook voorbeelden van. </p> <p>Software met algoritmen  en AI wordt vaak ontwikkeld door gespecialiseerde aanbieders en bevat steeds meer algoritmen en AI. Het komt ook voor dat de overheid deze technologie zelf ontwikkelt. Deze algoritmen en AI kunnen eenvoudig van aard zijn, zoals het maken van een eenvoudige berekening. Zij kunnen complexer van aard zijn, zoals een voorspelling geven of het genereren van informatie. In het laatste geval kan worden gedacht aan ChatGPT, Google Bard of Co-Pilot. Er zijn verschillende type technologie\u00ebn die vallen onder het bereik van algoritmen en AI. In dit kader drukken we deze uit als \u2018rekenregel\u2019, \u2018machine learning\u2019 en \u2018generatieve AI\u2019. Elke technologie heeft eigen bijzondere aandachtspunten. Ook de bijbehorende risico\u2019s kunnen per type verschillen. Het identificeren van deze risico\u2019s en het treffen van beheersmaatregelen is daarbij van belang. Dat geldt in het bijzonder als algoritmen en AI bijdragen aan de totstandkoming van overheidsbesluitvorming en impactvolle beslissingen die burgers en ondernemingen raken. </p> <p>Door bij publieke inkoop van software met algoritmen en AI rekening te houden met vereisten die voorkomen uit wet- en regelgeving, toepassen van publieke waarden, het type algoritme of AI en de potenti\u00eble risico\u2019s die ontstaan bij het gebruiken ervan, kunnen negatieve gevolgen worden voorkomen. Publieke inkoop speelt daarom een belangrijke rol bij de totstandkoming van verantwoord ontwikkelde algoritmen en AI en het gebruik daarvan door ambtenaren.  In dit deel van het Algoritmekader wordt nader ingegaan op deze vereisten. Er worden suggesties gedaan hoe deze vereisten kunnen worden nageleefd en welke rollen daarbij betrokken kunnen zijn. Waar mogelijk worden concrete voorbeelden uit de praktijk gegeven en zal worden aangegeven bij welk type algoritmen of AI dit relevant is.</p> <p>Het publiek inkopen van algoritmen en AI wordt ook gekoppeld aan de algoritme levenscyclus. Dit geeft een beeld van wanneer bepaalde vereisten en maatregelen, bij het ontwikkelen van algoritmen en AI, moeten worden geadresseerd. Door deze vereisten ook te vertalen naar het inkoopproces, zullen de rollen binnen het inkoopproces beter in staat zijn om te duiden wanneer en hoe dit kan worden geadresseerd. Dit moet bijdragen aan een goed samenspel met aanbieders, zodat de kansen van algoritmen en AI worden benut en de negatieve gevolgen worden voorkomen.  </p>"},{"location":"bouwblokken/publieke-inkoop/#algoritme-levenscyclus","title":"Algoritme levenscyclus","text":"<p>Algoritmen en AI kunnen een grote impact hebben op onze maatschappij. Daarom is het van belang dat deze op een verantwoorde manier worden ontwikkeld en gebruikt. Het toepassen van de algoritme levenscyclus is hierover een bruikbare leidraad. De algoritme levenscyclus bestaat uit meerdere fasen. De werkzaamheden die noodzakelijk zijn om een verantwoord algoritme of AI te ontwikkelen, kunnen logisch worden gekoppeld aan deze fasen.  Deze levenscyclus kan worden gebruikt voor alle typen algoritmen en AI. Het verschilt uiteraard wel per type wat moet worden gedaan en dit is mede afhankelijk van de risico classificatie. Bij hoge risico toepassing zal meer moeten worden gedaan om risico\u2019s te mitigeren dan als er sprake is van lage risico toepassingen. De levenscyclus geeft een bruikbaar overzicht voor leveranciers en opdrachtgevers wanneer welke werkzaamheden moeten worden uitgevoerd. Het laat ook zien welke werkzaamheden moeten zijn afgerond als algoritmen en AI in de markt mogen worden gezet en klaar zijn voor gebruik. </p> <p>Bij het publiek inkopen van software met bijbehorende algoritmen en AI zijn de wensen van de behoeftesteller en de doelstellingen van de organisatie van groot belang. Dit kan tot verschillende situaties leiden:</p> <p>\u2022   Een al ontwikkelde kant-en-klare oplossing voldoet direct aan deze wensen en doelstellingen;</p> <p>\u2022   Een al ontwikkelde oplossing moet eerst worden aangepast voordat deze kan worden gebruikt;</p> <p>\u2022   Er moet een nieuwe oplossing worden ontwikkeld om te voldoen aan de wensen. </p> <p>Deze inschatting is dus bepalend wat wel en niet van een product mag worden verwacht. Dit is relevant voor zowel de leverancier als de opdrachtgever. Het is aannemelijk dat als het om risicovolle (nog te ontwikkelen) algoritmen of AI gaat, de opdrachtgever een intensieve bijdrage moet leveren aan de samenwerking om het product te kunnen gebruiken. De opdrachtgever zal bijvoorbeeld moeten aangeven wat de juridische en ethische grenzen zijn van de uiteindelijk werking van het algoritme of AI. Als een kant-en-klare oplossing wordt afgenomen, dan zal de leverancier moeten laten zien dat de ontwikkelde algoritmen en AI voldoen aan alle vereisten en moet dit kunnen aantonen. </p> <p>De inzichten uit de algoritme levenscyclus kunnen ondersteunen bij bijvoorbeeld de behoeftestelling, het maken van make-or-buy beslissingen, de te hanteren aanbestedingsvorm, de totstandkoming van de selectie- en gunningseisen, contractspecificaties en de uitvoering en management van het contract. De algoritme levenscyclus kan worden geraadpleegd via het tabblad boven aan deze pagina. Per fase en per type algoritme of AI kan worden bekeken aan welke vereisten moet worden voldaan en welke beheersmaatregelen kunnen worden getroffen. </p>"},{"location":"bouwblokken/publieke-inkoop/#vereisten","title":"Vereisten","text":""},{"location":"bouwblokken/publieke-inkoop/#vereisten_1","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/publieke-inkoop/#maatregelen","title":"Maatregelen","text":"Vereisten Uitleg verplicht voor hoog-risico AI systemen (AI Act) verplicht voor impactvolle algoritmes verplicht voor niet-impactvolle algoritmes Archiveren De grondslag van de Archiefwet is dat, als de overheid de informatie bewaart die voortkomt uit de verschillende werkprocessen, aan de hand van deze informatie de werkprocessen kunnen worden gereconstrueerd en kan worden nagegaan hoe besluiten tot stand zijn gekomen. De oordeelsvorming over hoe zaken zijn verlopen kan dan worden overgelaten aan anderen Non-discriminatie Verbod op ongelijke behandeling in gelijke omstandigheden. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht of op welke grond dan ook, is niet toegestaan. Verbod schenden Auteursrechten Bepaalde vormen van algoritmen en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainingen en testen van algoritmen en AI. Deze data mag geen inbreuk maken op Auteursrechten. Ook de gegenereerde output van algoritmen en AI mag geen inbreuk maken op deze rechten. Kwaliteitsmanagementsysteem De  ontwikkelaar van een AI-systeem of een 'general purpose AI model' die deze op de markt plaatst zal een kwaliteitsmanagementsysteem toepassen waarmee wordt voldaan aan de verplichtingen die voortkomen uit de AI-verordening."},{"location":"bouwblokken/publieke-inkoop/#nuttige-informatie","title":"Nuttige informatie","text":"<p>Europese modelcontractbepalingen AI-systemen (hoog risico)</p> <p>Europese modelcontractbepalingen AI-systemen (niet hoog risico)</p> <p>Contractvoorwaarden voor algoritmen gemeente Amsterdam</p>"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/","title":"Technische robuustheid en veiligheid","text":"<p>Hier komt een beschrijving van dit bouwblok</p>"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmen en aiVolgens de archiefwet moeten overheden informatie bewaren op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en ai, tot stand zijn gekomen informatie over en van algoritmen en ai moet daarom ook bewaard en vernietigd wordenInformatie en informatiesystemen van de overheid moet worden beveiligdInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen in nederland is besloten dat overheidsinstellingen de baseline informatiebeveiliging overheid dienen toe te passen over hun informatie en informatiesystemen de bio beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn algoritmen en ai-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de bio op van toepassing is het is van belang om algoritmische toepassingen en ai-systemen op de juiste manier te beveiligen"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/transparantie/","title":"Transparantie","text":"<p>Hier komt een beschrijving van dit bouwblok.</p>"},{"location":"bouwblokken/transparantie/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/transparantie/#maatregelen","title":"Maatregelen","text":""},{"location":"instrumenten/","title":"Instrumenten","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Het Algoritmekader is tot stand gekomen op basis van de volgende instrumenten:</p> Naam instrument Categorie Jaartal uitgebracht Verantwoordelijke organisatie Ontwikkeld door null null Ontwikkeld voor null null Voor overheidsorganisatie specfiek Volwassenheidsniveau Locatie Doel null null null Mogelijke wettelijke verplichting Toelichting doel Toepassing overheid wetenschap overig overheid wetenschap overig Informerend Sturend Normerend Faciliterend technologie algemeen Impact Assessment Mensenrechten en Algoritmes Impact Assessment 2021 Universiteit Utrecht ja ja ja ja In gebruik Internationaal \u00b1 - - + ja Dit impact assessment werkt in eerste instantie faciliterend voor het gesprek. Maar biedt ook veel informatie. \u00b1 Handreiking Non-discriminatie by Design Handleiking/leidraad 2021 Binnenlandse Zaken ja ja nee ja ja ja In gebruik Nationaal + + - \u00b1 nee Deze handreiking is bedoeld voor projectleiders die sturing geven aan systeembouwers, data-analisten en AI-experts op het gebied van het discriminatieverbod. - De Ethische Data Assistent (DEDA) Handleiking/leidraad 2022 Utrecht Data School nee ja nee ja ja ja In gebruik Nationaal + - - + nee DEDA helpt data-analisten, projectmanagers en beleidsmakers om samen ethische problemen in dataprojecten, datamanagement en databeleid te herkennen. - Toetsingskader Algoritmes Algemene Rekenkamer Toetsingskader 2020 Algemene Rekenkamer ja nee nee ja ja ja In gebruik Nationaal + + - - nee Dit toetsingskader is een instrument dat aandacht besteedt aan de relevante perspectieven op algoritmes. Met een vertaling van normenkaders en richtlijnen naar verschillende aspecten waarop algoritmes kunnen worden getoetst. Een instrument dat bovendien rekening houdt met de risico\u2019s en de onderzoeksvragen die in een toetsingskader aan bod moeten komen. - Baseline Informatiebeveiliging Overheid Wet- en regelgeving 2018 Binnenlandse Zaken ja nee nee ja nee nee In gebruik Nationaal - - + - ja De Baseline Informatiebeveiliging Overheid (BIO) is het basisnormenkader voor informatiebeveiliging binnen alle overheidslagen (Rijk, gemeenten, provincies en waterschappen). + Framework for Meaningful Engagement Handleiking/leidraad 2023 Action Coalition on Civic Engagement for AI (Denemarken) ja nee ja ja ja ja In gebruik Internationaal + \u00b1 - + nee Dit kader is gecre\u00eberd om iedereen die producten of diensten ontwerpt met behulp van AI, machine learning of op algoritme-gebaseerde gegegevensanalyse in staat te stellen belanghebbenden bij dat proces te betrekken. \u00b1 Waarborgen Selectie-Instrumenten voor de Belastingdienst Handleiking/leidraad 2023 Belastingdienst ja nee nee ja nee nee Financi\u00ebn (Fin) In gebruik Nationaal + + \u00b1 - nee Een waarborgenkader voor selectie-instrumenten waarmee de rechtmatigheid en transparantie van de instrumenten (beter) gegarandeerd kunnen worden. + Modelbepalingen en toelichting voor verantwoord gebruik van algoritme door de overheid (contractvoorwaarden) Handleiking/leidraad 2022 Gemeente Amsterdam ja nee nee ja nee nee Gemeenten In gebruik Nationaal + + \u00b1 - nee + AI Impact Assessment Handleiking/leidraad 2022 Infrastructuur en Waterstaat ja nee nee ja ja ja In gebruik Nationaal \u00b1 - - + nee Het AI Impact Assessment (AIIA) is een hulpmiddel voor het maken van afwegingen bij het inzetten van kunstmatige intelligentie (artificial intelligence, AI) in een project. Het AIIA dient als instrument voor het gesprek en het vastleggen van het denkproces zodat onder andere de verantwoording, kwaliteit en reproduceerbaarheid worden vergroot. - Artificial Intelligence Impact Assessment Handleiking/leidraad 2018 ECP nee nee ja ja ja ja In gebruik Nationaal \u00b1 - - + nee De Artificial Intelligence Impact Assessment (AIIA) helpt bedrijven artificial intelligence verantwoord in te zetten, nu slimme algoritmes steeds vaker taken van mensen overnemen. Aan de hand van een stappenplan, bestaande uit acht stappen, maken bedrijven inzichtelijk welke juridische en ethische normen een rol spelen bij de ontwikkeling en inzet van AI-toepassingen, en welke afwegingen ten grondslag liggen aan keuzes en besluiten. - Data Protection Impact Assessment Impact Assessment 2018 Autoriteit Persoonsgegevens ja nee nee ja ja ja In gebruik Nationaal - - + - ja Is een organisatie van plan persoonsgegevens te verwerken, maar levert dat waarschijnlijk een hoog privacyrisico op? Dan is de organisatie verplicht eerst een 'data protection impact assessment' (DPIA) uit te voeren. Een DPIA is een instrument om vooraf de privacyrisico\u2019s van een gegevensverwerking in kaart te brengen. + The Fairness Handbook Handleiking/leidraad 2022 Gemeente Amsterdam ja nee nee ja ja ja In gebruik Nationaal + \u00b1 - \u00b1 nee The Fairness Handbook is uitgebracht door de gemeente Amsterdam om bias in algoritmische systemen te minimaliseren en fairness te maximaliseren. Het handboek legt uit hoe vooroordelen en andere problemen rondom fairness tijdens de ontwikkeling van algoritmes kunnen voorkomen en wat hieraan gedaan kan worden. - Ethics Guideline for Trustworthy AI Handleiking/leidraad 2019 EU High-Level Expert Group on AI ja nee nee ja ja ja In gebruik Internationaal \u00b1 + - - nee Deze richtlijnen, opgesteld door leden van de 'high level expert group on AI', hebben als doel gebruikers te begeleiden in het ontwikkelen van betrouwbare AI. Hiervoor worden drie domeinen belicht; juridisch, ethisch en robuustheid. - Norea Guiding Principles Trustworthy AI Investigations Handleiking/leidraad 2021 Norea Beroepsorganisatie van IT-auditors nee nee ja ja ja ja In gebruik Internationaal \u00b1 + - - nee -"},{"location":"levenscyclus/","title":"Levenscyclus","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Algoritmen en kunstmatige intelligentie zijn \u2018producten\u2019 die door overheidsinstellingen kunnen worden gebruikt om de uitvoering van wettelijke taken te ondersteunen. Deze producten doorlopen een zogenaamde levenscyclus. Een algoritme wordt ontwikkeld en na enige tijd van gebruik kan worden besloten het gebruik ervan te be\u00ebindigen. Een krachtig aspect van de \u2018algoritme levenscyclus\u2019 is dat de levenscyclus voor alle gevallen nagenoeg hetzelfde is. Daarmee is het bruikbaar als leidraad om relevante informatie te structureren en  te communiceren. Het is tegelijkertijd een brug tussen de technische kant van het product en de wereld van gebruikers. Om tot een wettige, ethisch verantwoorde en robuuste oplossing te komen zullen in elke fase van de algoritme levenscyclus specifieke handelingen of maatregelen moeten worden getroffen.  </p> <p></p>"},{"location":"levenscyclus/archiveren/","title":"Archiveren","text":"<p>Wanneer het AI-model niet langer nodig is of wordt vervangen door een verbeterde versie, wordt het gearchiveerd. Dit omvat het behouden van documentatie en eventuele relevante artefacten.</p>"},{"location":"levenscyclus/archiveren/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmen en aiVolgens de archiefwet moeten overheden informatie bewaren op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en ai, tot stand zijn gekomen informatie over en van algoritmen en ai moet daarom ook bewaard en vernietigd wordenBewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het ai-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periodeBewaartermijn voor gegenereerde logsAanbieders van ai-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplicht"},{"location":"levenscyclus/archiveren/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/","title":"Dataverkenning en datapreparatie","text":"<p>In deze fase worden relevante datasets geidentificeerd en genaliseerd om inziichten te krijgen. Daarna worden de gegevens verzameld, gereinigd en voorbereid voor gebruik.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#vereisten","title":"Vereisten","text":"VereisteUitlegVerbod op schenden auteursrechtenBepaalde vormen van algoritmen en ai worden ontwikkeld op basis van grote hoeveelheden data deze data wordt gebruikt voor het trainen en testen van algoritmen en ai het gebruiken van deze data mag geen inbreuk maken op auteursrechten van diegene die deze rechten heeft ook de gegenereerde output van algoritmen en ai mag geen inbreuk maken op deze rechtenAutomatische logregistratie voor hoog-risico aiAi-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren, wat vaak wordt aangeduid als \"logs\" deze logs bieden een traceerbaarheidsmechanisme waarmee exploitanten en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken het doel van deze registratie is om de transparantie en verantwoordingsplicht van ai-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetertBeperkte bewaartermijn van persoonsgegevensGegevens mogen niet langer worden bewaard dan nodig is voor het beoogde doel, zoals vereist door het principe van opslagbeperking deze maatregel waarborgt dat persoonsgegevens niet langer worden bewaard dan strikt noodzakelijk is, waardoor risico's met betrekking tot gegevensbescherming worden verminderd en de privacy van individuen wordt beschermd het naleven van de opslagbeperking draagt bij aan een effici\u00ebnte gegevensverwerking en bevordert het vertrouwen van individuen in hoe hun gegevens worden beheerdBeschermen van persoonsgegevensVoor de ontwikkeling en gebruik van algoritmen en ai is dat nodig deze data kan persoonsgegevens bevatten deze persoonsgegevens moeten worden beschermd de organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of ai-systeem voldoende te beschermen hierbij kan worden gedacht aan dataminimalisatie, het pseudonomiseren of aggregeren van persoonsgegevens per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijnBescherming van kwetsbare groepenBescherm de privacy van kinderen en kwetsbare groepen door ervoor te zorgen dat de verwerking van hun persoonsgegevens voldoet aan de algemene verordening gegevensbescherming (avg) dit omvat het nemen van passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens veilig en rechtmatig is, en dat de rechten van deze groepen worden gerespecteerd het waarborgen van privacy voor deze groepen draagt bij aan een veilige en vertrouwde online omgeving waarin hun gegevens worden beschermdBeschrijven en toewijzen van verantwoordelijkhedenBij het verwerken van persoonsgegevens voor algoritmen en ai-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn de verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergrotenVerbod op schenden databankenrechtenHet databankenrecht beschermt tegen kopi\u00ebren of oneigenlijk gebruik van gegevens in een databank degene die een substanti\u00eble financi\u00eble investering heeft verricht om de databank tot stand te brengen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken voor het ontwikkelen van algoritme en ai is data nodig de data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databankDocumentatie beoordeling niet-hoog-risico aiEen aanbieder die oordeelt dat een ai-systeem geen hoog risico vormt, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem en voldoet aan de registratievereisten op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordelingNoneNoneGeb/dpia verplicht bij hoog risicoEen gegevensbeschermingseffectbeoordeling (geb) of data protection impact assessment (dpia) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgdGerichte doelverzamelingPersoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerkingJuistheid en actualiteit van gegevensDe te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevensVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatPersoonsgegeven worden rechtmatig, behoorlijk en transparant verwerktDe verwerking van persoonsgegevens moet eerlijk en rechtmatig plaatsvinden, wat betekent dat het voldoet aan de principes van rechtmatigheid, behoorlijkheid en transparantie dit houdt in dat de verwerking gebaseerd moet zijn op een van de wettelijke grondslagen die zijn vastgesteld in de algemene verordening gegevensbescherming (avg)"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/implementatie/","title":"Implementatie","text":"<p>In deze fase wordt het AI-model in de praktijk gebracht en ge\u00efntegreerd in het bedrijfsproces. Het wordt operationeel en begint te werken met echte gegevens.</p>"},{"location":"levenscyclus/implementatie/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmen en aiVolgens de archiefwet moeten overheden informatie bewaren op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en ai, tot stand zijn gekomen informatie over en van algoritmen en ai moet daarom ook bewaard en vernietigd wordenInformatie en informatiesystemen van de overheid moet worden beveiligdInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen in nederland is besloten dat overheidsinstellingen de baseline informatiebeveiliging overheid dienen toe te passen over hun informatie en informatiesystemen de bio beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn algoritmen en ai-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de bio op van toepassing is het is van belang om algoritmische toepassingen en ai-systemen op de juiste manier te beveiligenKlachten indienen bij markttoezichtautoriteitNaast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en aiMelden van ernstige incidentenAanbieders van ai-systemen met een hoog risico die binnen de eu worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze ai-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek het doel is om de veiligheid en betrouwbaarheid van ai-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliserenVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat"},{"location":"levenscyclus/implementatie/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/monitoren/","title":"Monitoren","text":"<p>Het AI-model wordt voortdurend gemonitord om ervoor te zorgen dat het blijft presteren zoals verwacht. Eventuele afwijkingen of degradatie van prestaties worden ge\u00efdentificeerd en aangepakt.</p>"},{"location":"levenscyclus/monitoren/#vereisten","title":"Vereisten","text":"VereisteUitlegInformatie en informatiesystemen van de overheid moet worden beveiligdInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen in nederland is besloten dat overheidsinstellingen de baseline informatiebeveiliging overheid dienen toe te passen over hun informatie en informatiesystemen de bio beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn algoritmen en ai-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de bio op van toepassing is het is van belang om algoritmische toepassingen en ai-systemen op de juiste manier te beveiligenBewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het ai-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periodeBewaartermijn voor gegenereerde logsAanbieders van ai-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplichtCorrigerende maatregelen voor non-conforme aiAanbieders van ai-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem ze moeten ook alle relevante partijen, zoals distributeurs, exploitanten en importeurs, op de hoogte stellen van deze maatregelenKlachten indienen bij markttoezichtautoriteitNaast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en aiMelden van ernstige incidentenAanbieders van ai-systemen met een hoog risico die binnen de eu worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze ai-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek het doel is om de veiligheid en betrouwbaarheid van ai-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliserenVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat"},{"location":"levenscyclus/monitoren/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/ontwerp/","title":"Ontwerp","text":"<p>Hier wordt het conceptuele ontwerp van het AI-systeem gemaakt. Dit omvat het bepalen van de architectuur, algoritmen en benodigde middelen voor de implementatie.</p>"},{"location":"levenscyclus/ontwerp/#vereisten","title":"Vereisten","text":"VereisteUitlegVerbod op schenden auteursrechtenBepaalde vormen van algoritmen en ai worden ontwikkeld op basis van grote hoeveelheden data deze data wordt gebruikt voor het trainen en testen van algoritmen en ai het gebruiken van deze data mag geen inbreuk maken op auteursrechten van diegene die deze rechten heeft ook de gegenereerde output van algoritmen en ai mag geen inbreuk maken op deze rechtenBeperkte bewaartermijn van persoonsgegevensGegevens mogen niet langer worden bewaard dan nodig is voor het beoogde doel, zoals vereist door het principe van opslagbeperking deze maatregel waarborgt dat persoonsgegevens niet langer worden bewaard dan strikt noodzakelijk is, waardoor risico's met betrekking tot gegevensbescherming worden verminderd en de privacy van individuen wordt beschermd het naleven van de opslagbeperking draagt bij aan een effici\u00ebnte gegevensverwerking en bevordert het vertrouwen van individuen in hoe hun gegevens worden beheerdBescherming van kwetsbare groepenBescherm de privacy van kinderen en kwetsbare groepen door ervoor te zorgen dat de verwerking van hun persoonsgegevens voldoet aan de algemene verordening gegevensbescherming (avg) dit omvat het nemen van passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens veilig en rechtmatig is, en dat de rechten van deze groepen worden gerespecteerd het waarborgen van privacy voor deze groepen draagt bij aan een veilige en vertrouwde online omgeving waarin hun gegevens worden beschermdBeschrijven en toewijzen van verantwoordelijkhedenBij het verwerken van persoonsgegevens voor algoritmen en ai-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn de verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergrotenInformatie en informatiesystemen van de overheid moet worden beveiligdInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen in nederland is besloten dat overheidsinstellingen de baseline informatiebeveiliging overheid dienen toe te passen over hun informatie en informatiesystemen de bio beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn algoritmen en ai-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de bio op van toepassing is het is van belang om algoritmische toepassingen en ai-systemen op de juiste manier te beveiligenBevorder ai-geletterdheid personeelAanbieders en exploitanten van ai-systemen nemen maatregelen om ervoor te zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van ai dit omvat het overwegen van technische kennis, ervaring, onderwijs en opleiding van individuen, evenals de context waarin de ai-systemen worden gebruikt en de gebruikers van deze systemen het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van ai en het minimaliseren van risico'sBewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het ai-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periodeBewaartermijn voor gegenereerde logsAanbieders van ai-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplichtCorrigerende maatregelen voor non-conforme aiAanbieders van ai-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem ze moeten ook alle relevante partijen, zoals distributeurs, exploitanten en importeurs, op de hoogte stellen van deze maatregelenVerbod op schenden databankenrechtenHet databankenrecht beschermt tegen kopi\u00ebren of oneigenlijk gebruik van gegevens in een databank degene die een substanti\u00eble financi\u00eble investering heeft verricht om de databank tot stand te brengen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken voor het ontwikkelen van algoritme en ai is data nodig de data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databankDocumentatie beoordeling niet-hoog-risico aiEen aanbieder die oordeelt dat een ai-systeem geen hoog risico vormt, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem en voldoet aan de registratievereisten op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordelingNoneNoneGeb/dpia verplicht bij hoog risicoEen gegevensbeschermingseffectbeoordeling (geb) of data protection impact assessment (dpia) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgdGerichte doelverzamelingPersoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerkingJuistheid en actualiteit van gegevensDe te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevensVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatPersoonsgegeven worden rechtmatig, behoorlijk en transparant verwerktDe verwerking van persoonsgegevens moet eerlijk en rechtmatig plaatsvinden, wat betekent dat het voldoet aan de principes van rechtmatigheid, behoorlijkheid en transparantie dit houdt in dat de verwerking gebaseerd moet zijn op een van de wettelijke grondslagen die zijn vastgesteld in de algemene verordening gegevensbescherming (avg)NoneVoor zover strikt noodzakelijk voor het detecteren en corrigeren van vooringenomenheid met betrekking tot ai-systemen met een hoog risico, mogen aanbieders van dergelijke systemen uitzonderlijk speciale categorie\u00ebn persoonsgegevens verwerken deze verwerking moet gepaard gaan met passende waarborgen voor de fundamentele rechten en vrijheden van natuurlijke personen"},{"location":"levenscyclus/ontwerp/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/ontwikkelen/","title":"Ontwikkelen","text":"<p>Dit is de fase waarin het AI-model of algoritme wordt gebouwd. Als het gaat om AI-modellen, omvat het trainen van modellen met behulp van de voorbereide gegevens.</p>"},{"location":"levenscyclus/ontwikkelen/#vereisten","title":"Vereisten","text":"VereisteUitlegAutomatische logregistratie voor hoog-risico aiAi-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren, wat vaak wordt aangeduid als \"logs\" deze logs bieden een traceerbaarheidsmechanisme waarmee exploitanten en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken het doel van deze registratie is om de transparantie en verantwoordingsplicht van ai-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetertBeperkte bewaartermijn van persoonsgegevensGegevens mogen niet langer worden bewaard dan nodig is voor het beoogde doel, zoals vereist door het principe van opslagbeperking deze maatregel waarborgt dat persoonsgegevens niet langer worden bewaard dan strikt noodzakelijk is, waardoor risico's met betrekking tot gegevensbescherming worden verminderd en de privacy van individuen wordt beschermd het naleven van de opslagbeperking draagt bij aan een effici\u00ebnte gegevensverwerking en bevordert het vertrouwen van individuen in hoe hun gegevens worden beheerdBeschermen van persoonsgegevensVoor de ontwikkeling en gebruik van algoritmen en ai is dat nodig deze data kan persoonsgegevens bevatten deze persoonsgegevens moeten worden beschermd de organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of ai-systeem voldoende te beschermen hierbij kan worden gedacht aan dataminimalisatie, het pseudonomiseren of aggregeren van persoonsgegevens per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijnBescherming van kwetsbare groepenBescherm de privacy van kinderen en kwetsbare groepen door ervoor te zorgen dat de verwerking van hun persoonsgegevens voldoet aan de algemene verordening gegevensbescherming (avg) dit omvat het nemen van passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens veilig en rechtmatig is, en dat de rechten van deze groepen worden gerespecteerd het waarborgen van privacy voor deze groepen draagt bij aan een veilige en vertrouwde online omgeving waarin hun gegevens worden beschermdBeschrijven en toewijzen van verantwoordelijkhedenBij het verwerken van persoonsgegevens voor algoritmen en ai-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn de verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergrotenBewaartermijn voor gegenereerde logsAanbieders van ai-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplichtCorrigerende maatregelen voor non-conforme aiAanbieders van ai-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem ze moeten ook alle relevante partijen, zoals distributeurs, exploitanten en importeurs, op de hoogte stellen van deze maatregelenDocumentatie beoordeling niet-hoog-risico aiEen aanbieder die oordeelt dat een ai-systeem geen hoog risico vormt, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem en voldoet aan de registratievereisten op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordelingGeb/dpia verplicht bij hoog risicoEen gegevensbeschermingseffectbeoordeling (geb) of data protection impact assessment (dpia) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgdGerichte doelverzamelingPersoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerkingJuistheid en actualiteit van gegevensDe te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevens"},{"location":"levenscyclus/ontwikkelen/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/probleemanalyse/","title":"Probleemanalyse","text":"<p>In deze fase wordt het probleem gedefinieerd dat moet worden opgelost. Het omvat het begrijpen van de vereisten, doelstellingen en beperkingen van het probleem.</p>"},{"location":"levenscyclus/probleemanalyse/#vereisten","title":"Vereisten","text":"VereisteUitlegBevorder ai-geletterdheid personeelAanbieders en exploitanten van ai-systemen nemen maatregelen om ervoor te zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van ai dit omvat het overwegen van technische kennis, ervaring, onderwijs en opleiding van individuen, evenals de context waarin de ai-systemen worden gebruikt en de gebruikers van deze systemen het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van ai en het minimaliseren van risico'sNoneNoneGerichte doelverzamelingPersoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerkingJuistheid en actualiteit van gegevensDe te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevensVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaatPersoonsgegeven worden rechtmatig, behoorlijk en transparant verwerktDe verwerking van persoonsgegevens moet eerlijk en rechtmatig plaatsvinden, wat betekent dat het voldoet aan de principes van rechtmatigheid, behoorlijkheid en transparantie dit houdt in dat de verwerking gebaseerd moet zijn op een van de wettelijke grondslagen die zijn vastgesteld in de algemene verordening gegevensbescherming (avg)NoneVoor zover strikt noodzakelijk voor het detecteren en corrigeren van vooringenomenheid met betrekking tot ai-systemen met een hoog risico, mogen aanbieders van dergelijke systemen uitzonderlijk speciale categorie\u00ebn persoonsgegevens verwerken deze verwerking moet gepaard gaan met passende waarborgen voor de fundamentele rechten en vrijheden van natuurlijke personen"},{"location":"levenscyclus/probleemanalyse/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/validatie/","title":"Validatie","text":"<p>Nadat het model is ontwikkeld, wordt het gevalideerd om ervoor te zorgen dat het goed presteert op nieuwe, niet eerder geziene gegevens. Dit omvat het evalueren van de nauwkeurigheid en prestaties van het model. Validatie is een interatief proces dat plaatsvindt op verschillende momenten van de levenscyclus.</p>"},{"location":"levenscyclus/validatie/#vereisten","title":"Vereisten","text":"VereisteUitlegBeschrijven en toewijzen van verantwoordelijkhedenBij het verwerken van persoonsgegevens voor algoritmen en ai-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn de verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergrotenGeb/dpia verplicht bij hoog risicoEen gegevensbeschermingseffectbeoordeling (geb) of data protection impact assessment (dpia) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgdKlachten indienen bij markttoezichtautoriteitNaast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en aiMelden van ernstige incidentenAanbieders van ai-systemen met een hoog risico die binnen de eu worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze ai-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek het doel is om de veiligheid en betrouwbaarheid van ai-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliserenVerbod op discriminatieOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of ai wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat"},{"location":"levenscyclus/validatie/#maatregelen","title":"Maatregelen","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"maatregelen/","title":"Maatregelen","text":"<p>Hier komt een overzicht van alle maatregelen.</p>"},{"location":"overhetalgoritmekader/","title":"Over het algoritmekader","text":"<p>Overheidsorganisaties moeten weten wat de eisen zijn voor verantwoorde inzet van algoritmes. Er zijn al verschillende instrumenten ontwikkeld die helpen wet- en regelgeving beter toe te passen.\u00a0Het algoritmekader gaat prioriteiten aanbrengen in deze instrumenten en stroomlijnt ze, zodat overheden in alle fasen van de levenscyclus van algoritmische toepassingen praktische handvatten hebben. Best practices, use cases en input van eindgebruikers en de toezichthouder helpen tot een goed en gedragen algoritmekader voor alle overheden te komen.</p> <p>7 juli 2023 is het concept Implementatiekader naar de kamer verstuurd, vergezeld door de Kamerbrief 'Verzamelbrief Algoritmes Reguleren'.</p>"},{"location":"overhetalgoritmekader/#uitgangspunt-publieke-waarden-mensenrechten-en-ethische-principes","title":"Uitgangspunt: Publieke waarden, mensenrechten en ethische principes","text":"<p>Het verantwoord inzetten van algoritmen betekent dat de inzet wettig, ethisch en robuust is. Dit betekent dat ten minste voldaan moet worden aan wet- en regelgeving en dat de inzet in lijn is met publieke waarden en ethische principes. Het algoritmekader neemt dit dan ook als uitgangspunt.</p> <p>Voor de structuur is aangesloten op de ethische richtsnoeren die ook een basis vormen voor de Europese AI Verordening. Deze richtsnoeren omvatten belangrijke publieke waarden zoals menselijke controle, rechtvaardigheid, privacy en non-discriminatie. In deze thema\u2019s zijn de belangrijkste bestaande verplichtingen en richtlijnen in kaart gebracht, en worden maatregelen en waarborgen aangereikt. </p>"},{"location":"overhetalgoritmekader/#doorontwikkeling","title":"Doorontwikkeling","text":"<p>Hoe deze governance (waaronder een heldere verdeling van bevoegdheden en verantwoordelijkheden) binnen de overheid invulling krijgt, is nog onderwerp van gesprek. Dit wordt  meegenomen in de verdere doorontwikkeling van het algoritmekader.</p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"overhetalgoritmekader/definities/","title":"Definities","text":"<p>Welke definities gebruikt het Algoritmekader? Je vindt een overzicht op deze pagina. Deze definities komen overeen met de definities van het het Algoritmeregister, zie daarvoor de Handreiking Algoritmeregister</p>"},{"location":"overhetalgoritmekader/definities/#definitie-van-een-algoritme","title":"Definitie van een algoritme","text":"<p>Er zijn veel definities van een algoritme. Voor het algoritmekader hanteren we de definitie van de Algemene Rekenkamer:</p> <p>'Een set van regels en instructies die een computer geautomatiseerd volgt bij het maken van berekeningen om een probleem op te lossen of een vraag te beantwoorden.\u2019</p> <p>Dit is een brede definitie die de maximale reikwijdte weergeeft van algoritmes waarvoor het Algoritmekader relevant is. Waar de definitie van de Algemene Rekenkamer schrijft \u201com een probleem op te lossen of een vraag te beantwoorden\u201d, verstaan we daar ook onder \u201com een taak of proces uit te voeren of tot een besluit te komen\u201d. In het uitvoeren van een taak of het komen tot een besluit kunnen \u00e9\u00e9n of meer algoritmes voorkomen. Daarnaast hebben we het bij het Algoritmekader over zowel Artifici\u00eble Intelligentie (AI) als algoritmes. De essentie is dat AI is opgebouwd uit algoritmes. Maar niet alle algoritmes zijn AI. </p> <p></p> <p>Gebruikte terminologie</p> <p>De termen hoog-risico, impactvol, AI en Algoritmes worden veel door elkaar gebruikt. Wij hanteren uitsluitend de volgende twee termen:</p> <ol> <li> <p>Hoog-risico AI (-systeem)  Hiermee bedoelen we altijd de definitie zoals deze in de AI-verordening wordt gehanteerd.</p> </li> <li> <p>Impactvolle algoritmes Dit betreft de minimale reikwijdte van het Algoritmekader. Het omvat de hoog-risico AI-systemen zoals gedefinieerd in de AI-verordening \u00e9n de algoritmes die we daarnaast als impactvol beschouwen. </p> </li> </ol>"},{"location":"overhetalgoritmekader/definities/#relatie-scope-algoritmekader-en-de-ai-verordening","title":"Relatie scope Algoritmekader en de AI-Verordening","text":"<p>Op dit moment wordt op EU-niveau de AI-verordening ontwikkeld, die naar verwachting van toepassing wordt op een deel van de algoritmes in gebruik bij de overheid. In de AI-verordening zijn AI-systemen onderverdeeld in verschillende categorie\u00ebn: verboden praktijken, hoog-risico AI-systemen, AI-systemen met manipulatierisico\u2019s en AI-systemen met geen/minimale risico\u2019s. Afhankelijk van de categorie waarin een AI-systeem valt, gelden zwaardere of minder zware eisen waar die systemen aan moeten voldoen.</p> <p>Het Algoritmekader is hoe dan ook relevant voor hoog-risico AI-systemen volgens de definitie van de AI-verordening. Een AI-systeem is hoog-risico als het voldoet aan de volgende eisen: 1. Het AI-systeem valt onder de definitie van AI-systemen in artikel 3 lid 1 van de verordening en moet o.a. autonome elementen bevatten, en</p> <ol> <li>Het AI-systeem wordt in een van de toepassingsgebieden van ANNEX III ingezet zoals biometrie, kritieke infrastructuur en rechtshandhaving. Bovenstaande betreft een versimpelde beschrijving van de AI-verordening. In bijlage 2 van de Handreiking Algoritmeregister is meer informatie te vinden over de AI-verordening. Aangezien de AI-verordening nog in onderhandeling is, bestaat de kans dat de classificatie van hoog-risico AI-systemen nog wordt aangepast. </li> </ol>"},{"location":"overhetalgoritmekader/definities/#definitie-van-impactvolle-algoritmes","title":"Definitie van impactvolle algoritmes","text":"<p>Om te bepalen of een algoritme in aanmerking komt voor publicatie in het Algoritmeregister, is een hulpmiddel 'Selectie' gemaakt. Het zijn dezelfde algoritmes die relevant zijn voor het Algoritmekader. Dit hulpmiddel wordt hieronder weergegeven in de figuur, en is ook leidend voor het Algoritmekader.</p> <p></p> <p>Voor meer toelichting over dit hulpmiddel verwijzen we naar de Handreiking Algoritmeregister. </p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/","title":"Rollen","text":"<p>Hier komt een overzicht van alle rollen.</p>"},{"location":"rollen/data-scientist/","title":"Data scientist","text":""},{"location":"rollen/data-scientist/#title-data-scientist","title":"title: Data scientist","text":""},{"location":"vereisten/","title":"Vereisten","text":"<p>Hier komt een lijst van de vereisten.</p>"},{"location":"vereisten/archiefwet/","title":"De archiefwet is ook van toepassing op algoritmen en ai","text":"<p>ArchiverenImplementatieTechnische robuustheid en veiligheidGovernanceDataPrivacy en gegevensbescherming</p>"},{"location":"vereisten/archiefwet/#vereiste","title":"Vereiste","text":"<p>Overheidsorganen zijn verplicht de onder hen berustende archiefbescheiden in goede, geordende en toegankelijke staat te brengen en te bewaren, alsmede zorg te dragen voor de vernietiging van de daarvoor in aanmerking komende archiefbescheiden.</p>"},{"location":"vereisten/archiefwet/#toelichting","title":"Toelichting","text":"<p>Volgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmen en AI, tot stand zijn gekomen. Informatie over en van algoritmen en AI moet daarom ook bewaard en vernietigd worden.</p>"},{"location":"vereisten/archiefwet/#bronnen","title":"Bronnen","text":"Bron Artikel 3 Archiefwet Artikel 15 lid 2 Archiefwet Archiefbesluit 1995 Archiefregeling"},{"location":"vereisten/archiefwet/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/archiefwet/#risico","title":"Risico","text":"<p>Zonder goede toepassing van de Archiefwet is het voor betrokkene(n) of derden niet mogelijk om achteraf te reconstrueren en te controleren hoe besluiten, waar algoritmen en AI aan hebben bijgedragen, tot stand zijn gekomen. Het nalaten om archiefbescheiden na verloop van tijd te verwijderen brengt risico's met zich mee op het gebied van privacy en informatiebeveiliging </p>"},{"location":"vereisten/archiefwet/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/archiefwet/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/auteursrechten/","title":"Verbod op schenden auteursrechten","text":"<p>Dataverkenning en datapreparatieOntwerpDataGovernance</p>"},{"location":"vereisten/auteursrechten/#vereiste","title":"Vereiste","text":"<p>Auteursrechten mogen niet geschonden worden bij het ontwikkelen en gebruiken van algoritmen en AI.</p>"},{"location":"vereisten/auteursrechten/#toelichting","title":"Toelichting","text":"<p>Bepaalde vormen van algoritmen en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmen en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmen en AI mag geen inbreuk maken op deze rechten.</p>"},{"location":"vereisten/auteursrechten/#bronnen","title":"Bronnen","text":"Bron Artikel 1 Auteurswet Artikel 4-9 Auteurswet Artikel 10 Auteurswet Artikel 13 Auteurswet Artikel 15n jo. 15o Auteurswet Artikel 3 en 4 van de DSM-richtlijn (EU 2019/790)"},{"location":"vereisten/auteursrechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/auteursrechten/#risico","title":"Risico","text":"<p>Het is onduidelijk of de ontwikkelaar van het algoritme of AI voldoende rekening heeft gehouden met de rechten van auteurs wiens werken al dan niet zijn gebruikt als trainingsdata voor het ontwikkelde algoritme of AI. Daardoor ontstaat het risico, bv. bij scraping van data van het internet, dat auteursrechten worden geschonden.</p>"},{"location":"vereisten/auteursrechten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/auteursrechten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/automatische_logregistratie/","title":"Automatische logregistratie voor hoog-risico ai","text":"<p>Dataverkenning en datapreparatieOntwikkelenGovernance</p>"},{"location":"vereisten/automatische_logregistratie/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).</p>"},{"location":"vereisten/automatische_logregistratie/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren, wat vaak wordt aangeduid als \"logs\". Deze logs bieden een traceerbaarheidsmechanisme waarmee exploitanten en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken. Het doel van deze registratie is om de transparantie en verantwoordingsplicht van AI-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetert.</p>"},{"location":"vereisten/automatische_logregistratie/#bronnen","title":"Bronnen","text":"Bron Artikel 12(1) Registratie- AI verordening"},{"location":"vereisten/automatische_logregistratie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/automatische_logregistratie/#risico","title":"Risico","text":"<p>Ontbreken van automatische logregistratie kan leiden tot een gebrek aan transparantie en traceerbaarheid van het AI-systeem, wat het vermogen om verantwoordelijkheid te nemen en eventuele problemen aan te pakken belemmert.</p>"},{"location":"vereisten/automatische_logregistratie/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/automatische_logregistratie/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/","title":"Beperkte bewaartermijn van persoonsgegevens","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Gegevens worden niet langer bewaard dan nodig (opslagbeperking)</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Gegevens mogen niet langer worden bewaard dan nodig is voor het beoogde doel, zoals vereist door het principe van opslagbeperking. Deze maatregel waarborgt dat persoonsgegevens niet langer worden bewaard dan strikt noodzakelijk is, waardoor risico's met betrekking tot gegevensbescherming worden verminderd en de privacy van individuen wordt beschermd. Het naleven van de opslagbeperking draagt bij aan een effici\u00ebnte gegevensverwerking en bevordert het vertrouwen van individuen in hoe hun gegevens worden beheerd.</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 onder e AVG"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#risico","title":"Risico","text":""},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bescherming_persoonsgegevens/","title":"Beschermen van persoonsgegevens","text":"<p>Dataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbeschermingData</p>"},{"location":"vereisten/bescherming_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Rekening houdend met de stand van de techniek, de uitvoeringskosten, alsook met de aard, de omvang, de context en de verwerkingsdoeleinden en de qua waarschijnlijkheid en ernst uiteenlopende risico's voor de rechten en vrijheden  van personen, treffen de verwerkingsverantwoordelijke en de verwerker passende technische en organisatorische maatregelen om een op het risico afgestemd beveiligingsniveau te waarborgen.</p>"},{"location":"vereisten/bescherming_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Voor de ontwikkeling en gebruik van algoritmen en AI is dat nodig. Deze data kan persoonsgegevens bevatten. Deze persoonsgegevens moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonomiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.</p>"},{"location":"vereisten/bescherming_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 32 AVG"},{"location":"vereisten/bescherming_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bescherming_persoonsgegevens/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals ongeautoriseerde toegang, vernietiging, onrechtmatige verwerking, verlies, wijziging of niet-toegestane verwerking van persoonsgegevens.</p>"},{"location":"vereisten/bescherming_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bescherming_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/","title":"Bescherming van kwetsbare groepen","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#vereiste","title":"Vereiste","text":"<p>Bescherm de privacy van kinderen en kwetsbare groepen en neem passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens in overeenstemming is met de AVG</p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#toelichting","title":"Toelichting","text":"<p>Bescherm de privacy van kinderen en kwetsbare groepen door ervoor te zorgen dat de verwerking van hun persoonsgegevens voldoet aan de Algemene Verordening Gegevensbescherming (AVG). Dit omvat het nemen van passende maatregelen om ervoor te zorgen dat de verwerking van persoonsgegevens veilig en rechtmatig is, en dat de rechten van deze groepen worden gerespecteerd. Het waarborgen van privacy voor deze groepen draagt bij aan een veilige en vertrouwde online omgeving waarin hun gegevens worden beschermd.</p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#bronnen","title":"Bronnen","text":"Bron Artikel 8 AVG Overweging 38 en 75 AVG"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#risico","title":"Risico","text":""},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bescherming_van_kwetsbare_groepen/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/","title":"Beschrijven en toewijzen van verantwoordelijkheden","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatieGovernance</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De verantwoordelijkheden bij de verwerking van persoonsgegevens voor algoritmen en AI-systemen moeten zijn beschreven en toegekend.</p> <p>De verwerkingsverantwoordelijke is verantwoordelijk voor de naleving van lid 1 en kan deze aantonen (\"verantwoordingsplicht\").</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Bij het verwerken van persoonsgegevens voor algoritmen en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorg dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 24, 26, 27, 28 en 29, 5(2) AVG"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#risico","title":"Risico","text":"<p>Door rollen en verantwoordelijkheden rondom de verwerking van persoonsgegevens niet te duiden en te beleggen, ontstaat het risico dat persoonsgegevens onrechtmatig on onveilig wordt verwerkt.</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/","title":"Informatie en informatiesystemen van de overheid moet worden beveiligd","text":"<p>OntwerpImplementatieMonitorenTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#vereiste","title":"Vereiste","text":"<p>Informatie en informatiesystemen moeten op de juiste manier worden beveiligd.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#toelichting","title":"Toelichting","text":"<p>Informatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving,  passend beveiligd zijn. Algoritmen en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#bronnen","title":"Bronnen","text":"Bron Baseline Informatiebeveiliging Overheid Besluit voorschrift informatiebeveiliging rijksdienst 2007"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals ongeautoriseerde toegang, vernietiging, verlies, wijziging of niet-toegestane verwerking van gegevens als de informatie en informatiesystemen onvoldoende zijn beveiligd.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/","title":"Bevorder ai-geletterdheid personeel","text":"<p>ProbleemanalyseOntwerpMenselijke controle</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#vereiste","title":"Vereiste","text":"<p>Aanbieders en exploitanten van AI-systemen nemen maatregelen om, zoveel als mogelijk, te zorgen voor een toereikend niveau van AI-geletterdheid bij hun personeel en andere personen die namens hen AI-systemen exploiteren en gebruiken, en houden daarbij rekening met hun technische kennis, ervaring, onderwijs en opleiding en de context waarin de AI-systemen zullen worden gebruikt, evenals met de personen of groepen personen ten aanzien van wie de AI-systemen zullen worden gebruikt.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#toelichting","title":"Toelichting","text":"<p>Aanbieders en exploitanten van AI-systemen nemen maatregelen om ervoor te zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het overwegen van technische kennis, ervaring, onderwijs en opleiding van individuen, evenals de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#bronnen","title":"Bronnen","text":"Bron Artikel 4 AI-geletterdheid - AI verordening"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#risico","title":"Risico","text":"<p>Onvoldoende AI-geletterdheid kan leiden tot misbruik of verkeerd gebruik van AI-systemen.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/","title":"Bewaartermijn voor documentatie","text":"<p>OntwerpMonitorenArchiverenGovernance</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#vereiste","title":"Vereiste","text":"<p>De aanbieder houdt gedurende een periode van tien jaar nadat het AI-systeem met een hoog risico in de handel is gebracht of in gebruik is gesteld de elementen van art. 18 ter beschikking van de nationale bevoegde autoriteiten.</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#toelichting","title":"Toelichting","text":"<p>De aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#bronnen","title":"Bronnen","text":"Bron Artikel 18(1) Bewaring van documentatie- AI verordening Artikel 16(d) Verplichtingen van aanbieders van AI-systemen met een hoog risico - AI veordening"},{"location":"vereisten/bewaartermijn_voor_documentatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bewaartermijn_voor_documentatie/#risico","title":"Risico","text":"<p>Niet voldoen aan de bewaartermijn kan leiden tot juridische consequenties en kan het vermogen van de autoriteiten om toezicht te houden op de naleving van de regelgeving belemmeren.</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/","title":"Bewaartermijn voor gegenereerde logs","text":"<p>OntwerpOntwikkelenMonitorenArchiverenGovernance</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen. Deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door Unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplicht.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#bronnen","title":"Bronnen","text":"Bron Artikel 19(1) Automatisch gegenereerde logs- AI verordening Artikel 16(e) Verplichtingen van aanbieders van AI-systemen met een hoog risico - AI veordening"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#risico","title":"Risico","text":"<p>Onvoldoende bewaring van logs kan het vermogen belemmeren om incidenten te analyseren, naleving te controleren en verantwoordelijkheid vast te stellen bij mogelijke problemen met het AI-systeem.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/","title":"Corrigerende maatregelen voor non-conforme ai","text":"<p>MonitorenOntwerpOntwikkelenGovernance</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met deze verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de exploitanten, de gemachtigden en importeurs dienovereenkomstig in kennis.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem. Ze moeten ook alle relevante partijen, zoals distributeurs, exploitanten en importeurs, op de hoogte stellen van deze maatregelen.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 20(1) Corrigerende maatregelen en mededelingsverplichting- AI verordening Artikel 16(j) Verplichtingen van aanbieders van AI-systemen met een hoog risico - AI veordening"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#risico","title":"Risico","text":"<p>Niet reageren op non-conformiteit kan leiden tot juridische en reputatieschade, evenals risico's voor gebruikers en derden.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/databankenwet/","title":"Verbod op schenden databankenrechten","text":"<p>OntwerpDataverkenning en datapreparatieData</p>"},{"location":"vereisten/databankenwet/#vereiste","title":"Vereiste","text":"<p>Het is verboden onbevoegd data op te vragen of te hergebruiken uit een databank, wanneer deze systematisch zijn geordend en door een substanti\u00eble investering tot stand is gekomen.</p>"},{"location":"vereisten/databankenwet/#toelichting","title":"Toelichting","text":"<p>Het databankenrecht beschermt tegen kopi\u00ebren of oneigenlijk gebruik van gegevens in een databank. Degene die een substanti\u00eble financi\u00eble investering heeft verricht om de databank tot stand te brengen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken. Voor het ontwikkelen van algoritme en AI is data nodig. De data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databank.</p>"},{"location":"vereisten/databankenwet/#bronnen","title":"Bronnen","text":"Bron Artikel 5a en 5b Databankenwet"},{"location":"vereisten/databankenwet/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/databankenwet/#risico","title":"Risico","text":"<p>Als een ontwikkelaar onbevoegd gebruik heeft gemaakt van data uit een databank bij de ontwikkeling van algoritmen en AI, wordt het databankenrecht geschonden van de eigenaar.  De eigenaar van de databank kan bijvoorbeeld ontrekking van de data uit het handelsverkeer, vernietiging en onbruikbaarmaking  eisen, wat vergaande gevolgen kan hebben voor het gebruik kunnen maken van het algoritmen of AI-systeem.</p>"},{"location":"vereisten/databankenwet/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/databankenwet/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/","title":"Documentatie beoordeling niet-hoog-risico ai","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenGovernance</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>Een aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>Een aanbieder die oordeelt dat een AI-systeem geen hoog risico vormt, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem en voldoet aan de registratievereisten. Op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 6(4) Classificatieregels voor AI-systemen met een hoog risico - AI verordening"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#risico","title":"Risico","text":"<p>Gebrek aan transparantie en verantwoording bij risicobeoordeling kan leiden tot onrechtmatig in de markt brengen van risicovolle AI-systemen.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/fundamentele_rechten/","title":"None","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieFundamentele rechten</p>"},{"location":"vereisten/fundamentele_rechten/#vereiste","title":"Vereiste","text":"<p>Fundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.</p>"},{"location":"vereisten/fundamentele_rechten/#toelichting","title":"Toelichting","text":""},{"location":"vereisten/fundamentele_rechten/#bronnen","title":"Bronnen","text":"Bron Grondwet en internationale verdragen Art 27 AI-verordening"},{"location":"vereisten/fundamentele_rechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/fundamentele_rechten/#risico","title":"Risico","text":"<p>Grondrechten kunnen worden aangetast door de inzet van algoritmes</p>"},{"location":"vereisten/fundamentele_rechten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/fundamentele_rechten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/","title":"Geb/dpia verplicht bij hoog risico","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenValidatiePrivacy en gegevensbescherming</p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Een gegevensbeschermingseffectbeoordeling / Data Protection Impact Assessment (GEB / DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen.</p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#toelichting","title":"Toelichting","text":"<p>Een Gegevensbeschermingseffectbeoordeling (GEB) of Data Protection Impact Assessment (DPIA) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens, waardoor de privacy van individuen wordt gewaarborgd.</p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 35 AVG"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#risico","title":"Risico","text":"<p>Bij de verwerking van persoonsgegevens zijn de risico's voor de rechten en vrijheden van betrokkenen zijn niet bekend en niet gemitigeerd.</p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/geb_dpia_verplicht_bij_hoog_risico/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/","title":"Gerichte doelverzameling","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens mogen alleen voor welbepaalde, uitdrukkelijk omschreven en gerechtvaardigde doeleinden worden verzameld en mogen vervolgens niet verder op een met die doeleinden onverenigbare wijze worden verwerkt (doelbinding).</p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden. Het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden. Deze regel, bekend als doelbinding, zorgt ervoor dat persoonsgegevens alleen worden gebruikt zoals bedoeld en voorkomt misbruik van gegevens voor andere doeleinden. Dit waarborgt de privacy van individuen en versterkt het vertrouwen in gegevensverwerking.</p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid, onder b AVG Overweging 50 AVG Artikel 54 AI-Verordening"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#risico","title":"Risico","text":"<p>De verwerking van persoonsgegevens in het algoritme valt niet onder het doel waarvoor zij verzameld zijn of een hiermee verenigbaar doel.</p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/gerichte_doelverzameling_bij_verwerking_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/","title":"Juistheid en actualiteit van gegevens","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De te verwerken gegevens zijn juist, nauwkeurig en zo nodig geactualiseerd</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>De te verwerken gegevens moeten nauwkeurig zijn en indien nodig regelmatig worden bijgewerkt. Dit waarborgt dat de informatie die wordt gebruikt bij gegevensverwerking actueel en betrouwbaar is, wat essentieel is om de integriteit van de gegevens te behouden en nauwkeurige resultaten te garanderen. Het bijhouden van juiste en actuele gegevens draagt bij aan transparantie en vertrouwen in de verwerking van persoonsgegevens.</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 sub d AVG Artikel 3 Wjsg Artikel 4 Wpg"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#risico","title":"Risico","text":"<p>De kwaliteit en integriteit van data is niet voldoende geborgd.</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/klachten/","title":"Klachten indienen bij markttoezichtautoriteit","text":"<p>ValidatieImplementatieMonitorenGovernanceFundamentele rechten</p>"},{"location":"vereisten/klachten/#vereiste","title":"Vereiste","text":"<p>Onverminderd andere administratieve of gerechtelijke rechtsmiddelen, kan elke natuurlijke of rechtspersoon die redenen heeft om van mening te zijn dat er inbreuk is gepleegd op de bepalingen van deze verordening, met redenen omklede klachten indienen bij de relevante markttoezichtautoriteit.</p>"},{"location":"vereisten/klachten/#toelichting","title":"Toelichting","text":"<p>Naast andere opties voor juridische stappen, heeft iedereen die gelooft dat de regels van deze verordening zijn geschonden, het recht om een klacht in te dienen bij de relevante markttoezichtautoriteit. Deze klachten moeten goed onderbouwd zijn en kunnen worden ingediend door zowel individuen als organisaties. Deze maatregel biedt een mechanisme om vermeende schendingen van de verordening aan te pakken en draagt bij aan de handhaving van de regels met betrekking tot gegevensbescherming en AI.</p>"},{"location":"vereisten/klachten/#bronnen","title":"Bronnen","text":"Bron Artikel 85(1) Recht om een klacht in te dienen bij een markttoezichtautoriteit- AI verordening"},{"location":"vereisten/klachten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/klachten/#risico","title":"Risico","text":"<p>Het indienen van klachten is een belangrijk middel om naleving van de verordening te waarborgen en eventuele inbreuken aan te pakken.</p>"},{"location":"vereisten/klachten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/klachten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/melding_ernstige_incidenten/","title":"Melden van ernstige incidenten","text":"<p>ValidatieImplementatieMonitorenGovernance</p>"},{"location":"vereisten/melding_ernstige_incidenten/#vereiste","title":"Vereiste","text":"<p>Aanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die binnen de EU worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden. Dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze AI-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek. Het doel is om de veiligheid en betrouwbaarheid van AI-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliseren.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#bronnen","title":"Bronnen","text":"Bron Artikel 73(1) Melding van ernstige incidenten AI verordening"},{"location":"vereisten/melding_ernstige_incidenten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/melding_ernstige_incidenten/#risico","title":"Risico","text":"<p>Het niet melden van ernstige incidenten kan leiden tot vertraagde reactie op potenti\u00eble gevaren voor gebruikers en kan het vertrouwen in AI-systemen ondermijnen.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/melding_ernstige_incidenten/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/non_discriminatie/","title":"Verbod op discriminatie","text":"<p>ProbleemanalyseDataverkenning en datapreparatieOntwerpValidatieImplementatieMonitorenFundamentele rechten</p>"},{"location":"vereisten/non_discriminatie/#vereiste","title":"Vereiste","text":"<p>Allen die zich in Nederland bevinden, worden in gelijke gevallen gelijk behandeld. Directe en indirecte discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, handicap, seksuele gerichtheid of op welke grond dan ook, is niet toegestaan.</p>"},{"location":"vereisten/non_discriminatie/#toelichting","title":"Toelichting","text":"<p>Overheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.</p>"},{"location":"vereisten/non_discriminatie/#bronnen","title":"Bronnen","text":"Bron Grondwet Artikel 1 EVRM Artikel 1 en 14, jo. 21 HvEU Algemene wet gelijke behandeling, Protocol 12 2.2, Artikel 1 lid 1 sub c Aritkel 9 AVG Artikel 2:4 Awb"},{"location":"vereisten/non_discriminatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/non_discriminatie/#risico","title":"Risico","text":"<p>Het model cre\u00ebert onwenselijke systematische afwijking voor specifieke personen, groepen of andere eenheden (bias). Deze onwenselijke systematische afwijking kan duiden op directe of indirecte discriminerende effecten van de inzet van het algoritme.</p>"},{"location":"vereisten/non_discriminatie/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/non_discriminatie/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/","title":"Persoonsgegeven worden rechtmatig, behoorlijk en transparant verwerkt","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatiePrivacy en gegevensbescherming</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens is rechtmatig, behoorlijk en transparant. De verwerking (inclusief het verzamelen) is gebaseerd op \u00e9\u00e9n van de wettelijke grondslagen die zijn genoemd in de AVG. De verwerking van persoonsgegevens op een eerlijke en rechtmatige manier moet gebeuren.</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#toelichting","title":"Toelichting","text":"<p>De verwerking van persoonsgegevens moet eerlijk en rechtmatig plaatsvinden, wat betekent dat het voldoet aan de principes van rechtmatigheid, behoorlijkheid en transparantie. Dit houdt in dat de verwerking gebaseerd moet zijn op een van de wettelijke grondslagen die zijn vastgesteld in de Algemene Verordening Gegevensbescherming (AVG).</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 onder a AVG Artikel 6 en 12 AVG Artikel 5 en 6 AVG Overweging 39 en 60 AVG"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#risico","title":"Risico","text":""},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_behoorlijk_en_transparant_verwerkt/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/","title":"None","text":"<p>ProbleemanalyseOntwerpPrivacy en gegevensbescherming</p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#vereiste","title":"Vereiste","text":"<p>Voor zover dit strikt noodzakelijk is om de opsporing en correctie van vertekeningen te waarborgen in verband met de AI-systemen met een hoog risico overeenkomstig lid 2, punten f) en g), van dit artikel, mogen de aanbieders van dergelijke systemen uitzonderlijk bijzondere categorie\u00ebn persoonsgegevens verwerken, mits passende waarborgen worden geboden voor de grondrechten en fundamentele vrijheden van natuurlijke personen.</p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#toelichting","title":"Toelichting","text":"<p>Voor zover strikt noodzakelijk voor het detecteren en corrigeren van vooringenomenheid met betrekking tot AI-systemen met een hoog risico, mogen aanbieders van dergelijke systemen uitzonderlijk speciale categorie\u00ebn persoonsgegevens verwerken. Deze verwerking moet gepaard gaan met passende waarborgen voor de fundamentele rechten en vrijheden van natuurlijke personen.</p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#bronnen","title":"Bronnen","text":"Bron Artikel 10(5)  Data and datagovernance- AI verordening"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#risico","title":"Risico","text":""},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/uitzonderlijk_verwerken_%20bijzondere_categorie%C3%ABn_persoonsgegevens%20/#maatregelen","title":"Maatregelen","text":"<p>Hier komt een lijst met relevante maatregelen om te voldoen aan dit vereiste. </p>"}]}